CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU E5-2620 v3 @ 2.40GHz
    Hardware threads: 24
    Total Memory: 33476764 kB
-------------------------------------------------------------------
=== Running /cygdrive/c/repo/cntk_github/CNTK/x64/debug/cntk.exe configFile=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Simple/cntk.cntk currentDirectory=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Data RunDir=F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu DataDir=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Data ConfigDir=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Simple OutputDir=F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu DeviceId=-1 timestamping=true
-------------------------------------------------------------------
Build info: 

		Built time: Aug 19 2016 15:33:50
		Last modified date: Wed Aug 17 12:18:00 2016
		Build type: Debug
		Build target: GPU
		With 1bit-SGD: yes
		Math lib: mkl
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
		CUB_PATH: c:\Tools\cub-1.4.1\
		CUDNN_PATH: c:\Tools\cudnn-4.0\cuda
		Build Branch: eldak/mtNonUniform2
		Build SHA1: bf68d59b287b6a44797ded0815a80d1451d8774e (modified)
		Built by eldak on ELDAK-0
		Build Path: c:\repo\cntk_github\CNTK\Source\CNTK\
-------------------------------------------------------------------
Changed current directory to C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Data
08/19/2016 14:55:34: -------------------------------------------------------------------
08/19/2016 14:55:34: Build info: 

08/19/2016 14:55:34: 		Built time: Aug 19 2016 15:33:50
08/19/2016 14:55:34: 		Last modified date: Wed Aug 17 12:18:00 2016
08/19/2016 14:55:34: 		Build type: Debug
08/19/2016 14:55:34: 		Build target: GPU
08/19/2016 14:55:34: 		With 1bit-SGD: yes
08/19/2016 14:55:34: 		Math lib: mkl
08/19/2016 14:55:34: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
08/19/2016 14:55:34: 		CUB_PATH: c:\Tools\cub-1.4.1\
08/19/2016 14:55:34: 		CUDNN_PATH: c:\Tools\cudnn-4.0\cuda
08/19/2016 14:55:34: 		Build Branch: eldak/mtNonUniform2
08/19/2016 14:55:34: 		Build SHA1: bf68d59b287b6a44797ded0815a80d1451d8774e (modified)
08/19/2016 14:55:34: 		Built by eldak on ELDAK-0
08/19/2016 14:55:34: 		Build Path: c:\repo\cntk_github\CNTK\Source\CNTK\
08/19/2016 14:55:34: -------------------------------------------------------------------
08/19/2016 14:55:35: -------------------------------------------------------------------
08/19/2016 14:55:35: GPU info:

08/19/2016 14:55:35: 		Device[0]: cores = 1536; computeCapability = 5.2; type = "GeForce GTX 960"; memory = 2048 MB
08/19/2016 14:55:35: 		Device[1]: cores = 576; computeCapability = 5.0; type = "Quadro K620"; memory = 2048 MB
08/19/2016 14:55:35: -------------------------------------------------------------------

08/19/2016 14:55:35: Running on ELDAK-0 at 2016/08/19 14:55:35
08/19/2016 14:55:35: Command line: 
C:\repo\cntk_github\CNTK\x64\debug\cntk.exe  configFile=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Simple/cntk.cntk  currentDirectory=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Data  RunDir=F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu  DataDir=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Data  ConfigDir=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Simple  OutputDir=F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu  DeviceId=-1  timestamping=true



08/19/2016 14:55:35: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
08/19/2016 14:55:35: command=Simple_Demo:Simple_Demo_Output
DeviceNumber=-1
precision=float
modelPath=$RunDir$/models/simple.dnn
deviceId=$DeviceNumber$
outputNodeNames=ScaledLogLikelihood
traceLevel=1
Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=$DataDir$/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]
Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=$DataDir$/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=$RunDir$/SimpleOutput    
]
currentDirectory=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Data
RunDir=F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu
DataDir=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Data
ConfigDir=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Simple
OutputDir=F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu
DeviceId=-1
timestamping=true

08/19/2016 14:55:35: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<

08/19/2016 14:55:35: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
08/19/2016 14:55:35: command=Simple_Demo:Simple_Demo_Output
DeviceNumber=-1
precision=float
modelPath=F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/models/simple.dnn
deviceId=-1
outputNodeNames=ScaledLogLikelihood
traceLevel=1
Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]
Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/SimpleOutput    
]
currentDirectory=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Data
RunDir=F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu
DataDir=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Data
ConfigDir=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Simple
OutputDir=F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu
DeviceId=-1
timestamping=true

08/19/2016 14:55:35: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<

08/19/2016 14:55:35: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
configparameters: cntk.cntk:command=Simple_Demo:Simple_Demo_Output
configparameters: cntk.cntk:ConfigDir=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Simple
configparameters: cntk.cntk:currentDirectory=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Data
configparameters: cntk.cntk:DataDir=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Data
configparameters: cntk.cntk:deviceId=-1
configparameters: cntk.cntk:DeviceNumber=-1
configparameters: cntk.cntk:modelPath=F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/models/simple.dnn
configparameters: cntk.cntk:OutputDir=F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu
configparameters: cntk.cntk:outputNodeNames=ScaledLogLikelihood
configparameters: cntk.cntk:precision=float
configparameters: cntk.cntk:RunDir=F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu
configparameters: cntk.cntk:Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]

configparameters: cntk.cntk:Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/SimpleOutput    
]

configparameters: cntk.cntk:timestamping=true
configparameters: cntk.cntk:traceLevel=1
08/19/2016 14:55:35: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
08/19/2016 14:55:35: Commands: Simple_Demo Simple_Demo_Output
08/19/2016 14:55:35: Precision = "float"
08/19/2016 14:55:35: CNTKModelPath: F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/models/simple.dnn
08/19/2016 14:55:35: CNTKCommandTrainInfo: Simple_Demo : 50
08/19/2016 14:55:35: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 50

08/19/2016 14:55:35: ##############################################################################
08/19/2016 14:55:35: #                                                                            #
08/19/2016 14:55:35: # Action "train"                                                             #
08/19/2016 14:55:35: #                                                                            #
08/19/2016 14:55:35: ##############################################################################

08/19/2016 14:55:35: CNTKCommandTrainBegin: Simple_Demo
SimpleNetworkBuilder Using CPU

08/19/2016 14:55:35: Creating virgin network.
Node 'W0' (LearnableParameter operation): Initializing Parameter[50 x 2] <- 0.000000.
Node 'W0' (LearnableParameter operation): Initializing Parameter[50 x 2] <- uniform(seed=1, range=0.050000*1.000000, onCPU=false).
Node 'B0' (LearnableParameter operation): Initializing Parameter[50 x 1] <- 0.000000.
Node 'B0' (LearnableParameter operation): Initializing Parameter[50 x 1] <- 0.000000.
Node 'W1' (LearnableParameter operation): Initializing Parameter[50 x 50] <- 0.000000.
Node 'W1' (LearnableParameter operation): Initializing Parameter[50 x 50] <- uniform(seed=2, range=0.050000*1.000000, onCPU=false).
Node 'B1' (LearnableParameter operation): Initializing Parameter[50 x 1] <- 0.000000.
Node 'B1' (LearnableParameter operation): Initializing Parameter[50 x 1] <- 0.000000.
Node 'W2' (LearnableParameter operation): Initializing Parameter[2 x 50] <- 0.000000.
Node 'W2' (LearnableParameter operation): Initializing Parameter[2 x 50] <- uniform(seed=3, range=0.050000*1.000000, onCPU=false).
Node 'B2' (LearnableParameter operation): Initializing Parameter[2 x 1] <- 0.000000.
Node 'B2' (LearnableParameter operation): Initializing Parameter[2 x 1] <- 0.000000.

Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalErrorPrediction = ErrorPrediction()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *]
Validating --> MeanOfFeatures = Mean (features) : [2 x *] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *], [2], [2] -> [2 x *]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *] -> [50 x *]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *], [50 x 1] -> [50 x 1 x *]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *] -> [50 x 1 x *]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *] -> [50 x 1 x *]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *], [50 x 1] -> [50 x 1 x *]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *] -> [50 x 1 x *]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *] -> [2 x 1 x *]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *], [2 x 1] -> [2 x 1 x *]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *], [2 x 1 x *] -> [1]
Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [2 x *], [2 x 1 x *] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *] -> [2 x 1 x *]
Validating --> Prior = Mean (labels) : [2 x *] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *], [2] -> [2 x 1 x *]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

08/19/2016 14:55:35: Created model with 25 nodes on CPU.

08/19/2016 14:55:35: Training criterion node(s):
08/19/2016 14:55:35: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax

08/19/2016 14:55:35: Evaluation criterion node(s):
08/19/2016 14:55:35: 	EvalErrorPrediction = ErrorPrediction


Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 40 matrices, 19 are shared as 8, and 21 are not shared.

	{ HLast : [2 x 1 x *]
	  W2 : [2 x 50] (gradient) }
	{ H2 : [50 x 1 x *]
	  W1*H1 : [50 x 1 x *] (gradient) }
	{ B0 : [50 x 1] (gradient)
	  H1 : [50 x 1 x *] (gradient)
	  W1*H1+B1 : [50 x 1 x *] (gradient)
	  W2*H1 : [2 x 1 x *] }
	{ H1 : [50 x 1 x *]
	  W0*features : [50 x *] (gradient) }
	{ W0*features+B0 : [50 x 1 x *] (gradient)
	  W1*H1 : [50 x 1 x *] }
	{ W0 : [50 x 2] (gradient)
	  W0*features+B0 : [50 x 1 x *] }
	{ W1 : [50 x 50] (gradient)
	  W1*H1+B1 : [50 x 1 x *] }
	{ B1 : [50 x 1] (gradient)
	  H2 : [50 x 1 x *] (gradient)
	  HLast : [2 x 1 x *] (gradient) }


08/19/2016 14:55:35: Training 2802 parameters in 6 out of 6 parameter tensors and 15 nodes with gradient:

08/19/2016 14:55:35: 	Node 'B0' (LearnableParameter operation) : [50 x 1]
08/19/2016 14:55:35: 	Node 'B1' (LearnableParameter operation) : [50 x 1]
08/19/2016 14:55:35: 	Node 'B2' (LearnableParameter operation) : [2 x 1]
08/19/2016 14:55:35: 	Node 'W0' (LearnableParameter operation) : [50 x 2]
08/19/2016 14:55:35: 	Node 'W1' (LearnableParameter operation) : [50 x 50]
08/19/2016 14:55:35: 	Node 'W2' (LearnableParameter operation) : [2 x 50]


08/19/2016 14:55:35: Precomputing --> 3 PreCompute nodes found.

08/19/2016 14:55:35: 	MeanOfFeatures = Mean()
08/19/2016 14:55:35: 	InvStdOfFeatures = InvStdDev()
08/19/2016 14:55:35: 	Prior = Mean()
BlockRandomizer::StartEpoch: epoch 1: samples [0..10000] (first sequence at sample 0), worker rank 0, total workers 1

08/19/2016 14:55:36: Precomputing --> Completed.


08/19/2016 14:55:36: Starting Epoch 1: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 1: samples [0..10000] (first sequence at sample 0), worker rank 0, total workers 1

08/19/2016 14:55:36: Starting minibatch loop.
08/19/2016 14:55:37:  Epoch[ 1 of 50]-Minibatch[   1-  10]: CrossEntropyWithSoftmax = 0.84135866 * 1280; EvalErrorPrediction = 0.49375000 * 1280; time = 0.4473s; samplesPerSecond = 2861.8
08/19/2016 14:55:37:  Epoch[ 1 of 50]-Minibatch[  11-  20]: CrossEntropyWithSoftmax = 0.80750952 * 1280; EvalErrorPrediction = 0.50937500 * 1280; time = 0.4087s; samplesPerSecond = 3131.7
08/19/2016 14:55:37:  Epoch[ 1 of 50]-Minibatch[  21-  30]: CrossEntropyWithSoftmax = 0.73671169 * 1280; EvalErrorPrediction = 0.48828125 * 1280; time = 0.4138s; samplesPerSecond = 3093.3
08/19/2016 14:55:38:  Epoch[ 1 of 50]-Minibatch[  31-  40]: CrossEntropyWithSoftmax = 0.71652241 * 1280; EvalErrorPrediction = 0.51484375 * 1280; time = 0.4284s; samplesPerSecond = 2988.1
08/19/2016 14:55:38:  Epoch[ 1 of 50]-Minibatch[  41-  50]: CrossEntropyWithSoftmax = 0.70134087 * 1280; EvalErrorPrediction = 0.50078125 * 1280; time = 0.4341s; samplesPerSecond = 2948.6
08/19/2016 14:55:39:  Epoch[ 1 of 50]-Minibatch[  51-  60]: CrossEntropyWithSoftmax = 0.71664810 * 1280; EvalErrorPrediction = 0.50781250 * 1280; time = 0.4557s; samplesPerSecond = 2808.6
08/19/2016 14:55:39:  Epoch[ 1 of 50]-Minibatch[  61-  70]: CrossEntropyWithSoftmax = 0.71382103 * 1280; EvalErrorPrediction = 0.50156250 * 1280; time = 0.4722s; samplesPerSecond = 2711.0
08/19/2016 14:55:40: Finished Epoch[ 1 of 50]: [Training] CrossEntropyWithSoftmax = 0.74341201 * 10000; EvalErrorPrediction = 0.50260000 * 10000; totalSamplesSeen = 10000; learningRatePerSample = 0.1; epochTime=3.78465s
08/19/2016 14:55:40: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/models/simple.dnn.1'

08/19/2016 14:55:40: Starting Epoch 2: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 2: samples [10000..20000] (first sequence at sample 10000), worker rank 0, total workers 1

08/19/2016 14:55:40: Starting minibatch loop.
08/19/2016 14:55:40:  Epoch[ 2 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.71325479 * 1280; EvalErrorPrediction = 0.49296875 * 1280; time = 0.4902s; samplesPerSecond = 2611.0
08/19/2016 14:55:41:  Epoch[ 2 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.75389848 * 1280; EvalErrorPrediction = 0.46406250 * 1280; time = 0.4889s; samplesPerSecond = 2618.4
08/19/2016 14:55:41:  Epoch[ 2 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.75757513 * 1280; EvalErrorPrediction = 0.51171875 * 1280; time = 0.5001s; samplesPerSecond = 2559.7
08/19/2016 14:55:42:  Epoch[ 2 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.75674992 * 1280; EvalErrorPrediction = 0.51171875 * 1280; time = 0.5046s; samplesPerSecond = 2536.4
08/19/2016 14:55:42:  Epoch[ 2 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.74725094 * 1280; EvalErrorPrediction = 0.50390625 * 1280; time = 0.5123s; samplesPerSecond = 2498.5
08/19/2016 14:55:43:  Epoch[ 2 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.73079414 * 1280; EvalErrorPrediction = 0.50546875 * 1280; time = 0.5199s; samplesPerSecond = 2462.2
08/19/2016 14:55:43:  Epoch[ 2 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.73625755 * 1280; EvalErrorPrediction = 0.50078125 * 1280; time = 0.5275s; samplesPerSecond = 2426.8
08/19/2016 14:55:44: Finished Epoch[ 2 of 50]: [Training] CrossEntropyWithSoftmax = 0.73900103 * 10000; EvalErrorPrediction = 0.49680000 * 10000; totalSamplesSeen = 20000; learningRatePerSample = 0.1; epochTime=4.14734s
08/19/2016 14:55:44: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/models/simple.dnn.2'

08/19/2016 14:55:44: Starting Epoch 3: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 3: samples [20000..30000] (first sequence at sample 20000), worker rank 0, total workers 1

08/19/2016 14:55:44: Starting minibatch loop.
08/19/2016 14:55:44:  Epoch[ 3 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.74044714 * 1280; EvalErrorPrediction = 0.50000000 * 1280; time = 0.5634s; samplesPerSecond = 2272.0
08/19/2016 14:55:45:  Epoch[ 3 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.73792171 * 1280; EvalErrorPrediction = 0.50625000 * 1280; time = 0.5512s; samplesPerSecond = 2322.2
08/19/2016 14:55:46:  Epoch[ 3 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.77087240 * 1280; EvalErrorPrediction = 0.52187500 * 1280; time = 0.5649s; samplesPerSecond = 2265.7
08/19/2016 14:55:46:  Epoch[ 3 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.75999603 * 1280; EvalErrorPrediction = 0.50234375 * 1280; time = 0.5679s; samplesPerSecond = 2253.9
08/19/2016 14:55:47:  Epoch[ 3 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.73512688 * 1280; EvalErrorPrediction = 0.50937500 * 1280; time = 0.5779s; samplesPerSecond = 2215.1
08/19/2016 14:55:47:  Epoch[ 3 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.71369209 * 1280; EvalErrorPrediction = 0.48984375 * 1280; time = 0.5854s; samplesPerSecond = 2186.4
08/19/2016 14:55:48:  Epoch[ 3 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.69696960 * 1280; EvalErrorPrediction = 0.50703125 * 1280; time = 0.6013s; samplesPerSecond = 2128.8
08/19/2016 14:55:49: Finished Epoch[ 3 of 50]: [Training] CrossEntropyWithSoftmax = 0.73257485 * 10000; EvalErrorPrediction = 0.50380000 * 10000; totalSamplesSeen = 30000; learningRatePerSample = 0.1; epochTime=4.67536s
08/19/2016 14:55:49: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/models/simple.dnn.3'

08/19/2016 14:55:49: Starting Epoch 4: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 4: samples [30000..40000] (first sequence at sample 30000), worker rank 0, total workers 1

08/19/2016 14:55:49: Starting minibatch loop.
08/19/2016 14:55:49:  Epoch[ 4 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.71515265 * 1280; EvalErrorPrediction = 0.49296875 * 1280; time = 0.6343s; samplesPerSecond = 2018.0
08/19/2016 14:55:50:  Epoch[ 4 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.74560337 * 1280; EvalErrorPrediction = 0.50234375 * 1280; time = 0.6240s; samplesPerSecond = 2051.2
08/19/2016 14:55:51:  Epoch[ 4 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.73897238 * 1280; EvalErrorPrediction = 0.47812500 * 1280; time = 0.6381s; samplesPerSecond = 2006.0
08/19/2016 14:55:51:  Epoch[ 4 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.71412621 * 1280; EvalErrorPrediction = 0.48671875 * 1280; time = 0.6438s; samplesPerSecond = 1988.3
08/19/2016 14:55:52:  Epoch[ 4 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.71213531 * 1280; EvalErrorPrediction = 0.50000000 * 1280; time = 0.6583s; samplesPerSecond = 1944.5
08/19/2016 14:55:52:  Epoch[ 4 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.70156898 * 1280; EvalErrorPrediction = 0.50390625 * 1280; time = 0.6710s; samplesPerSecond = 1907.6
08/19/2016 14:55:53:  Epoch[ 4 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.70737991 * 1280; EvalErrorPrediction = 0.49687500 * 1280; time = 0.6798s; samplesPerSecond = 1883.0
08/19/2016 14:55:54: Finished Epoch[ 4 of 50]: [Training] CrossEntropyWithSoftmax = 0.71707461 * 10000; EvalErrorPrediction = 0.49440000 * 10000; totalSamplesSeen = 40000; learningRatePerSample = 0.1; epochTime=5.27447s
08/19/2016 14:55:54: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/models/simple.dnn.4'

08/19/2016 14:55:54: Starting Epoch 5: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 5: samples [40000..50000] (first sequence at sample 40000), worker rank 0, total workers 1

08/19/2016 14:55:54: Starting minibatch loop.
08/19/2016 14:55:55:  Epoch[ 5 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.69854627 * 1280; EvalErrorPrediction = 0.50234375 * 1280; time = 0.7085s; samplesPerSecond = 1806.7
08/19/2016 14:55:55:  Epoch[ 5 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.70018859 * 1280; EvalErrorPrediction = 0.49140625 * 1280; time = 0.7075s; samplesPerSecond = 1809.1
08/19/2016 14:55:56:  Epoch[ 5 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.69679489 * 1280; EvalErrorPrediction = 0.51796875 * 1280; time = 0.7154s; samplesPerSecond = 1789.2
08/19/2016 14:55:57:  Epoch[ 5 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.69342003 * 1280; EvalErrorPrediction = 0.49531250 * 1280; time = 0.7249s; samplesPerSecond = 1765.7
08/19/2016 14:55:57:  Epoch[ 5 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.69504795 * 1280; EvalErrorPrediction = 0.48906250 * 1280; time = 0.7339s; samplesPerSecond = 1744.1
08/19/2016 14:55:58:  Epoch[ 5 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.70215073 * 1280; EvalErrorPrediction = 0.48593750 * 1280; time = 0.7525s; samplesPerSecond = 1701.0
08/19/2016 14:55:59:  Epoch[ 5 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.69844475 * 1280; EvalErrorPrediction = 0.47734375 * 1280; time = 0.7589s; samplesPerSecond = 1686.6
08/19/2016 14:56:00: Finished Epoch[ 5 of 50]: [Training] CrossEntropyWithSoftmax = 0.69761064 * 10000; EvalErrorPrediction = 0.49640000 * 10000; totalSamplesSeen = 50000; learningRatePerSample = 0.1; epochTime=5.89345s
08/19/2016 14:56:00: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/models/simple.dnn.5'

08/19/2016 14:56:00: Starting Epoch 6: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 6: samples [50000..60000] (first sequence at sample 50000), worker rank 0, total workers 1

08/19/2016 14:56:00: Starting minibatch loop.
08/19/2016 14:56:01:  Epoch[ 6 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.70235510 * 1280; EvalErrorPrediction = 0.49843750 * 1280; time = 0.7801s; samplesPerSecond = 1640.9
08/19/2016 14:56:01:  Epoch[ 6 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.69491978 * 1280; EvalErrorPrediction = 0.46875000 * 1280; time = 0.8000s; samplesPerSecond = 1600.1
08/19/2016 14:56:02:  Epoch[ 6 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.68310022 * 1280; EvalErrorPrediction = 0.49062500 * 1280; time = 0.8075s; samplesPerSecond = 1585.1
08/19/2016 14:56:03:  Epoch[ 6 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.68258762 * 1280; EvalErrorPrediction = 0.50625000 * 1280; time = 0.8164s; samplesPerSecond = 1567.8
08/19/2016 14:56:04:  Epoch[ 6 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.55128212 * 1280; EvalErrorPrediction = 0.29218750 * 1280; time = 0.8230s; samplesPerSecond = 1555.2
08/19/2016 14:56:05:  Epoch[ 6 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.26577034 * 1280; EvalErrorPrediction = 0.10390625 * 1280; time = 0.8401s; samplesPerSecond = 1523.7
08/19/2016 14:56:06:  Epoch[ 6 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17695389 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.8752s; samplesPerSecond = 1462.5
08/19/2016 14:56:06: Finished Epoch[ 6 of 50]: [Training] CrossEntropyWithSoftmax = 0.49745508 * 10000; EvalErrorPrediction = 0.31920000 * 10000; totalSamplesSeen = 60000; learningRatePerSample = 0.1; epochTime=6.60162s
08/19/2016 14:56:06: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/models/simple.dnn.6'

08/19/2016 14:56:06: Starting Epoch 7: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 7: samples [60000..70000] (first sequence at sample 60000), worker rank 0, total workers 1

08/19/2016 14:56:06: Starting minibatch loop.
08/19/2016 14:56:07:  Epoch[ 7 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17652882 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.8701s; samplesPerSecond = 1471.1
08/19/2016 14:56:08:  Epoch[ 7 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17294160 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.8783s; samplesPerSecond = 1457.4
08/19/2016 14:56:09:  Epoch[ 7 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17362566 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.8887s; samplesPerSecond = 1440.3
08/19/2016 14:56:10:  Epoch[ 7 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16371789 * 1280; EvalErrorPrediction = 0.06718750 * 1280; time = 0.9009s; samplesPerSecond = 1420.8
08/19/2016 14:56:11:  Epoch[ 7 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16040406 * 1280; EvalErrorPrediction = 0.06562500 * 1280; time = 0.9064s; samplesPerSecond = 1412.3
08/19/2016 14:56:12:  Epoch[ 7 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.19018784 * 1280; EvalErrorPrediction = 0.08515625 * 1280; time = 0.9194s; samplesPerSecond = 1392.2
08/19/2016 14:56:13:  Epoch[ 7 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18002701 * 1280; EvalErrorPrediction = 0.08906250 * 1280; time = 0.9393s; samplesPerSecond = 1362.7
08/19/2016 14:56:14: Finished Epoch[ 7 of 50]: [Training] CrossEntropyWithSoftmax = 0.17465474 * 10000; EvalErrorPrediction = 0.07710000 * 10000; totalSamplesSeen = 70000; learningRatePerSample = 0.1; epochTime=7.2267s
08/19/2016 14:56:14: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/models/simple.dnn.7'

08/19/2016 14:56:14: Starting Epoch 8: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 8: samples [70000..80000] (first sequence at sample 70000), worker rank 0, total workers 1

08/19/2016 14:56:14: Starting minibatch loop.
08/19/2016 14:56:15:  Epoch[ 8 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17755414 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.9543s; samplesPerSecond = 1341.3
08/19/2016 14:56:16:  Epoch[ 8 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16834592 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.9555s; samplesPerSecond = 1339.6
08/19/2016 14:56:17:  Epoch[ 8 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17158256 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.9858s; samplesPerSecond = 1298.5
08/19/2016 14:56:18:  Epoch[ 8 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16443491 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.9950s; samplesPerSecond = 1286.5
08/19/2016 14:56:19:  Epoch[ 8 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17230649 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.9940s; samplesPerSecond = 1287.8
08/19/2016 14:56:20:  Epoch[ 8 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.19415274 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 1.0144s; samplesPerSecond = 1261.8
08/19/2016 14:56:21:  Epoch[ 8 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15374594 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 1.0272s; samplesPerSecond = 1246.1
08/19/2016 14:56:22: Finished Epoch[ 8 of 50]: [Training] CrossEntropyWithSoftmax = 0.17303987 * 10000; EvalErrorPrediction = 0.07940000 * 10000; totalSamplesSeen = 80000; learningRatePerSample = 0.1; epochTime=7.91947s
08/19/2016 14:56:22: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/models/simple.dnn.8'

08/19/2016 14:56:22: Starting Epoch 9: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 9: samples [80000..90000] (first sequence at sample 80000), worker rank 0, total workers 1

08/19/2016 14:56:22: Starting minibatch loop.
08/19/2016 14:56:23:  Epoch[ 9 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.21020057 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 1.0299s; samplesPerSecond = 1242.9
08/19/2016 14:56:24:  Epoch[ 9 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.20800202 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 1.0474s; samplesPerSecond = 1222.1
08/19/2016 14:56:25:  Epoch[ 9 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.19789515 * 1280; EvalErrorPrediction = 0.09609375 * 1280; time = 1.0422s; samplesPerSecond = 1228.2
08/19/2016 14:56:26:  Epoch[ 9 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.19386339 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 1.0676s; samplesPerSecond = 1198.9
08/19/2016 14:56:27:  Epoch[ 9 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18509102 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 1.0689s; samplesPerSecond = 1197.5
08/19/2016 14:56:28:  Epoch[ 9 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17263746 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 1.0749s; samplesPerSecond = 1190.8
08/19/2016 14:56:29:  Epoch[ 9 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17052603 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 1.0873s; samplesPerSecond = 1177.2
08/19/2016 14:56:30: Finished Epoch[ 9 of 50]: [Training] CrossEntropyWithSoftmax = 0.19133789 * 10000; EvalErrorPrediction = 0.08210000 * 10000; totalSamplesSeen = 90000; learningRatePerSample = 0.1; epochTime=8.45629s
08/19/2016 14:56:30: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/models/simple.dnn.9'

08/19/2016 14:56:30: Starting Epoch 10: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 10: samples [90000..100000] (first sequence at sample 90000), worker rank 0, total workers 1

08/19/2016 14:56:30: Starting minibatch loop.
08/19/2016 14:56:31:  Epoch[10 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.19219271 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 1.1077s; samplesPerSecond = 1155.5
08/19/2016 14:56:32:  Epoch[10 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15465158 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 1.1287s; samplesPerSecond = 1134.0
08/19/2016 14:56:33:  Epoch[10 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17315254 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 1.1320s; samplesPerSecond = 1130.8
08/19/2016 14:56:35:  Epoch[10 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15401797 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 1.1563s; samplesPerSecond = 1107.0
08/19/2016 14:56:36:  Epoch[10 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.22233386 * 1280; EvalErrorPrediction = 0.09609375 * 1280; time = 1.1573s; samplesPerSecond = 1106.0
08/19/2016 14:56:37:  Epoch[10 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17278605 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 1.1538s; samplesPerSecond = 1109.4
08/19/2016 14:56:38:  Epoch[10 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18744640 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 1.1546s; samplesPerSecond = 1108.6
08/19/2016 14:56:39: Finished Epoch[10 of 50]: [Training] CrossEntropyWithSoftmax = 0.17763798 * 10000; EvalErrorPrediction = 0.07900000 * 10000; totalSamplesSeen = 100000; learningRatePerSample = 0.1; epochTime=9.11368s
08/19/2016 14:56:39: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/models/simple.dnn.10'

08/19/2016 14:56:39: Starting Epoch 11: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 11: samples [100000..110000] (first sequence at sample 100000), worker rank 0, total workers 1

08/19/2016 14:56:39: Starting minibatch loop.
08/19/2016 14:56:40:  Epoch[11 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.18563154 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 1.1774s; samplesPerSecond = 1087.1
08/19/2016 14:56:42:  Epoch[11 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16324418 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 1.1909s; samplesPerSecond = 1074.8
08/19/2016 14:56:43:  Epoch[11 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16656928 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 1.1880s; samplesPerSecond = 1077.4
08/19/2016 14:56:44:  Epoch[11 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16170974 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 1.2083s; samplesPerSecond = 1059.4
08/19/2016 14:56:45:  Epoch[11 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15505877 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 1.2171s; samplesPerSecond = 1051.7
08/19/2016 14:56:46:  Epoch[11 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14944458 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 1.2584s; samplesPerSecond = 1017.1
08/19/2016 14:56:48:  Epoch[11 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14352760 * 1280; EvalErrorPrediction = 0.06250000 * 1280; time = 1.2289s; samplesPerSecond = 1041.6
08/19/2016 14:56:49: Finished Epoch[11 of 50]: [Training] CrossEntropyWithSoftmax = 0.16358132 * 10000; EvalErrorPrediction = 0.07530000 * 10000; totalSamplesSeen = 110000; learningRatePerSample = 0.1; epochTime=9.62638s
08/19/2016 14:56:49: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/models/simple.dnn.11'

08/19/2016 14:56:49: Starting Epoch 12: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 12: samples [110000..120000] (first sequence at sample 110000), worker rank 0, total workers 1

08/19/2016 14:56:49: Starting minibatch loop.
08/19/2016 14:56:50:  Epoch[12 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.19218025 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 1.2895s; samplesPerSecond = 992.6
08/19/2016 14:56:51:  Epoch[12 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16834052 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 1.2662s; samplesPerSecond = 1010.9
08/19/2016 14:56:53:  Epoch[12 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17563388 * 1280; EvalErrorPrediction = 0.08906250 * 1280; time = 1.2770s; samplesPerSecond = 1002.4
08/19/2016 14:56:54:  Epoch[12 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17781725 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 1.2985s; samplesPerSecond = 985.8
08/19/2016 14:56:55:  Epoch[12 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15833340 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 1.3094s; samplesPerSecond = 977.6
08/19/2016 14:56:57:  Epoch[12 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16590996 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 1.3122s; samplesPerSecond = 975.5
08/19/2016 14:56:58:  Epoch[12 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14364977 * 1280; EvalErrorPrediction = 0.06406250 * 1280; time = 1.3135s; samplesPerSecond = 974.5
08/19/2016 14:56:59: Finished Epoch[12 of 50]: [Training] CrossEntropyWithSoftmax = 0.16857529 * 10000; EvalErrorPrediction = 0.08060000 * 10000; totalSamplesSeen = 120000; learningRatePerSample = 0.1; epochTime=10.2892s
08/19/2016 14:56:59: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/models/simple.dnn.12'

08/19/2016 14:56:59: Starting Epoch 13: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 13: samples [120000..130000] (first sequence at sample 120000), worker rank 0, total workers 1

08/19/2016 14:56:59: Starting minibatch loop.
08/19/2016 14:57:00:  Epoch[13 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15128603 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 1.3276s; samplesPerSecond = 964.1
08/19/2016 14:57:02:  Epoch[13 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17994967 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 1.3729s; samplesPerSecond = 932.3
08/19/2016 14:57:03:  Epoch[13 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.18206768 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 1.3504s; samplesPerSecond = 947.9
08/19/2016 14:57:05:  Epoch[13 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14708014 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 1.3582s; samplesPerSecond = 942.4
08/19/2016 14:57:06:  Epoch[13 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16766205 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 1.3745s; samplesPerSecond = 931.2
08/19/2016 14:57:07:  Epoch[13 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17110033 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 1.3697s; samplesPerSecond = 934.5
08/19/2016 14:57:09:  Epoch[13 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15526752 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 1.3796s; samplesPerSecond = 927.8
08/19/2016 14:57:10: Finished Epoch[13 of 50]: [Training] CrossEntropyWithSoftmax = 0.16543713 * 10000; EvalErrorPrediction = 0.07730000 * 10000; totalSamplesSeen = 130000; learningRatePerSample = 0.1; epochTime=10.8004s
08/19/2016 14:57:10: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/models/simple.dnn.13'

08/19/2016 14:57:10: Starting Epoch 14: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 14: samples [130000..140000] (first sequence at sample 130000), worker rank 0, total workers 1

08/19/2016 14:57:10: Starting minibatch loop.
08/19/2016 14:57:11:  Epoch[14 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.21896849 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 1.4083s; samplesPerSecond = 908.9
08/19/2016 14:57:13:  Epoch[14 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.21173124 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 1.4326s; samplesPerSecond = 893.5
08/19/2016 14:57:14:  Epoch[14 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.22914400 * 1280; EvalErrorPrediction = 0.08906250 * 1280; time = 1.4465s; samplesPerSecond = 884.9
08/19/2016 14:57:16:  Epoch[14 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.24508562 * 1280; EvalErrorPrediction = 0.09687500 * 1280; time = 1.4478s; samplesPerSecond = 884.1
08/19/2016 14:57:17:  Epoch[14 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.20996094 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 1.4823s; samplesPerSecond = 863.5
08/19/2016 14:57:19:  Epoch[14 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15946674 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 1.4430s; samplesPerSecond = 887.1
08/19/2016 14:57:20:  Epoch[14 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16174555 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 1.4455s; samplesPerSecond = 885.5
08/19/2016 14:57:21: Finished Epoch[14 of 50]: [Training] CrossEntropyWithSoftmax = 0.20097520 * 10000; EvalErrorPrediction = 0.08110000 * 10000; totalSamplesSeen = 140000; learningRatePerSample = 0.1; epochTime=11.4429s
08/19/2016 14:57:21: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/models/simple.dnn.14'

08/19/2016 14:57:21: Starting Epoch 15: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 15: samples [140000..150000] (first sequence at sample 140000), worker rank 0, total workers 1

08/19/2016 14:57:21: Starting minibatch loop.
08/19/2016 14:57:23:  Epoch[15 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16884087 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 1.4707s; samplesPerSecond = 870.3
08/19/2016 14:57:24:  Epoch[15 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14230670 * 1280; EvalErrorPrediction = 0.06562500 * 1280; time = 1.5091s; samplesPerSecond = 848.2
08/19/2016 14:57:26:  Epoch[15 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17886117 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 1.4906s; samplesPerSecond = 858.7
08/19/2016 14:57:27:  Epoch[15 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16692190 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 1.5002s; samplesPerSecond = 853.2
08/19/2016 14:57:29:  Epoch[15 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18277912 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 1.5284s; samplesPerSecond = 837.5
08/19/2016 14:57:30:  Epoch[15 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16112318 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 1.5208s; samplesPerSecond = 841.7
08/19/2016 14:57:32:  Epoch[15 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15517721 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 1.5268s; samplesPerSecond = 838.3
08/19/2016 14:57:33: Finished Epoch[15 of 50]: [Training] CrossEntropyWithSoftmax = 0.16386920 * 10000; EvalErrorPrediction = 0.07500000 * 10000; totalSamplesSeen = 150000; learningRatePerSample = 0.1; epochTime=11.9326s
08/19/2016 14:57:33: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/models/simple.dnn.15'

08/19/2016 14:57:33: Starting Epoch 16: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 16: samples [150000..160000] (first sequence at sample 150000), worker rank 0, total workers 1

08/19/2016 14:57:33: Starting minibatch loop.
08/19/2016 14:57:35:  Epoch[16 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16801599 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 1.5730s; samplesPerSecond = 813.7
08/19/2016 14:57:37:  Epoch[16 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15308295 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 1.5751s; samplesPerSecond = 812.7
08/19/2016 14:57:38:  Epoch[16 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.18203158 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 1.5551s; samplesPerSecond = 823.1
08/19/2016 14:57:40:  Epoch[16 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.19762783 * 1280; EvalErrorPrediction = 0.08828125 * 1280; time = 1.6037s; samplesPerSecond = 798.2
08/19/2016 14:57:41:  Epoch[16 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.19891701 * 1280; EvalErrorPrediction = 0.09140625 * 1280; time = 1.5899s; samplesPerSecond = 805.1
08/19/2016 14:57:43:  Epoch[16 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.19651556 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 1.5944s; samplesPerSecond = 802.8
08/19/2016 14:57:44:  Epoch[16 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.21214323 * 1280; EvalErrorPrediction = 0.09843750 * 1280; time = 1.5945s; samplesPerSecond = 802.8
08/19/2016 14:57:46: Finished Epoch[16 of 50]: [Training] CrossEntropyWithSoftmax = 0.18779862 * 10000; EvalErrorPrediction = 0.08370000 * 10000; totalSamplesSeen = 160000; learningRatePerSample = 0.1; epochTime=12.5255s
08/19/2016 14:57:46: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/models/simple.dnn.16'

08/19/2016 14:57:46: Starting Epoch 17: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 17: samples [160000..170000] (first sequence at sample 160000), worker rank 0, total workers 1

08/19/2016 14:57:46: Starting minibatch loop.
08/19/2016 14:57:48:  Epoch[17 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.18665776 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 1.6206s; samplesPerSecond = 789.8
08/19/2016 14:57:49:  Epoch[17 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.19373622 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 1.6496s; samplesPerSecond = 776.0
08/19/2016 14:57:51:  Epoch[17 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.20847716 * 1280; EvalErrorPrediction = 0.09531250 * 1280; time = 1.6501s; samplesPerSecond = 775.7
08/19/2016 14:57:52:  Epoch[17 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17158852 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 1.6401s; samplesPerSecond = 780.4
08/19/2016 14:57:54:  Epoch[17 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17117295 * 1280; EvalErrorPrediction = 0.08828125 * 1280; time = 1.6526s; samplesPerSecond = 774.5
08/19/2016 14:57:56:  Epoch[17 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17139359 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 1.6757s; samplesPerSecond = 763.9
08/19/2016 14:57:57:  Epoch[17 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16966114 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 1.6585s; samplesPerSecond = 771.8
08/19/2016 14:57:59: Finished Epoch[17 of 50]: [Training] CrossEntropyWithSoftmax = 0.18154399 * 10000; EvalErrorPrediction = 0.08240000 * 10000; totalSamplesSeen = 170000; learningRatePerSample = 0.1; epochTime=13.0459s
08/19/2016 14:57:59: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/models/simple.dnn.17'

08/19/2016 14:57:59: Starting Epoch 18: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 18: samples [170000..180000] (first sequence at sample 170000), worker rank 0, total workers 1

08/19/2016 14:57:59: Starting minibatch loop.
08/19/2016 14:58:01:  Epoch[18 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15839394 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 1.7464s; samplesPerSecond = 733.0
08/19/2016 14:58:02:  Epoch[18 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16292149 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 1.6984s; samplesPerSecond = 753.7
08/19/2016 14:58:04:  Epoch[18 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16794109 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 1.7131s; samplesPerSecond = 747.2
08/19/2016 14:58:06:  Epoch[18 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15814919 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 1.7179s; samplesPerSecond = 745.1
08/19/2016 14:58:08:  Epoch[18 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15214424 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 1.7299s; samplesPerSecond = 739.9
08/19/2016 14:58:09:  Epoch[18 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15942898 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 1.7340s; samplesPerSecond = 738.2
08/19/2016 14:58:11:  Epoch[18 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15782070 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 1.7487s; samplesPerSecond = 732.0
08/19/2016 14:58:13: Finished Epoch[18 of 50]: [Training] CrossEntropyWithSoftmax = 0.15980394 * 10000; EvalErrorPrediction = 0.07450000 * 10000; totalSamplesSeen = 180000; learningRatePerSample = 0.1; epochTime=13.6728s
08/19/2016 14:58:13: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/models/simple.dnn.18'

08/19/2016 14:58:13: Starting Epoch 19: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 19: samples [180000..190000] (first sequence at sample 180000), worker rank 0, total workers 1

08/19/2016 14:58:13: Starting minibatch loop.
08/19/2016 14:58:14:  Epoch[19 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15393734 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 1.7561s; samplesPerSecond = 728.9
08/19/2016 14:58:16:  Epoch[19 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14663672 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 1.7672s; samplesPerSecond = 724.3
08/19/2016 14:58:18:  Epoch[19 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16556649 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 1.7888s; samplesPerSecond = 715.5
08/19/2016 14:58:20:  Epoch[19 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15092320 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 1.8174s; samplesPerSecond = 704.3
08/19/2016 14:58:22:  Epoch[19 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18201089 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 1.7989s; samplesPerSecond = 711.6
08/19/2016 14:58:23:  Epoch[19 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16243162 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 1.8119s; samplesPerSecond = 706.5
08/19/2016 14:58:25:  Epoch[19 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17175312 * 1280; EvalErrorPrediction = 0.08984375 * 1280; time = 1.8127s; samplesPerSecond = 706.1
08/19/2016 14:58:27: Finished Epoch[19 of 50]: [Training] CrossEntropyWithSoftmax = 0.16262649 * 10000; EvalErrorPrediction = 0.07780000 * 10000; totalSamplesSeen = 190000; learningRatePerSample = 0.1; epochTime=14.1977s
08/19/2016 14:58:27: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/models/simple.dnn.19'

08/19/2016 14:58:27: Starting Epoch 20: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 20: samples [190000..200000] (first sequence at sample 190000), worker rank 0, total workers 1

08/19/2016 14:58:27: Starting minibatch loop.
08/19/2016 14:58:29:  Epoch[20 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16131891 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 1.8301s; samplesPerSecond = 699.4
08/19/2016 14:58:31:  Epoch[20 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16551570 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 1.8358s; samplesPerSecond = 697.2
08/19/2016 14:58:32:  Epoch[20 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16214778 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 1.8457s; samplesPerSecond = 693.5
08/19/2016 14:58:34:  Epoch[20 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17391610 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 1.8519s; samplesPerSecond = 691.2
08/19/2016 14:58:36:  Epoch[20 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16826520 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 1.8488s; samplesPerSecond = 692.3
08/19/2016 14:58:38:  Epoch[20 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15876560 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 1.9111s; samplesPerSecond = 669.8
08/19/2016 14:58:40:  Epoch[20 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16728592 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 1.8767s; samplesPerSecond = 682.1
08/19/2016 14:58:42: Finished Epoch[20 of 50]: [Training] CrossEntropyWithSoftmax = 0.16359941 * 10000; EvalErrorPrediction = 0.07680000 * 10000; totalSamplesSeen = 200000; learningRatePerSample = 0.1; epochTime=14.7245s
08/19/2016 14:58:42: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/models/simple.dnn.20'

08/19/2016 14:58:42: Starting Epoch 21: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 21: samples [200000..210000] (first sequence at sample 200000), worker rank 0, total workers 1

08/19/2016 14:58:42: Starting minibatch loop.
08/19/2016 14:58:44:  Epoch[21 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16337178 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 1.9328s; samplesPerSecond = 662.3
08/19/2016 14:58:45:  Epoch[21 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14521406 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 1.9116s; samplesPerSecond = 669.6
08/19/2016 14:58:47:  Epoch[21 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15791101 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 1.9567s; samplesPerSecond = 654.2
08/19/2016 14:58:49:  Epoch[21 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14245071 * 1280; EvalErrorPrediction = 0.06484375 * 1280; time = 1.9368s; samplesPerSecond = 660.9
08/19/2016 14:58:51:  Epoch[21 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16054139 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 1.9624s; samplesPerSecond = 652.3
08/19/2016 14:58:53:  Epoch[21 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16650777 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 1.9509s; samplesPerSecond = 656.1
08/19/2016 14:58:55:  Epoch[21 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16315174 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 1.9500s; samplesPerSecond = 656.4
08/19/2016 14:58:57: Finished Epoch[21 of 50]: [Training] CrossEntropyWithSoftmax = 0.15772710 * 10000; EvalErrorPrediction = 0.07760000 * 10000; totalSamplesSeen = 210000; learningRatePerSample = 0.1; epochTime=15.392s
08/19/2016 14:58:57: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/models/simple.dnn.21'

08/19/2016 14:58:57: Starting Epoch 22: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 22: samples [210000..220000] (first sequence at sample 210000), worker rank 0, total workers 1

08/19/2016 14:58:57: Starting minibatch loop.
08/19/2016 14:58:59:  Epoch[22 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15215902 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 1.9628s; samplesPerSecond = 652.1
08/19/2016 14:59:01:  Epoch[22 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13743286 * 1280; EvalErrorPrediction = 0.06171875 * 1280; time = 1.9866s; samplesPerSecond = 644.3
08/19/2016 14:59:03:  Epoch[22 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16303315 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 1.9949s; samplesPerSecond = 641.6
08/19/2016 14:59:05:  Epoch[22 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16213331 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 2.0122s; samplesPerSecond = 636.1
08/19/2016 14:59:07:  Epoch[22 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15396910 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 2.0239s; samplesPerSecond = 632.4
08/19/2016 14:59:09:  Epoch[22 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14866014 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 2.0507s; samplesPerSecond = 624.2
08/19/2016 14:59:11:  Epoch[22 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18067427 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 2.0477s; samplesPerSecond = 625.1
08/19/2016 14:59:13: Finished Epoch[22 of 50]: [Training] CrossEntropyWithSoftmax = 0.15909163 * 10000; EvalErrorPrediction = 0.07480000 * 10000; totalSamplesSeen = 220000; learningRatePerSample = 0.1; epochTime=15.9242s
08/19/2016 14:59:13: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/models/simple.dnn.22'

08/19/2016 14:59:13: Starting Epoch 23: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 23: samples [220000..230000] (first sequence at sample 220000), worker rank 0, total workers 1

08/19/2016 14:59:13: Starting minibatch loop.
08/19/2016 14:59:15:  Epoch[23 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17811930 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 2.0662s; samplesPerSecond = 619.5
08/19/2016 14:59:17:  Epoch[23 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17204502 * 1280; EvalErrorPrediction = 0.09140625 * 1280; time = 2.0436s; samplesPerSecond = 626.3
08/19/2016 14:59:19:  Epoch[23 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15119953 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 2.1051s; samplesPerSecond = 608.1
08/19/2016 14:59:21:  Epoch[23 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17851715 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 2.0885s; samplesPerSecond = 612.9
08/19/2016 14:59:23:  Epoch[23 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15495739 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 2.0583s; samplesPerSecond = 621.9
08/19/2016 14:59:25:  Epoch[23 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16573563 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 2.1428s; samplesPerSecond = 597.3
08/19/2016 14:59:28:  Epoch[23 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15394459 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 2.1296s; samplesPerSecond = 601.0
08/19/2016 14:59:29: Finished Epoch[23 of 50]: [Training] CrossEntropyWithSoftmax = 0.16411897 * 10000; EvalErrorPrediction = 0.07810000 * 10000; totalSamplesSeen = 230000; learningRatePerSample = 0.1; epochTime=16.533s
08/19/2016 14:59:30: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/models/simple.dnn.23'

08/19/2016 14:59:30: Starting Epoch 24: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 24: samples [230000..240000] (first sequence at sample 230000), worker rank 0, total workers 1

08/19/2016 14:59:30: Starting minibatch loop.
08/19/2016 14:59:32:  Epoch[24 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16390244 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 2.1265s; samplesPerSecond = 601.9
08/19/2016 14:59:34:  Epoch[24 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17473849 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 2.1394s; samplesPerSecond = 598.3
08/19/2016 14:59:36:  Epoch[24 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14501152 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 2.1393s; samplesPerSecond = 598.3
08/19/2016 14:59:38:  Epoch[24 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.12699533 * 1280; EvalErrorPrediction = 0.05781250 * 1280; time = 2.1895s; samplesPerSecond = 584.6
08/19/2016 14:59:40:  Epoch[24 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18086944 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 2.1620s; samplesPerSecond = 592.1
08/19/2016 14:59:42:  Epoch[24 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13314519 * 1280; EvalErrorPrediction = 0.05937500 * 1280; time = 2.1781s; samplesPerSecond = 587.7
08/19/2016 14:59:45:  Epoch[24 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15527363 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 2.2160s; samplesPerSecond = 577.6
08/19/2016 14:59:47: Finished Epoch[24 of 50]: [Training] CrossEntropyWithSoftmax = 0.15476786 * 10000; EvalErrorPrediction = 0.07410000 * 10000; totalSamplesSeen = 240000; learningRatePerSample = 0.1; epochTime=17.1543s
08/19/2016 14:59:47: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/models/simple.dnn.24'

08/19/2016 14:59:47: Starting Epoch 25: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 25: samples [240000..250000] (first sequence at sample 240000), worker rank 0, total workers 1

08/19/2016 14:59:47: Starting minibatch loop.
08/19/2016 14:59:49:  Epoch[25 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.13738270 * 1280; EvalErrorPrediction = 0.06250000 * 1280; time = 2.2213s; samplesPerSecond = 576.2
08/19/2016 14:59:51:  Epoch[25 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17391899 * 1280; EvalErrorPrediction = 0.09218750 * 1280; time = 2.2033s; samplesPerSecond = 580.9
08/19/2016 14:59:53:  Epoch[25 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14000723 * 1280; EvalErrorPrediction = 0.06640625 * 1280; time = 2.2252s; samplesPerSecond = 575.2
08/19/2016 14:59:56:  Epoch[25 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15249629 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 2.2241s; samplesPerSecond = 575.5
08/19/2016 14:59:58:  Epoch[25 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17014837 * 1280; EvalErrorPrediction = 0.08828125 * 1280; time = 2.2685s; samplesPerSecond = 564.3
08/19/2016 15:00:00:  Epoch[25 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17271819 * 1280; EvalErrorPrediction = 0.08828125 * 1280; time = 2.2628s; samplesPerSecond = 565.7
08/19/2016 15:00:02:  Epoch[25 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18484859 * 1280; EvalErrorPrediction = 0.10078125 * 1280; time = 2.2734s; samplesPerSecond = 563.0
08/19/2016 15:00:04: Finished Epoch[25 of 50]: [Training] CrossEntropyWithSoftmax = 0.16432645 * 10000; EvalErrorPrediction = 0.08380000 * 10000; totalSamplesSeen = 250000; learningRatePerSample = 0.1; epochTime=17.7006s
08/19/2016 15:00:04: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/models/simple.dnn.25'

08/19/2016 15:00:04: Starting Epoch 26: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 26: samples [250000..260000] (first sequence at sample 250000), worker rank 0, total workers 1

08/19/2016 15:00:04: Starting minibatch loop.
08/19/2016 15:00:07:  Epoch[26 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17241586 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 2.2918s; samplesPerSecond = 558.5
08/19/2016 15:00:09:  Epoch[26 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.21459781 * 1280; EvalErrorPrediction = 0.09375000 * 1280; time = 2.3187s; samplesPerSecond = 552.0
08/19/2016 15:00:11:  Epoch[26 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16780243 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 2.3082s; samplesPerSecond = 554.5
08/19/2016 15:00:14:  Epoch[26 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15440912 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 2.3429s; samplesPerSecond = 546.3
08/19/2016 15:00:16:  Epoch[26 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16801772 * 1280; EvalErrorPrediction = 0.09140625 * 1280; time = 2.3274s; samplesPerSecond = 550.0
08/19/2016 15:00:18:  Epoch[26 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.12417860 * 1280; EvalErrorPrediction = 0.05312500 * 1280; time = 2.3435s; samplesPerSecond = 546.2
08/19/2016 15:00:21:  Epoch[26 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16505766 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 2.3474s; samplesPerSecond = 545.3
08/19/2016 15:00:23: Finished Epoch[26 of 50]: [Training] CrossEntropyWithSoftmax = 0.16583290 * 10000; EvalErrorPrediction = 0.08000000 * 10000; totalSamplesSeen = 260000; learningRatePerSample = 0.1; epochTime=18.3918s
08/19/2016 15:00:23: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/models/simple.dnn.26'

08/19/2016 15:00:23: Starting Epoch 27: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 27: samples [260000..270000] (first sequence at sample 260000), worker rank 0, total workers 1

08/19/2016 15:00:23: Starting minibatch loop.
08/19/2016 15:00:25:  Epoch[27 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16580271 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 2.3407s; samplesPerSecond = 546.8
08/19/2016 15:00:28:  Epoch[27 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16926092 * 1280; EvalErrorPrediction = 0.09296875 * 1280; time = 2.4010s; samplesPerSecond = 533.1
08/19/2016 15:00:30:  Epoch[27 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14731348 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 2.3915s; samplesPerSecond = 535.2
08/19/2016 15:00:32:  Epoch[27 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16390576 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 2.3861s; samplesPerSecond = 536.4
08/19/2016 15:00:35:  Epoch[27 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17031822 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 2.4038s; samplesPerSecond = 532.5
08/19/2016 15:00:37:  Epoch[27 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16041813 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 2.3979s; samplesPerSecond = 533.8
08/19/2016 15:00:40:  Epoch[27 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17107611 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 2.3925s; samplesPerSecond = 535.0
08/19/2016 15:00:42: Finished Epoch[27 of 50]: [Training] CrossEntropyWithSoftmax = 0.16272667 * 10000; EvalErrorPrediction = 0.07950000 * 10000; totalSamplesSeen = 270000; learningRatePerSample = 0.1; epochTime=18.898s
08/19/2016 15:00:42: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/models/simple.dnn.27'

08/19/2016 15:00:42: Starting Epoch 28: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 28: samples [270000..280000] (first sequence at sample 270000), worker rank 0, total workers 1

08/19/2016 15:00:42: Starting minibatch loop.
08/19/2016 15:00:44:  Epoch[28 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15708725 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 2.3962s; samplesPerSecond = 534.2
08/19/2016 15:00:47:  Epoch[28 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16087668 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 2.4482s; samplesPerSecond = 522.8
08/19/2016 15:00:49:  Epoch[28 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16611686 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 2.4359s; samplesPerSecond = 525.5
08/19/2016 15:00:51:  Epoch[28 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14507895 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 2.4739s; samplesPerSecond = 517.4
08/19/2016 15:00:54:  Epoch[28 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14170361 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 2.4706s; samplesPerSecond = 518.1
08/19/2016 15:00:56:  Epoch[28 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15535679 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 2.4651s; samplesPerSecond = 519.2
08/19/2016 15:00:59:  Epoch[28 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16406012 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 2.5507s; samplesPerSecond = 501.8
08/19/2016 15:01:01: Finished Epoch[28 of 50]: [Training] CrossEntropyWithSoftmax = 0.15698973 * 10000; EvalErrorPrediction = 0.07960000 * 10000; totalSamplesSeen = 280000; learningRatePerSample = 0.1; epochTime=19.4619s
08/19/2016 15:01:01: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/models/simple.dnn.28'

08/19/2016 15:01:01: Starting Epoch 29: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 29: samples [280000..290000] (first sequence at sample 280000), worker rank 0, total workers 1

08/19/2016 15:01:01: Starting minibatch loop.
08/19/2016 15:01:04:  Epoch[29 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15682987 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 2.5124s; samplesPerSecond = 509.5
08/19/2016 15:01:06:  Epoch[29 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13538409 * 1280; EvalErrorPrediction = 0.06484375 * 1280; time = 2.5191s; samplesPerSecond = 508.1
08/19/2016 15:01:09:  Epoch[29 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17439880 * 1280; EvalErrorPrediction = 0.09453125 * 1280; time = 2.5414s; samplesPerSecond = 503.7
08/19/2016 15:01:11:  Epoch[29 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14585319 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 2.5164s; samplesPerSecond = 508.7
08/19/2016 15:01:14:  Epoch[29 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16546826 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 2.5119s; samplesPerSecond = 509.6
08/19/2016 15:01:16:  Epoch[29 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14468045 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 2.5632s; samplesPerSecond = 499.4
08/19/2016 15:01:19:  Epoch[29 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16794758 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 2.5152s; samplesPerSecond = 508.9
08/19/2016 15:01:21: Finished Epoch[29 of 50]: [Training] CrossEntropyWithSoftmax = 0.16054127 * 10000; EvalErrorPrediction = 0.08080000 * 10000; totalSamplesSeen = 290000; learningRatePerSample = 0.1; epochTime=20.0687s
08/19/2016 15:01:21: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/models/simple.dnn.29'

08/19/2016 15:01:21: Starting Epoch 30: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 30: samples [290000..300000] (first sequence at sample 290000), worker rank 0, total workers 1

08/19/2016 15:01:21: Starting minibatch loop.
08/19/2016 15:01:24:  Epoch[30 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15940990 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 2.5682s; samplesPerSecond = 498.4
08/19/2016 15:01:26:  Epoch[30 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15095575 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 2.5775s; samplesPerSecond = 496.6
08/19/2016 15:01:29:  Epoch[30 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14840562 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 2.6328s; samplesPerSecond = 486.2
08/19/2016 15:01:32:  Epoch[30 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16832032 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 2.5980s; samplesPerSecond = 492.7
08/19/2016 15:01:34:  Epoch[30 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15944853 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 2.6035s; samplesPerSecond = 491.6
08/19/2016 15:01:37:  Epoch[30 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16040373 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 2.5867s; samplesPerSecond = 494.8
08/19/2016 15:01:39:  Epoch[30 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16300545 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 2.6090s; samplesPerSecond = 490.6
08/19/2016 15:01:42: Finished Epoch[30 of 50]: [Training] CrossEntropyWithSoftmax = 0.15703723 * 10000; EvalErrorPrediction = 0.08010000 * 10000; totalSamplesSeen = 300000; learningRatePerSample = 0.1; epochTime=20.5366s
08/19/2016 15:01:42: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/models/simple.dnn.30'

08/19/2016 15:01:42: Starting Epoch 31: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 31: samples [300000..310000] (first sequence at sample 300000), worker rank 0, total workers 1

08/19/2016 15:01:42: Starting minibatch loop.
08/19/2016 15:01:44:  Epoch[31 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16174891 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 2.6849s; samplesPerSecond = 476.7
08/19/2016 15:01:47:  Epoch[31 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15350633 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 2.7402s; samplesPerSecond = 467.1
08/19/2016 15:01:50:  Epoch[31 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15347884 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 2.6549s; samplesPerSecond = 482.1
08/19/2016 15:01:53:  Epoch[31 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14529233 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 2.7151s; samplesPerSecond = 471.4
08/19/2016 15:01:55:  Epoch[31 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16926942 * 1280; EvalErrorPrediction = 0.08515625 * 1280; time = 2.7387s; samplesPerSecond = 467.4
08/19/2016 15:01:58:  Epoch[31 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13906202 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 2.6894s; samplesPerSecond = 475.9
08/19/2016 15:02:01:  Epoch[31 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15153503 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 2.7391s; samplesPerSecond = 467.3
08/19/2016 15:02:03: Finished Epoch[31 of 50]: [Training] CrossEntropyWithSoftmax = 0.15330370 * 10000; EvalErrorPrediction = 0.07790000 * 10000; totalSamplesSeen = 310000; learningRatePerSample = 0.1; epochTime=21.4243s
08/19/2016 15:02:03: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/models/simple.dnn.31'

08/19/2016 15:02:03: Starting Epoch 32: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 32: samples [310000..320000] (first sequence at sample 310000), worker rank 0, total workers 1

08/19/2016 15:02:03: Starting minibatch loop.
08/19/2016 15:02:06:  Epoch[32 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15779847 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 2.7299s; samplesPerSecond = 468.9
08/19/2016 15:02:09:  Epoch[32 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14719065 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 2.8386s; samplesPerSecond = 450.9
08/19/2016 15:02:12:  Epoch[32 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14815099 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 2.7454s; samplesPerSecond = 466.2
08/19/2016 15:02:14:  Epoch[32 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15589519 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 2.7330s; samplesPerSecond = 468.3
08/19/2016 15:02:17:  Epoch[32 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15082564 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 2.7500s; samplesPerSecond = 465.5
08/19/2016 15:02:20:  Epoch[32 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15918651 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 2.7934s; samplesPerSecond = 458.2
08/19/2016 15:02:23:  Epoch[32 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15812445 * 1280; EvalErrorPrediction = 0.08515625 * 1280; time = 2.7887s; samplesPerSecond = 459.0
08/19/2016 15:02:25: Finished Epoch[32 of 50]: [Training] CrossEntropyWithSoftmax = 0.15583115 * 10000; EvalErrorPrediction = 0.07920000 * 10000; totalSamplesSeen = 320000; learningRatePerSample = 0.1; epochTime=21.8625s
08/19/2016 15:02:25: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/models/simple.dnn.32'

08/19/2016 15:02:25: Starting Epoch 33: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 33: samples [320000..330000] (first sequence at sample 320000), worker rank 0, total workers 1

08/19/2016 15:02:25: Starting minibatch loop.
08/19/2016 15:02:28:  Epoch[33 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16428367 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 2.8019s; samplesPerSecond = 456.8
08/19/2016 15:02:31:  Epoch[33 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17547854 * 1280; EvalErrorPrediction = 0.09140625 * 1280; time = 2.8371s; samplesPerSecond = 451.2
08/19/2016 15:02:34:  Epoch[33 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15117326 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 2.8387s; samplesPerSecond = 450.9
08/19/2016 15:02:36:  Epoch[33 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15776572 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 2.7892s; samplesPerSecond = 458.9
08/19/2016 15:02:39:  Epoch[33 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.13862433 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 2.8504s; samplesPerSecond = 449.1
08/19/2016 15:02:42:  Epoch[33 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14410987 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 2.8040s; samplesPerSecond = 456.5
08/19/2016 15:02:45:  Epoch[33 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16480970 * 1280; EvalErrorPrediction = 0.08984375 * 1280; time = 2.8324s; samplesPerSecond = 451.9
08/19/2016 15:02:47: Finished Epoch[33 of 50]: [Training] CrossEntropyWithSoftmax = 0.15588053 * 10000; EvalErrorPrediction = 0.08000000 * 10000; totalSamplesSeen = 330000; learningRatePerSample = 0.1; epochTime=22.371s
08/19/2016 15:02:47: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/models/simple.dnn.33'

08/19/2016 15:02:48: Starting Epoch 34: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 34: samples [330000..340000] (first sequence at sample 330000), worker rank 0, total workers 1

08/19/2016 15:02:48: Starting minibatch loop.
08/19/2016 15:02:50:  Epoch[34 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14668400 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 2.9028s; samplesPerSecond = 440.9
08/19/2016 15:02:53:  Epoch[34 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15635211 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 2.8953s; samplesPerSecond = 442.1
08/19/2016 15:02:56:  Epoch[34 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15694470 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 2.9198s; samplesPerSecond = 438.4
08/19/2016 15:02:59:  Epoch[34 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14793911 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 2.9013s; samplesPerSecond = 441.2
08/19/2016 15:03:02:  Epoch[34 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16622338 * 1280; EvalErrorPrediction = 0.09062500 * 1280; time = 2.9951s; samplesPerSecond = 427.4
08/19/2016 15:03:05:  Epoch[34 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16044922 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 2.9103s; samplesPerSecond = 439.8
08/19/2016 15:03:08:  Epoch[34 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15663633 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 2.9554s; samplesPerSecond = 433.1
08/19/2016 15:03:11: Finished Epoch[34 of 50]: [Training] CrossEntropyWithSoftmax = 0.15421027 * 10000; EvalErrorPrediction = 0.07950000 * 10000; totalSamplesSeen = 340000; learningRatePerSample = 0.1; epochTime=23.0723s
08/19/2016 15:03:11: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/models/simple.dnn.34'

08/19/2016 15:03:11: Starting Epoch 35: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 35: samples [340000..350000] (first sequence at sample 340000), worker rank 0, total workers 1

08/19/2016 15:03:11: Starting minibatch loop.
08/19/2016 15:03:14:  Epoch[35 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16275177 * 1280; EvalErrorPrediction = 0.09218750 * 1280; time = 2.9900s; samplesPerSecond = 428.1
08/19/2016 15:03:17:  Epoch[35 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14439979 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 2.9684s; samplesPerSecond = 431.2
08/19/2016 15:03:20:  Epoch[35 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14823351 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 2.9816s; samplesPerSecond = 429.3
08/19/2016 15:03:23:  Epoch[35 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14811802 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 3.0362s; samplesPerSecond = 421.6
08/19/2016 15:03:26:  Epoch[35 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14211264 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 3.0514s; samplesPerSecond = 419.5
08/19/2016 15:03:29:  Epoch[35 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14512029 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 2.9896s; samplesPerSecond = 428.1
08/19/2016 15:03:32:  Epoch[35 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15983896 * 1280; EvalErrorPrediction = 0.09218750 * 1280; time = 3.0551s; samplesPerSecond = 419.0
08/19/2016 15:03:34: Finished Epoch[35 of 50]: [Training] CrossEntropyWithSoftmax = 0.15051914 * 10000; EvalErrorPrediction = 0.07740000 * 10000; totalSamplesSeen = 350000; learningRatePerSample = 0.1; epochTime=23.7791s
08/19/2016 15:03:34: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/models/simple.dnn.35'

08/19/2016 15:03:34: Starting Epoch 36: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 36: samples [350000..360000] (first sequence at sample 350000), worker rank 0, total workers 1

08/19/2016 15:03:34: Starting minibatch loop.
08/19/2016 15:03:37:  Epoch[36 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14918096 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 3.0279s; samplesPerSecond = 422.7
08/19/2016 15:03:40:  Epoch[36 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17718103 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 3.0374s; samplesPerSecond = 421.4
08/19/2016 15:03:43:  Epoch[36 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15503120 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 3.0457s; samplesPerSecond = 420.3
08/19/2016 15:03:47:  Epoch[36 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15608578 * 1280; EvalErrorPrediction = 0.08515625 * 1280; time = 3.0917s; samplesPerSecond = 414.0
08/19/2016 15:03:50:  Epoch[36 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15259948 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 3.0774s; samplesPerSecond = 415.9
08/19/2016 15:03:53:  Epoch[36 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13625984 * 1280; EvalErrorPrediction = 0.06562500 * 1280; time = 3.0928s; samplesPerSecond = 413.9
08/19/2016 15:03:56:  Epoch[36 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14133883 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 3.0661s; samplesPerSecond = 417.5
08/19/2016 15:03:59: Finished Epoch[36 of 50]: [Training] CrossEntropyWithSoftmax = 0.15433691 * 10000; EvalErrorPrediction = 0.07960000 * 10000; totalSamplesSeen = 360000; learningRatePerSample = 0.1; epochTime=24.1834s
08/19/2016 15:03:59: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/models/simple.dnn.36'

08/19/2016 15:03:59: Starting Epoch 37: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 37: samples [360000..370000] (first sequence at sample 360000), worker rank 0, total workers 1

08/19/2016 15:03:59: Starting minibatch loop.
08/19/2016 15:04:02:  Epoch[37 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16840715 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 3.1150s; samplesPerSecond = 410.9
08/19/2016 15:04:05:  Epoch[37 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14221966 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 3.1837s; samplesPerSecond = 402.0
08/19/2016 15:04:08:  Epoch[37 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15075076 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 3.1788s; samplesPerSecond = 402.7
08/19/2016 15:04:11:  Epoch[37 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.12538824 * 1280; EvalErrorPrediction = 0.05703125 * 1280; time = 3.1057s; samplesPerSecond = 412.1
08/19/2016 15:04:14:  Epoch[37 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15709667 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 3.1171s; samplesPerSecond = 410.6
08/19/2016 15:04:17:  Epoch[37 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14256148 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 3.1718s; samplesPerSecond = 403.6
08/19/2016 15:04:21:  Epoch[37 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16219215 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 3.1628s; samplesPerSecond = 404.7
08/19/2016 15:04:23: Finished Epoch[37 of 50]: [Training] CrossEntropyWithSoftmax = 0.14978508 * 10000; EvalErrorPrediction = 0.07560000 * 10000; totalSamplesSeen = 370000; learningRatePerSample = 0.1; epochTime=24.9238s
08/19/2016 15:04:24: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/models/simple.dnn.37'

08/19/2016 15:04:24: Starting Epoch 38: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 38: samples [370000..380000] (first sequence at sample 370000), worker rank 0, total workers 1

08/19/2016 15:04:24: Starting minibatch loop.
08/19/2016 15:04:27:  Epoch[38 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16852400 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 3.1811s; samplesPerSecond = 402.4
08/19/2016 15:04:30:  Epoch[38 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14644649 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 3.2396s; samplesPerSecond = 395.1
08/19/2016 15:04:33:  Epoch[38 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14097185 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 3.2206s; samplesPerSecond = 397.4
08/19/2016 15:04:36:  Epoch[38 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16173840 * 1280; EvalErrorPrediction = 0.08906250 * 1280; time = 3.2465s; samplesPerSecond = 394.3
08/19/2016 15:04:40:  Epoch[38 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.13764353 * 1280; EvalErrorPrediction = 0.06640625 * 1280; time = 3.2291s; samplesPerSecond = 396.4
08/19/2016 15:04:43:  Epoch[38 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15780287 * 1280; EvalErrorPrediction = 0.09062500 * 1280; time = 3.2330s; samplesPerSecond = 395.9
08/19/2016 15:04:46:  Epoch[38 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.13848696 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 3.1775s; samplesPerSecond = 402.8
08/19/2016 15:04:49: Finished Epoch[38 of 50]: [Training] CrossEntropyWithSoftmax = 0.15009196 * 10000; EvalErrorPrediction = 0.07940000 * 10000; totalSamplesSeen = 380000; learningRatePerSample = 0.1; epochTime=25.3964s
08/19/2016 15:04:49: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/models/simple.dnn.38'

08/19/2016 15:04:49: Starting Epoch 39: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 39: samples [380000..390000] (first sequence at sample 380000), worker rank 0, total workers 1

08/19/2016 15:04:49: Starting minibatch loop.
08/19/2016 15:04:52:  Epoch[39 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14604683 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 3.2422s; samplesPerSecond = 394.8
08/19/2016 15:04:55:  Epoch[39 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14160192 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 3.2509s; samplesPerSecond = 393.7
08/19/2016 15:04:59:  Epoch[39 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15177090 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 3.3341s; samplesPerSecond = 383.9
08/19/2016 15:05:02:  Epoch[39 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15482445 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 3.2803s; samplesPerSecond = 390.2
08/19/2016 15:05:05:  Epoch[39 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16664810 * 1280; EvalErrorPrediction = 0.08906250 * 1280; time = 3.2558s; samplesPerSecond = 393.1
08/19/2016 15:05:09:  Epoch[39 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.18570986 * 1280; EvalErrorPrediction = 0.09062500 * 1280; time = 3.3115s; samplesPerSecond = 386.5
08/19/2016 15:05:12:  Epoch[39 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.19005833 * 1280; EvalErrorPrediction = 0.09687500 * 1280; time = 3.3265s; samplesPerSecond = 384.8
08/19/2016 15:05:15: Finished Epoch[39 of 50]: [Training] CrossEntropyWithSoftmax = 0.16020647 * 10000; EvalErrorPrediction = 0.08150000 * 10000; totalSamplesSeen = 390000; learningRatePerSample = 0.1; epochTime=26.0772s
08/19/2016 15:05:15: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/models/simple.dnn.39'

08/19/2016 15:05:15: Starting Epoch 40: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 40: samples [390000..400000] (first sequence at sample 390000), worker rank 0, total workers 1

08/19/2016 15:05:15: Starting minibatch loop.
08/19/2016 15:05:18:  Epoch[40 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.18148730 * 1280; EvalErrorPrediction = 0.09531250 * 1280; time = 3.4186s; samplesPerSecond = 374.4
08/19/2016 15:05:22:  Epoch[40 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15084960 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 3.3622s; samplesPerSecond = 380.7
08/19/2016 15:05:25:  Epoch[40 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15694609 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 3.3059s; samplesPerSecond = 387.2
08/19/2016 15:05:29:  Epoch[40 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15860066 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 3.4093s; samplesPerSecond = 375.4
08/19/2016 15:05:32:  Epoch[40 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16061530 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 3.3646s; samplesPerSecond = 380.4
08/19/2016 15:05:35:  Epoch[40 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16119318 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 3.3855s; samplesPerSecond = 378.1
08/19/2016 15:05:39:  Epoch[40 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14262619 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 3.3877s; samplesPerSecond = 377.8
08/19/2016 15:05:42: Finished Epoch[40 of 50]: [Training] CrossEntropyWithSoftmax = 0.15676719 * 10000; EvalErrorPrediction = 0.07940000 * 10000; totalSamplesSeen = 400000; learningRatePerSample = 0.1; epochTime=26.6773s
08/19/2016 15:05:42: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/models/simple.dnn.40'

08/19/2016 15:05:42: Starting Epoch 41: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 41: samples [400000..410000] (first sequence at sample 400000), worker rank 0, total workers 1

08/19/2016 15:05:42: Starting minibatch loop.
08/19/2016 15:05:45:  Epoch[41 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16488804 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 3.3720s; samplesPerSecond = 379.6
08/19/2016 15:05:48:  Epoch[41 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13255812 * 1280; EvalErrorPrediction = 0.06328125 * 1280; time = 3.3635s; samplesPerSecond = 380.6
08/19/2016 15:05:52:  Epoch[41 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14600101 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 3.5047s; samplesPerSecond = 365.2
08/19/2016 15:05:55:  Epoch[41 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15062561 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 3.3734s; samplesPerSecond = 379.4
08/19/2016 15:05:59:  Epoch[41 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14728317 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 3.5337s; samplesPerSecond = 362.2
08/19/2016 15:06:02:  Epoch[41 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14454322 * 1280; EvalErrorPrediction = 0.06484375 * 1280; time = 3.5226s; samplesPerSecond = 363.4
08/19/2016 15:06:06:  Epoch[41 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15257187 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 3.4312s; samplesPerSecond = 373.1
08/19/2016 15:06:09: Finished Epoch[41 of 50]: [Training] CrossEntropyWithSoftmax = 0.14739475 * 10000; EvalErrorPrediction = 0.07340000 * 10000; totalSamplesSeen = 410000; learningRatePerSample = 0.1; epochTime=27.1923s
08/19/2016 15:06:09: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/models/simple.dnn.41'

08/19/2016 15:06:09: Starting Epoch 42: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 42: samples [410000..420000] (first sequence at sample 410000), worker rank 0, total workers 1

08/19/2016 15:06:09: Starting minibatch loop.
08/19/2016 15:06:12:  Epoch[42 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14051281 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 3.4480s; samplesPerSecond = 371.2
08/19/2016 15:06:16:  Epoch[42 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14012600 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 3.4922s; samplesPerSecond = 366.5
08/19/2016 15:06:19:  Epoch[42 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15302045 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 3.5705s; samplesPerSecond = 358.5
08/19/2016 15:06:23:  Epoch[42 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14769464 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 3.5312s; samplesPerSecond = 362.5
08/19/2016 15:06:27:  Epoch[42 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15725412 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 3.6038s; samplesPerSecond = 355.2
08/19/2016 15:06:30:  Epoch[42 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15916190 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 3.5114s; samplesPerSecond = 364.5
08/19/2016 15:06:34:  Epoch[42 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18247147 * 1280; EvalErrorPrediction = 0.09687500 * 1280; time = 3.5451s; samplesPerSecond = 361.1
08/19/2016 15:06:37: Finished Epoch[42 of 50]: [Training] CrossEntropyWithSoftmax = 0.15401146 * 10000; EvalErrorPrediction = 0.07950000 * 10000; totalSamplesSeen = 420000; learningRatePerSample = 0.1; epochTime=27.8774s
08/19/2016 15:06:37: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/models/simple.dnn.42'

08/19/2016 15:06:37: Starting Epoch 43: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 43: samples [420000..430000] (first sequence at sample 420000), worker rank 0, total workers 1

08/19/2016 15:06:37: Starting minibatch loop.
08/19/2016 15:06:40:  Epoch[43 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16290735 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 3.5399s; samplesPerSecond = 361.6
08/19/2016 15:06:44:  Epoch[43 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.12217880 * 1280; EvalErrorPrediction = 0.06328125 * 1280; time = 3.5079s; samplesPerSecond = 364.9
08/19/2016 15:06:47:  Epoch[43 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14747930 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 3.5864s; samplesPerSecond = 356.9
08/19/2016 15:06:51:  Epoch[43 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15295563 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 3.6713s; samplesPerSecond = 348.7
08/19/2016 15:06:55:  Epoch[43 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15701661 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 3.6538s; samplesPerSecond = 350.3
08/19/2016 15:06:58:  Epoch[43 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14177742 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 3.6671s; samplesPerSecond = 349.1
08/19/2016 15:07:02:  Epoch[43 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17112389 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 3.6490s; samplesPerSecond = 350.8
08/19/2016 15:07:05: Finished Epoch[43 of 50]: [Training] CrossEntropyWithSoftmax = 0.14960372 * 10000; EvalErrorPrediction = 0.07820000 * 10000; totalSamplesSeen = 430000; learningRatePerSample = 0.1; epochTime=28.5604s
08/19/2016 15:07:05: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/models/simple.dnn.43'

08/19/2016 15:07:05: Starting Epoch 44: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 44: samples [430000..440000] (first sequence at sample 430000), worker rank 0, total workers 1

08/19/2016 15:07:05: Starting minibatch loop.
08/19/2016 15:07:09:  Epoch[44 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16002762 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 3.6338s; samplesPerSecond = 352.2
08/19/2016 15:07:13:  Epoch[44 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15523794 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 3.6394s; samplesPerSecond = 351.7
08/19/2016 15:07:16:  Epoch[44 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.13001204 * 1280; EvalErrorPrediction = 0.06171875 * 1280; time = 3.7066s; samplesPerSecond = 345.3
08/19/2016 15:07:20:  Epoch[44 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14640040 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 3.6241s; samplesPerSecond = 353.2
08/19/2016 15:07:24:  Epoch[44 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14898686 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 3.6977s; samplesPerSecond = 346.2
08/19/2016 15:07:27:  Epoch[44 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13171940 * 1280; EvalErrorPrediction = 0.06015625 * 1280; time = 3.7907s; samplesPerSecond = 337.7
08/19/2016 15:07:31:  Epoch[44 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15750570 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 3.7623s; samplesPerSecond = 340.2
08/19/2016 15:07:34: Finished Epoch[44 of 50]: [Training] CrossEntropyWithSoftmax = 0.14805739 * 10000; EvalErrorPrediction = 0.07370000 * 10000; totalSamplesSeen = 440000; learningRatePerSample = 0.1; epochTime=29.0866s
08/19/2016 15:07:34: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/models/simple.dnn.44'

08/19/2016 15:07:34: Starting Epoch 45: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 45: samples [440000..450000] (first sequence at sample 440000), worker rank 0, total workers 1

08/19/2016 15:07:34: Starting minibatch loop.
08/19/2016 15:07:38:  Epoch[45 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17800041 * 1280; EvalErrorPrediction = 0.09453125 * 1280; time = 3.7364s; samplesPerSecond = 342.6
08/19/2016 15:07:42:  Epoch[45 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14361967 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 3.7894s; samplesPerSecond = 337.8
08/19/2016 15:07:46:  Epoch[45 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15862999 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 3.7915s; samplesPerSecond = 337.6
08/19/2016 15:07:50:  Epoch[45 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15262280 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 3.8074s; samplesPerSecond = 336.2
08/19/2016 15:07:53:  Epoch[45 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14749093 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 3.7665s; samplesPerSecond = 339.8
08/19/2016 15:07:57:  Epoch[45 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13471837 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 3.7819s; samplesPerSecond = 338.5
08/19/2016 15:08:01:  Epoch[45 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15046511 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 3.7469s; samplesPerSecond = 341.6
08/19/2016 15:08:04: Finished Epoch[45 of 50]: [Training] CrossEntropyWithSoftmax = 0.15047557 * 10000; EvalErrorPrediction = 0.07730000 * 10000; totalSamplesSeen = 450000; learningRatePerSample = 0.1; epochTime=29.7628s
08/19/2016 15:08:04: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/models/simple.dnn.45'

08/19/2016 15:08:04: Starting Epoch 46: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 46: samples [450000..460000] (first sequence at sample 450000), worker rank 0, total workers 1

08/19/2016 15:08:04: Starting minibatch loop.
08/19/2016 15:08:08:  Epoch[46 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.12666093 * 1280; EvalErrorPrediction = 0.05937500 * 1280; time = 3.8187s; samplesPerSecond = 335.2
08/19/2016 15:08:12:  Epoch[46 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16436743 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 3.7562s; samplesPerSecond = 340.8
08/19/2016 15:08:16:  Epoch[46 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14386306 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 3.7745s; samplesPerSecond = 339.1
08/19/2016 15:08:20:  Epoch[46 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.13881469 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 3.9272s; samplesPerSecond = 325.9
08/19/2016 15:08:23:  Epoch[46 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14249277 * 1280; EvalErrorPrediction = 0.06562500 * 1280; time = 3.8753s; samplesPerSecond = 330.3
08/19/2016 15:08:27:  Epoch[46 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14794259 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 3.9694s; samplesPerSecond = 322.5
08/19/2016 15:08:31:  Epoch[46 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15111847 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 3.8355s; samplesPerSecond = 333.7
08/19/2016 15:08:35: Finished Epoch[46 of 50]: [Training] CrossEntropyWithSoftmax = 0.14532711 * 10000; EvalErrorPrediction = 0.07110000 * 10000; totalSamplesSeen = 460000; learningRatePerSample = 0.1; epochTime=30.3968s
08/19/2016 15:08:35: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/models/simple.dnn.46'

08/19/2016 15:08:35: Starting Epoch 47: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 47: samples [460000..470000] (first sequence at sample 460000), worker rank 0, total workers 1

08/19/2016 15:08:35: Starting minibatch loop.
08/19/2016 15:08:39:  Epoch[47 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14705383 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 3.8648s; samplesPerSecond = 331.2
08/19/2016 15:08:42:  Epoch[47 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15387183 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 3.8862s; samplesPerSecond = 329.4
08/19/2016 15:08:46:  Epoch[47 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15468142 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 3.9629s; samplesPerSecond = 323.0
08/19/2016 15:08:50:  Epoch[47 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.11875916 * 1280; EvalErrorPrediction = 0.06484375 * 1280; time = 3.8866s; samplesPerSecond = 329.3
08/19/2016 15:08:54:  Epoch[47 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.13453498 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 4.0010s; samplesPerSecond = 319.9
08/19/2016 15:08:58:  Epoch[47 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15137091 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 3.9418s; samplesPerSecond = 324.7
08/19/2016 15:09:02:  Epoch[47 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.13609571 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 3.9326s; samplesPerSecond = 325.5
08/19/2016 15:09:06: Finished Epoch[47 of 50]: [Training] CrossEntropyWithSoftmax = 0.14234733 * 10000; EvalErrorPrediction = 0.07680000 * 10000; totalSamplesSeen = 470000; learningRatePerSample = 0.1; epochTime=31.0017s
08/19/2016 15:09:06: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/models/simple.dnn.47'

08/19/2016 15:09:06: Starting Epoch 48: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 48: samples [470000..480000] (first sequence at sample 470000), worker rank 0, total workers 1

08/19/2016 15:09:06: Starting minibatch loop.
08/19/2016 15:09:10:  Epoch[48 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14787059 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 4.0046s; samplesPerSecond = 319.6
08/19/2016 15:09:14:  Epoch[48 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14771407 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 4.0498s; samplesPerSecond = 316.1
08/19/2016 15:09:18:  Epoch[48 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14863966 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 3.9708s; samplesPerSecond = 322.4
08/19/2016 15:09:22:  Epoch[48 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14012270 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 3.9754s; samplesPerSecond = 322.0
08/19/2016 15:09:26:  Epoch[48 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14018312 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 3.9181s; samplesPerSecond = 326.7
08/19/2016 15:09:30:  Epoch[48 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14272852 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 4.0215s; samplesPerSecond = 318.3
08/19/2016 15:09:34:  Epoch[48 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.12747297 * 1280; EvalErrorPrediction = 0.06406250 * 1280; time = 3.9874s; samplesPerSecond = 321.0
08/19/2016 15:09:37: Finished Epoch[48 of 50]: [Training] CrossEntropyWithSoftmax = 0.14266554 * 10000; EvalErrorPrediction = 0.07220000 * 10000; totalSamplesSeen = 480000; learningRatePerSample = 0.1; epochTime=31.5429s
08/19/2016 15:09:37: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/models/simple.dnn.48'

08/19/2016 15:09:37: Starting Epoch 49: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 49: samples [480000..490000] (first sequence at sample 480000), worker rank 0, total workers 1

08/19/2016 15:09:37: Starting minibatch loop.
08/19/2016 15:09:41:  Epoch[49 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15699662 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 4.1009s; samplesPerSecond = 312.1
08/19/2016 15:09:45:  Epoch[49 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.12934197 * 1280; EvalErrorPrediction = 0.06640625 * 1280; time = 4.0692s; samplesPerSecond = 314.6
08/19/2016 15:09:49:  Epoch[49 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14573290 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 4.0298s; samplesPerSecond = 317.6
08/19/2016 15:09:54:  Epoch[49 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14289498 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 4.1291s; samplesPerSecond = 310.0
08/19/2016 15:09:58:  Epoch[49 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14050484 * 1280; EvalErrorPrediction = 0.06406250 * 1280; time = 4.0598s; samplesPerSecond = 315.3
08/19/2016 15:10:02:  Epoch[49 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13542056 * 1280; EvalErrorPrediction = 0.06015625 * 1280; time = 4.0369s; samplesPerSecond = 317.1
08/19/2016 15:10:06:  Epoch[49 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16450481 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 4.0504s; samplesPerSecond = 316.0
08/19/2016 15:10:09: Finished Epoch[49 of 50]: [Training] CrossEntropyWithSoftmax = 0.14476306 * 10000; EvalErrorPrediction = 0.07090000 * 10000; totalSamplesSeen = 490000; learningRatePerSample = 0.1; epochTime=32.1636s
08/19/2016 15:10:09: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/models/simple.dnn.49'

08/19/2016 15:10:09: Starting Epoch 50: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 50: samples [490000..500000] (first sequence at sample 490000), worker rank 0, total workers 1

08/19/2016 15:10:09: Starting minibatch loop.
08/19/2016 15:10:14:  Epoch[50 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14711674 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 4.1935s; samplesPerSecond = 305.2
08/19/2016 15:10:18:  Epoch[50 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13557233 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 4.0688s; samplesPerSecond = 314.6
08/19/2016 15:10:22:  Epoch[50 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.13794892 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 4.1401s; samplesPerSecond = 309.2
08/19/2016 15:10:26:  Epoch[50 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14867930 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 4.1693s; samplesPerSecond = 307.0
08/19/2016 15:10:30:  Epoch[50 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.13444314 * 1280; EvalErrorPrediction = 0.06640625 * 1280; time = 4.1635s; samplesPerSecond = 307.4
08/19/2016 15:10:34:  Epoch[50 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14466457 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 4.2325s; samplesPerSecond = 302.4
08/19/2016 15:10:39:  Epoch[50 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14759626 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 4.2186s; samplesPerSecond = 303.4
08/19/2016 15:10:42: Finished Epoch[50 of 50]: [Training] CrossEntropyWithSoftmax = 0.14189930 * 10000; EvalErrorPrediction = 0.07380000 * 10000; totalSamplesSeen = 500000; learningRatePerSample = 0.1; epochTime=32.9149s
08/19/2016 15:10:42: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/models/simple.dnn'
08/19/2016 15:10:42: CNTKCommandTrainEnd: Simple_Demo

08/19/2016 15:10:42: Action "train" complete.


08/19/2016 15:10:42: ##############################################################################
08/19/2016 15:10:42: #                                                                            #
08/19/2016 15:10:42: # Action "write"                                                             #
08/19/2016 15:10:42: #                                                                            #
08/19/2016 15:10:42: ##############################################################################


Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalErrorPrediction = ErrorPrediction()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *1]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *1]
Validating --> MeanOfFeatures = Mean (features) : [2 x *1] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *1] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *1], [2], [2] -> [2 x *1]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *1] -> [50 x *1]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *1] -> [2 x 1 x *1]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *1], [2 x 1] -> [2 x 1 x *1]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *1] -> [2 x 1 x *1]
Validating --> Prior = Mean (labels) : [2 x *1] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *1], [2] -> [2 x 1 x *1]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.



Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 25 matrices, 3 are shared as 1, and 22 are not shared.

	{ CrossEntropyWithSoftmax : [1]
	  EvalErrorPrediction : [1]
	  PosteriorProb : [2 x 1 x *1] }

Minibatch[0]: ActualMBSize = 603
Written to F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/SimpleOutput*
Total Samples Evaluated = 603

08/19/2016 15:10:43: Action "write" complete.

08/19/2016 15:10:43: __COMPLETED__
=== Deleting last epoch data
==== Re-running from checkpoint
=== Running /cygdrive/c/repo/cntk_github/CNTK/x64/debug/cntk.exe configFile=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Simple/cntk.cntk currentDirectory=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Data RunDir=F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu DataDir=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Data ConfigDir=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Simple OutputDir=F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu DeviceId=-1 timestamping=true makeMode=true
-------------------------------------------------------------------
Build info: 

		Built time: Aug 19 2016 15:33:50
		Last modified date: Wed Aug 17 12:18:00 2016
		Build type: Debug
		Build target: GPU
		With 1bit-SGD: yes
		Math lib: mkl
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
		CUB_PATH: c:\Tools\cub-1.4.1\
		CUDNN_PATH: c:\Tools\cudnn-4.0\cuda
		Build Branch: eldak/mtNonUniform2
		Build SHA1: bf68d59b287b6a44797ded0815a80d1451d8774e (modified)
		Built by eldak on ELDAK-0
		Build Path: c:\repo\cntk_github\CNTK\Source\CNTK\
-------------------------------------------------------------------
Changed current directory to C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Data
08/19/2016 15:10:43: -------------------------------------------------------------------
08/19/2016 15:10:43: Build info: 

08/19/2016 15:10:43: 		Built time: Aug 19 2016 15:33:50
08/19/2016 15:10:43: 		Last modified date: Wed Aug 17 12:18:00 2016
08/19/2016 15:10:43: 		Build type: Debug
08/19/2016 15:10:43: 		Build target: GPU
08/19/2016 15:10:43: 		With 1bit-SGD: yes
08/19/2016 15:10:43: 		Math lib: mkl
08/19/2016 15:10:43: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.0
08/19/2016 15:10:43: 		CUB_PATH: c:\Tools\cub-1.4.1\
08/19/2016 15:10:43: 		CUDNN_PATH: c:\Tools\cudnn-4.0\cuda
08/19/2016 15:10:43: 		Build Branch: eldak/mtNonUniform2
08/19/2016 15:10:43: 		Build SHA1: bf68d59b287b6a44797ded0815a80d1451d8774e (modified)
08/19/2016 15:10:43: 		Built by eldak on ELDAK-0
08/19/2016 15:10:43: 		Build Path: c:\repo\cntk_github\CNTK\Source\CNTK\
08/19/2016 15:10:43: -------------------------------------------------------------------
08/19/2016 15:10:44: -------------------------------------------------------------------
08/19/2016 15:10:44: GPU info:

08/19/2016 15:10:44: 		Device[0]: cores = 1536; computeCapability = 5.2; type = "GeForce GTX 960"; memory = 2048 MB
08/19/2016 15:10:44: 		Device[1]: cores = 576; computeCapability = 5.0; type = "Quadro K620"; memory = 2048 MB
08/19/2016 15:10:44: -------------------------------------------------------------------

08/19/2016 15:10:44: Running on ELDAK-0 at 2016/08/19 15:10:44
08/19/2016 15:10:44: Command line: 
C:\repo\cntk_github\CNTK\x64\debug\cntk.exe  configFile=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Simple/cntk.cntk  currentDirectory=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Data  RunDir=F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu  DataDir=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Data  ConfigDir=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Simple  OutputDir=F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu  DeviceId=-1  timestamping=true  makeMode=true



08/19/2016 15:10:44: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
08/19/2016 15:10:44: command=Simple_Demo:Simple_Demo_Output
DeviceNumber=-1
precision=float
modelPath=$RunDir$/models/simple.dnn
deviceId=$DeviceNumber$
outputNodeNames=ScaledLogLikelihood
traceLevel=1
Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=$DataDir$/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]
Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=$DataDir$/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=$RunDir$/SimpleOutput    
]
currentDirectory=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Data
RunDir=F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu
DataDir=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Data
ConfigDir=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Simple
OutputDir=F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu
DeviceId=-1
timestamping=true
makeMode=true

08/19/2016 15:10:44: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<

08/19/2016 15:10:44: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
08/19/2016 15:10:44: command=Simple_Demo:Simple_Demo_Output
DeviceNumber=-1
precision=float
modelPath=F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/models/simple.dnn
deviceId=-1
outputNodeNames=ScaledLogLikelihood
traceLevel=1
Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]
Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/SimpleOutput    
]
currentDirectory=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Data
RunDir=F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu
DataDir=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Data
ConfigDir=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Simple
OutputDir=F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu
DeviceId=-1
timestamping=true
makeMode=true

08/19/2016 15:10:44: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<

08/19/2016 15:10:44: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
configparameters: cntk.cntk:command=Simple_Demo:Simple_Demo_Output
configparameters: cntk.cntk:ConfigDir=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Simple
configparameters: cntk.cntk:currentDirectory=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Data
configparameters: cntk.cntk:DataDir=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Data
configparameters: cntk.cntk:deviceId=-1
configparameters: cntk.cntk:DeviceNumber=-1
configparameters: cntk.cntk:makeMode=true
configparameters: cntk.cntk:modelPath=F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/models/simple.dnn
configparameters: cntk.cntk:OutputDir=F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu
configparameters: cntk.cntk:outputNodeNames=ScaledLogLikelihood
configparameters: cntk.cntk:precision=float
configparameters: cntk.cntk:RunDir=F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu
configparameters: cntk.cntk:Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]

configparameters: cntk.cntk:Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\repo\cntk_github\CNTK\Tests\EndToEndTests\Speech\Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/SimpleOutput    
]

configparameters: cntk.cntk:timestamping=true
configparameters: cntk.cntk:traceLevel=1
08/19/2016 15:10:44: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
08/19/2016 15:10:44: Commands: Simple_Demo Simple_Demo_Output
08/19/2016 15:10:44: Precision = "float"
08/19/2016 15:10:44: CNTKModelPath: F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/models/simple.dnn
08/19/2016 15:10:44: CNTKCommandTrainInfo: Simple_Demo : 50
08/19/2016 15:10:44: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 50

08/19/2016 15:10:44: ##############################################################################
08/19/2016 15:10:44: #                                                                            #
08/19/2016 15:10:44: # Action "train"                                                             #
08/19/2016 15:10:44: #                                                                            #
08/19/2016 15:10:44: ##############################################################################

08/19/2016 15:10:44: CNTKCommandTrainBegin: Simple_Demo
SimpleNetworkBuilder Using CPU

08/19/2016 15:10:45: Starting from checkpoint. Loading network from 'F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/models/simple.dnn.49'.

Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalErrorPrediction = ErrorPrediction()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *1]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *1]
Validating --> MeanOfFeatures = Mean (features) : [2 x *1] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *1] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *1], [2], [2] -> [2 x *1]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *1] -> [50 x *1]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *1] -> [2 x 1 x *1]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *1], [2 x 1] -> [2 x 1 x *1]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *1] -> [2 x 1 x *1]
Validating --> Prior = Mean (labels) : [2 x *1] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *1], [2] -> [2 x 1 x *1]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

08/19/2016 15:10:45: Loaded model with 25 nodes on CPU.

08/19/2016 15:10:45: Training criterion node(s):
08/19/2016 15:10:45: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax

08/19/2016 15:10:45: Evaluation criterion node(s):
08/19/2016 15:10:45: 	EvalErrorPrediction = ErrorPrediction


Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 40 matrices, 19 are shared as 8, and 21 are not shared.

	{ W0*features+B0 : [50 x 1 x *1] (gradient)
	  W1*H1 : [50 x 1 x *1] }
	{ HLast : [2 x 1 x *1]
	  W2 : [2 x 50] (gradient) }
	{ B0 : [50 x 1] (gradient)
	  H1 : [50 x 1 x *1] (gradient)
	  W1*H1+B1 : [50 x 1 x *1] (gradient)
	  W2*H1 : [2 x 1 x *1] }
	{ B1 : [50 x 1] (gradient)
	  H2 : [50 x 1 x *1] (gradient)
	  HLast : [2 x 1 x *1] (gradient) }
	{ W0 : [50 x 2] (gradient)
	  W0*features+B0 : [50 x 1 x *1] }
	{ W1 : [50 x 50] (gradient)
	  W1*H1+B1 : [50 x 1 x *1] }
	{ H2 : [50 x 1 x *1]
	  W1*H1 : [50 x 1 x *1] (gradient) }
	{ H1 : [50 x 1 x *1]
	  W0*features : [50 x *1] (gradient) }


08/19/2016 15:10:45: Training 2802 parameters in 6 out of 6 parameter tensors and 15 nodes with gradient:

08/19/2016 15:10:45: 	Node 'B0' (LearnableParameter operation) : [50 x 1]
08/19/2016 15:10:45: 	Node 'B1' (LearnableParameter operation) : [50 x 1]
08/19/2016 15:10:45: 	Node 'B2' (LearnableParameter operation) : [2 x 1]
08/19/2016 15:10:45: 	Node 'W0' (LearnableParameter operation) : [50 x 2]
08/19/2016 15:10:45: 	Node 'W1' (LearnableParameter operation) : [50 x 50]
08/19/2016 15:10:45: 	Node 'W2' (LearnableParameter operation) : [2 x 50]

08/19/2016 15:10:45: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

08/19/2016 15:10:45: Starting Epoch 50: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 50: samples [490000..500000] (first sequence at sample 490000), worker rank 0, total workers 1

08/19/2016 15:10:45: Starting minibatch loop.
08/19/2016 15:10:45:  Epoch[50 of 50]-Minibatch[   1-  10, 0.00000000000003%]: CrossEntropyWithSoftmax = 0.14711674 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.7152s; samplesPerSecond = 1789.6
08/19/2016 15:10:46:  Epoch[50 of 50]-Minibatch[  11-  20, 0.00000000000006%]: CrossEntropyWithSoftmax = 0.13557233 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.4322s; samplesPerSecond = 2961.9
08/19/2016 15:10:46:  Epoch[50 of 50]-Minibatch[  21-  30, 0.00000000000008%]: CrossEntropyWithSoftmax = 0.13794892 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.4382s; samplesPerSecond = 2921.0
08/19/2016 15:10:47:  Epoch[50 of 50]-Minibatch[  31-  40, 0.00000000000011%]: CrossEntropyWithSoftmax = 0.14867930 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.4452s; samplesPerSecond = 2875.2
08/19/2016 15:10:47:  Epoch[50 of 50]-Minibatch[  41-  50, 0.00000000000014%]: CrossEntropyWithSoftmax = 0.13444314 * 1280; EvalErrorPrediction = 0.06640625 * 1280; time = 0.4565s; samplesPerSecond = 2803.9
08/19/2016 15:10:48:  Epoch[50 of 50]-Minibatch[  51-  60, 0.00000000000017%]: CrossEntropyWithSoftmax = 0.14466457 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.4631s; samplesPerSecond = 2764.2
08/19/2016 15:10:48:  Epoch[50 of 50]-Minibatch[  61-  70, 0.00000000000019%]: CrossEntropyWithSoftmax = 0.14759626 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.4758s; samplesPerSecond = 2690.4
08/19/2016 15:10:49: Finished Epoch[50 of 50]: [Training] CrossEntropyWithSoftmax = 0.14189930 * 10000; EvalErrorPrediction = 0.07380000 * 10000; totalSamplesSeen = 500000; learningRatePerSample = 0.1; epochTime=4.11132s
08/19/2016 15:10:49: SGD: Saving checkpoint model 'F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/models/simple.dnn'
08/19/2016 15:10:49: CNTKCommandTrainEnd: Simple_Demo

08/19/2016 15:10:49: Action "train" complete.


08/19/2016 15:10:49: ##############################################################################
08/19/2016 15:10:49: #                                                                            #
08/19/2016 15:10:49: # Action "write"                                                             #
08/19/2016 15:10:49: #                                                                            #
08/19/2016 15:10:49: ##############################################################################


Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalErrorPrediction = ErrorPrediction()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *2]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *2]
Validating --> MeanOfFeatures = Mean (features) : [2 x *2] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *2] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *2], [2], [2] -> [2 x *2]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *2] -> [50 x *2]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *2], [50 x 1] -> [50 x 1 x *2]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *2], [50 x 1] -> [50 x 1 x *2]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *2] -> [2 x 1 x *2]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *2], [2 x 1] -> [2 x 1 x *2]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *2], [2 x 1 x *2] -> [1]
Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [2 x *2], [2 x 1 x *2] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *2] -> [2 x 1 x *2]
Validating --> Prior = Mean (labels) : [2 x *2] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *2], [2] -> [2 x 1 x *2]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.



Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 25 matrices, 3 are shared as 1, and 22 are not shared.

	{ CrossEntropyWithSoftmax : [1]
	  EvalErrorPrediction : [1]
	  PosteriorProb : [2 x 1 x *2] }

Minibatch[0]: ActualMBSize = 603
Written to F:\cygwin64\tmp\cntk-test-20160819155532.750486\Speech_Simple@debug_cpu/SimpleOutput*
Total Samples Evaluated = 603

08/19/2016 15:10:49: Action "write" complete.

08/19/2016 15:10:49: __COMPLETED__