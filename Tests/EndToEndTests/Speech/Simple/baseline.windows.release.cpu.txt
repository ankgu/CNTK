CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU E5-2630 v2 @ 2.60GHz
    Hardware threads: 24
    Total Memory: 268381192 kB
-------------------------------------------------------------------
=== Running /cygdrive/c/jenkins/workspace/CNTK-Test-Windows-W1/x64/release/cntk.exe configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple/cntk.cntk currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu DeviceId=-1 timestamping=true
-------------------------------------------------------------------
Build info: 

		Built time: Aug 18 2016 06:54:41
		Last modified date: Thu Aug 18 03:27:57 2016
		Build type: Release
		Build target: GPU
		With 1bit-SGD: no
		Math lib: mkl
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
		CUB_PATH: C:\src\cub-1.4.1
		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
		Build Branch: HEAD
		Build SHA1: ac4da60ce4c7318dc6e020a8a97afa5c6952dfce
		Built by svcphil on dphaim-26-new
		Build Path: c:\jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
-------------------------------------------------------------------
Changed current directory to C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
08/18/2016 07:43:28: -------------------------------------------------------------------
08/18/2016 07:43:28: Build info: 

08/18/2016 07:43:28: 		Built time: Aug 18 2016 06:54:41
08/18/2016 07:43:28: 		Last modified date: Thu Aug 18 03:27:57 2016
08/18/2016 07:43:28: 		Build type: Release
08/18/2016 07:43:28: 		Build target: GPU
08/18/2016 07:43:28: 		With 1bit-SGD: no
08/18/2016 07:43:28: 		Math lib: mkl
08/18/2016 07:43:28: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
08/18/2016 07:43:28: 		CUB_PATH: C:\src\cub-1.4.1
08/18/2016 07:43:28: 		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
08/18/2016 07:43:28: 		Build Branch: HEAD
08/18/2016 07:43:28: 		Build SHA1: ac4da60ce4c7318dc6e020a8a97afa5c6952dfce
08/18/2016 07:43:28: 		Built by svcphil on dphaim-26-new
08/18/2016 07:43:28: 		Build Path: c:\jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
08/18/2016 07:43:28: -------------------------------------------------------------------
08/18/2016 07:43:32: -------------------------------------------------------------------
08/18/2016 07:43:32: GPU info:

08/18/2016 07:43:32: 		Device[0]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3072 MB
08/18/2016 07:43:32: 		Device[1]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3072 MB
08/18/2016 07:43:32: 		Device[2]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3072 MB
08/18/2016 07:43:32: 		Device[3]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3072 MB
08/18/2016 07:43:32: -------------------------------------------------------------------

08/18/2016 07:43:32: Running on DPHAIM-24 at 2016/08/18 07:43:32
08/18/2016 07:43:32: Command line: 
C:\jenkins\workspace\CNTK-Test-Windows-W1\x64\release\cntk.exe  configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple/cntk.cntk  currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data  RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu  DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data  ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple  OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu  DeviceId=-1  timestamping=true



08/18/2016 07:43:32: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
08/18/2016 07:43:32: command=Simple_Demo:Simple_Demo_Output
DeviceNumber=-1
precision=float
modelPath=$RunDir$/models/simple.dnn
deviceId=$DeviceNumber$
outputNodeNames=ScaledLogLikelihood
traceLevel=1
Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=$DataDir$/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]
Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=$DataDir$/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=$RunDir$/SimpleOutput    
]
currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu
DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple
OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu
DeviceId=-1
timestamping=true

08/18/2016 07:43:32: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<

08/18/2016 07:43:32: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
08/18/2016 07:43:32: command=Simple_Demo:Simple_Demo_Output
DeviceNumber=-1
precision=float
modelPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/models/simple.dnn
deviceId=-1
outputNodeNames=ScaledLogLikelihood
traceLevel=1
Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]
Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/SimpleOutput    
]
currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu
DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple
OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu
DeviceId=-1
timestamping=true

08/18/2016 07:43:32: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<

08/18/2016 07:43:32: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
configparameters: cntk.cntk:command=Simple_Demo:Simple_Demo_Output
configparameters: cntk.cntk:ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple
configparameters: cntk.cntk:currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
configparameters: cntk.cntk:DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
configparameters: cntk.cntk:deviceId=-1
configparameters: cntk.cntk:DeviceNumber=-1
configparameters: cntk.cntk:modelPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/models/simple.dnn
configparameters: cntk.cntk:OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu
configparameters: cntk.cntk:outputNodeNames=ScaledLogLikelihood
configparameters: cntk.cntk:precision=float
configparameters: cntk.cntk:RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu
configparameters: cntk.cntk:Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]

configparameters: cntk.cntk:Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/SimpleOutput    
]

configparameters: cntk.cntk:timestamping=true
configparameters: cntk.cntk:traceLevel=1
08/18/2016 07:43:32: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
08/18/2016 07:43:32: Commands: Simple_Demo Simple_Demo_Output
08/18/2016 07:43:32: Precision = "float"
08/18/2016 07:43:32: CNTKModelPath: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/models/simple.dnn
08/18/2016 07:43:32: CNTKCommandTrainInfo: Simple_Demo : 50
08/18/2016 07:43:32: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 50

08/18/2016 07:43:32: ##############################################################################
08/18/2016 07:43:32: #                                                                            #
08/18/2016 07:43:32: # Action "train"                                                             #
08/18/2016 07:43:32: #                                                                            #
08/18/2016 07:43:32: ##############################################################################

08/18/2016 07:43:32: CNTKCommandTrainBegin: Simple_Demo
SimpleNetworkBuilder Using CPU

08/18/2016 07:43:32: Creating virgin network.
Node 'W0' (LearnableParameter operation): Initializing Parameter[50 x 2] <- 0.000000.
Node 'W0' (LearnableParameter operation): Initializing Parameter[50 x 2] <- uniform(seed=1, range=0.050000*1.000000, onCPU=false).
Node 'B0' (LearnableParameter operation): Initializing Parameter[50 x 1] <- 0.000000.
Node 'B0' (LearnableParameter operation): Initializing Parameter[50 x 1] <- 0.000000.
Node 'W1' (LearnableParameter operation): Initializing Parameter[50 x 50] <- 0.000000.
Node 'W1' (LearnableParameter operation): Initializing Parameter[50 x 50] <- uniform(seed=2, range=0.050000*1.000000, onCPU=false).
Node 'B1' (LearnableParameter operation): Initializing Parameter[50 x 1] <- 0.000000.
Node 'B1' (LearnableParameter operation): Initializing Parameter[50 x 1] <- 0.000000.
Node 'W2' (LearnableParameter operation): Initializing Parameter[2 x 50] <- 0.000000.
Node 'W2' (LearnableParameter operation): Initializing Parameter[2 x 50] <- uniform(seed=3, range=0.050000*1.000000, onCPU=false).
Node 'B2' (LearnableParameter operation): Initializing Parameter[2 x 1] <- 0.000000.
Node 'B2' (LearnableParameter operation): Initializing Parameter[2 x 1] <- 0.000000.

Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalErrorPrediction = ErrorPrediction()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *]
Validating --> MeanOfFeatures = Mean (features) : [2 x *] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *], [2], [2] -> [2 x *]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *] -> [50 x *]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *], [50 x 1] -> [50 x 1 x *]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *] -> [50 x 1 x *]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *] -> [50 x 1 x *]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *], [50 x 1] -> [50 x 1 x *]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *] -> [50 x 1 x *]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *] -> [2 x 1 x *]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *], [2 x 1] -> [2 x 1 x *]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *], [2 x 1 x *] -> [1]
Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [2 x *], [2 x 1 x *] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *] -> [2 x 1 x *]
Validating --> Prior = Mean (labels) : [2 x *] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *], [2] -> [2 x 1 x *]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

08/18/2016 07:43:32: Created model with 25 nodes on CPU.

08/18/2016 07:43:32: Training criterion node(s):
08/18/2016 07:43:32: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax

08/18/2016 07:43:32: Evaluation criterion node(s):
08/18/2016 07:43:32: 	EvalErrorPrediction = ErrorPrediction


Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 40 matrices, 19 are shared as 8, and 21 are not shared.

	{ W1 : [50 x 50] (gradient)
	  W1*H1+B1 : [50 x 1 x *] }
	{ W0 : [50 x 2] (gradient)
	  W0*features+B0 : [50 x 1 x *] }
	{ H1 : [50 x 1 x *]
	  W0*features : [50 x *] (gradient) }
	{ W0*features+B0 : [50 x 1 x *] (gradient)
	  W1*H1 : [50 x 1 x *] }
	{ B1 : [50 x 1] (gradient)
	  H2 : [50 x 1 x *] (gradient)
	  HLast : [2 x 1 x *] (gradient) }
	{ H2 : [50 x 1 x *]
	  W1*H1 : [50 x 1 x *] (gradient) }
	{ B0 : [50 x 1] (gradient)
	  H1 : [50 x 1 x *] (gradient)
	  W1*H1+B1 : [50 x 1 x *] (gradient)
	  W2*H1 : [2 x 1 x *] }
	{ HLast : [2 x 1 x *]
	  W2 : [2 x 50] (gradient) }


08/18/2016 07:43:32: Training 2802 parameters in 6 out of 6 parameter tensors and 15 nodes with gradient:

08/18/2016 07:43:32: 	Node 'B0' (LearnableParameter operation) : [50 x 1]
08/18/2016 07:43:32: 	Node 'B1' (LearnableParameter operation) : [50 x 1]
08/18/2016 07:43:32: 	Node 'B2' (LearnableParameter operation) : [2 x 1]
08/18/2016 07:43:32: 	Node 'W0' (LearnableParameter operation) : [50 x 2]
08/18/2016 07:43:32: 	Node 'W1' (LearnableParameter operation) : [50 x 50]
08/18/2016 07:43:32: 	Node 'W2' (LearnableParameter operation) : [2 x 50]


08/18/2016 07:43:32: Precomputing --> 3 PreCompute nodes found.

08/18/2016 07:43:32: 	MeanOfFeatures = Mean()
08/18/2016 07:43:32: 	InvStdOfFeatures = InvStdDev()
08/18/2016 07:43:32: 	Prior = Mean()
BlockRandomizer::StartEpoch: epoch 1: samples [0..10000] (first sequence at sample 0), worker rank 0, total workers 1

08/18/2016 07:43:32: Precomputing --> Completed.


08/18/2016 07:43:32: Starting Epoch 1: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 1: samples [0..10000] (first sequence at sample 0), worker rank 0, total workers 1

08/18/2016 07:43:32: Starting minibatch loop.
08/18/2016 07:43:32:  Epoch[ 1 of 50]-Minibatch[   1-  10]: CrossEntropyWithSoftmax = 0.84135866 * 1280; EvalErrorPrediction = 0.49375000 * 1280; time = 0.0670s; samplesPerSecond = 19103.6
08/18/2016 07:43:32:  Epoch[ 1 of 50]-Minibatch[  11-  20]: CrossEntropyWithSoftmax = 0.80750933 * 1280; EvalErrorPrediction = 0.50937500 * 1280; time = 0.0615s; samplesPerSecond = 20814.4
08/18/2016 07:43:32:  Epoch[ 1 of 50]-Minibatch[  21-  30]: CrossEntropyWithSoftmax = 0.73671169 * 1280; EvalErrorPrediction = 0.48828125 * 1280; time = 0.0602s; samplesPerSecond = 21258.6
08/18/2016 07:43:32:  Epoch[ 1 of 50]-Minibatch[  31-  40]: CrossEntropyWithSoftmax = 0.71652222 * 1280; EvalErrorPrediction = 0.51484375 * 1280; time = 0.0622s; samplesPerSecond = 20591.4
08/18/2016 07:43:32:  Epoch[ 1 of 50]-Minibatch[  41-  50]: CrossEntropyWithSoftmax = 0.70134087 * 1280; EvalErrorPrediction = 0.50078125 * 1280; time = 0.0601s; samplesPerSecond = 21287.6
08/18/2016 07:43:32:  Epoch[ 1 of 50]-Minibatch[  51-  60]: CrossEntropyWithSoftmax = 0.71664810 * 1280; EvalErrorPrediction = 0.50781250 * 1280; time = 0.0607s; samplesPerSecond = 21092.2
08/18/2016 07:43:32:  Epoch[ 1 of 50]-Minibatch[  61-  70]: CrossEntropyWithSoftmax = 0.71382103 * 1280; EvalErrorPrediction = 0.50156250 * 1280; time = 0.0604s; samplesPerSecond = 21202.6
08/18/2016 07:43:32: Finished Epoch[ 1 of 50]: [Training] CrossEntropyWithSoftmax = 0.74341196 * 10000; EvalErrorPrediction = 0.50260000 * 10000; totalSamplesSeen = 10000; learningRatePerSample = 0.1; epochTime=0.485537s
08/18/2016 07:43:32: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/models/simple.dnn.1'

08/18/2016 07:43:32: Starting Epoch 2: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 2: samples [10000..20000] (first sequence at sample 10000), worker rank 0, total workers 1

08/18/2016 07:43:32: Starting minibatch loop.
08/18/2016 07:43:33:  Epoch[ 2 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.71325479 * 1280; EvalErrorPrediction = 0.49296875 * 1280; time = 0.0627s; samplesPerSecond = 20421.8
08/18/2016 07:43:33:  Epoch[ 2 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.75389848 * 1280; EvalErrorPrediction = 0.46406250 * 1280; time = 0.0579s; samplesPerSecond = 22123.1
08/18/2016 07:43:33:  Epoch[ 2 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.75757513 * 1280; EvalErrorPrediction = 0.51171875 * 1280; time = 0.0565s; samplesPerSecond = 22666.5
08/18/2016 07:43:33:  Epoch[ 2 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.75674992 * 1280; EvalErrorPrediction = 0.51171875 * 1280; time = 0.0559s; samplesPerSecond = 22916.5
08/18/2016 07:43:33:  Epoch[ 2 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.74725094 * 1280; EvalErrorPrediction = 0.50390625 * 1280; time = 0.0556s; samplesPerSecond = 23007.5
08/18/2016 07:43:33:  Epoch[ 2 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.73079414 * 1280; EvalErrorPrediction = 0.50546875 * 1280; time = 0.0541s; samplesPerSecond = 23665.6
08/18/2016 07:43:33:  Epoch[ 2 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.73625755 * 1280; EvalErrorPrediction = 0.50078125 * 1280; time = 0.0545s; samplesPerSecond = 23472.0
08/18/2016 07:43:33: Finished Epoch[ 2 of 50]: [Training] CrossEntropyWithSoftmax = 0.73900103 * 10000; EvalErrorPrediction = 0.49680000 * 10000; totalSamplesSeen = 20000; learningRatePerSample = 0.1; epochTime=0.444709s
08/18/2016 07:43:33: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/models/simple.dnn.2'

08/18/2016 07:43:33: Starting Epoch 3: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 3: samples [20000..30000] (first sequence at sample 20000), worker rank 0, total workers 1

08/18/2016 07:43:33: Starting minibatch loop.
08/18/2016 07:43:33:  Epoch[ 3 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.74044714 * 1280; EvalErrorPrediction = 0.50000000 * 1280; time = 0.0551s; samplesPerSecond = 23233.0
08/18/2016 07:43:33:  Epoch[ 3 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.73792171 * 1280; EvalErrorPrediction = 0.50625000 * 1280; time = 0.0572s; samplesPerSecond = 22364.7
08/18/2016 07:43:33:  Epoch[ 3 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.77087240 * 1280; EvalErrorPrediction = 0.52187500 * 1280; time = 0.0559s; samplesPerSecond = 22896.8
08/18/2016 07:43:33:  Epoch[ 3 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.75999603 * 1280; EvalErrorPrediction = 0.50234375 * 1280; time = 0.0546s; samplesPerSecond = 23427.8
08/18/2016 07:43:33:  Epoch[ 3 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.73512688 * 1280; EvalErrorPrediction = 0.50937500 * 1280; time = 0.0558s; samplesPerSecond = 22956.8
08/18/2016 07:43:33:  Epoch[ 3 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.71369209 * 1280; EvalErrorPrediction = 0.48984375 * 1280; time = 0.0551s; samplesPerSecond = 23236.4
08/18/2016 07:43:33:  Epoch[ 3 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.69696960 * 1280; EvalErrorPrediction = 0.50703125 * 1280; time = 0.0543s; samplesPerSecond = 23591.4
08/18/2016 07:43:33: Finished Epoch[ 3 of 50]: [Training] CrossEntropyWithSoftmax = 0.73257485 * 10000; EvalErrorPrediction = 0.50380000 * 10000; totalSamplesSeen = 30000; learningRatePerSample = 0.1; epochTime=0.437243s
08/18/2016 07:43:33: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/models/simple.dnn.3'

08/18/2016 07:43:33: Starting Epoch 4: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 4: samples [30000..40000] (first sequence at sample 30000), worker rank 0, total workers 1

08/18/2016 07:43:33: Starting minibatch loop.
08/18/2016 07:43:33:  Epoch[ 4 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.71515269 * 1280; EvalErrorPrediction = 0.49296875 * 1280; time = 0.0586s; samplesPerSecond = 21854.9
08/18/2016 07:43:34:  Epoch[ 4 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.74560342 * 1280; EvalErrorPrediction = 0.50234375 * 1280; time = 0.0835s; samplesPerSecond = 15336.3
08/18/2016 07:43:34:  Epoch[ 4 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.73897247 * 1280; EvalErrorPrediction = 0.47812500 * 1280; time = 0.0567s; samplesPerSecond = 22570.2
08/18/2016 07:43:34:  Epoch[ 4 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.71412621 * 1280; EvalErrorPrediction = 0.48671875 * 1280; time = 0.0545s; samplesPerSecond = 23505.6
08/18/2016 07:43:34:  Epoch[ 4 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.71213512 * 1280; EvalErrorPrediction = 0.50000000 * 1280; time = 0.0560s; samplesPerSecond = 22854.7
08/18/2016 07:43:34:  Epoch[ 4 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.70156898 * 1280; EvalErrorPrediction = 0.50390625 * 1280; time = 0.0552s; samplesPerSecond = 23207.3
08/18/2016 07:43:34:  Epoch[ 4 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.70737953 * 1280; EvalErrorPrediction = 0.49687500 * 1280; time = 0.0555s; samplesPerSecond = 23056.0
08/18/2016 07:43:34: Finished Epoch[ 4 of 50]: [Training] CrossEntropyWithSoftmax = 0.71707456 * 10000; EvalErrorPrediction = 0.49440000 * 10000; totalSamplesSeen = 40000; learningRatePerSample = 0.1; epochTime=0.466661s
08/18/2016 07:43:34: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/models/simple.dnn.4'

08/18/2016 07:43:34: Starting Epoch 5: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 5: samples [40000..50000] (first sequence at sample 40000), worker rank 0, total workers 1

08/18/2016 07:43:34: Starting minibatch loop.
08/18/2016 07:43:34:  Epoch[ 5 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.69854627 * 1280; EvalErrorPrediction = 0.50234375 * 1280; time = 0.0545s; samplesPerSecond = 23469.0
08/18/2016 07:43:34:  Epoch[ 5 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.70018868 * 1280; EvalErrorPrediction = 0.49140625 * 1280; time = 0.0551s; samplesPerSecond = 23250.3
08/18/2016 07:43:34:  Epoch[ 5 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.69679499 * 1280; EvalErrorPrediction = 0.51796875 * 1280; time = 0.0559s; samplesPerSecond = 22908.3
08/18/2016 07:43:34:  Epoch[ 5 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.69342022 * 1280; EvalErrorPrediction = 0.49531250 * 1280; time = 0.0549s; samplesPerSecond = 23327.4
08/18/2016 07:43:34:  Epoch[ 5 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.69504795 * 1280; EvalErrorPrediction = 0.48906250 * 1280; time = 0.0541s; samplesPerSecond = 23649.0
08/18/2016 07:43:34:  Epoch[ 5 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.70215073 * 1280; EvalErrorPrediction = 0.48593750 * 1280; time = 0.0559s; samplesPerSecond = 22908.7
08/18/2016 07:43:34:  Epoch[ 5 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.69844475 * 1280; EvalErrorPrediction = 0.47734375 * 1280; time = 0.0550s; samplesPerSecond = 23286.3
08/18/2016 07:43:34: Finished Epoch[ 5 of 50]: [Training] CrossEntropyWithSoftmax = 0.69761069 * 10000; EvalErrorPrediction = 0.49640000 * 10000; totalSamplesSeen = 50000; learningRatePerSample = 0.1; epochTime=0.431197s
08/18/2016 07:43:34: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/models/simple.dnn.5'

08/18/2016 07:43:34: Starting Epoch 6: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 6: samples [50000..60000] (first sequence at sample 50000), worker rank 0, total workers 1

08/18/2016 07:43:34: Starting minibatch loop.
08/18/2016 07:43:34:  Epoch[ 6 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.70235519 * 1280; EvalErrorPrediction = 0.49843750 * 1280; time = 0.0555s; samplesPerSecond = 23043.5
08/18/2016 07:43:34:  Epoch[ 6 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.69492035 * 1280; EvalErrorPrediction = 0.46875000 * 1280; time = 0.0559s; samplesPerSecond = 22897.6
08/18/2016 07:43:34:  Epoch[ 6 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.68310108 * 1280; EvalErrorPrediction = 0.49062500 * 1280; time = 0.0552s; samplesPerSecond = 23207.7
08/18/2016 07:43:35:  Epoch[ 6 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.68259220 * 1280; EvalErrorPrediction = 0.50625000 * 1280; time = 0.0550s; samplesPerSecond = 23278.2
08/18/2016 07:43:35:  Epoch[ 6 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.55131454 * 1280; EvalErrorPrediction = 0.29218750 * 1280; time = 0.0547s; samplesPerSecond = 23393.1
08/18/2016 07:43:35:  Epoch[ 6 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.26579247 * 1280; EvalErrorPrediction = 0.10390625 * 1280; time = 0.0549s; samplesPerSecond = 23302.4
08/18/2016 07:43:35:  Epoch[ 6 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17694817 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0543s; samplesPerSecond = 23560.2
08/18/2016 07:43:35: Finished Epoch[ 6 of 50]: [Training] CrossEntropyWithSoftmax = 0.49746162 * 10000; EvalErrorPrediction = 0.31920000 * 10000; totalSamplesSeen = 60000; learningRatePerSample = 0.1; epochTime=0.431876s
08/18/2016 07:43:35: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/models/simple.dnn.6'

08/18/2016 07:43:35: Starting Epoch 7: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 7: samples [60000..70000] (first sequence at sample 60000), worker rank 0, total workers 1

08/18/2016 07:43:35: Starting minibatch loop.
08/18/2016 07:43:35:  Epoch[ 7 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17652937 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0548s; samplesPerSecond = 23366.2
08/18/2016 07:43:35:  Epoch[ 7 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17294260 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0552s; samplesPerSecond = 23204.4
08/18/2016 07:43:35:  Epoch[ 7 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17365062 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0549s; samplesPerSecond = 23313.0
08/18/2016 07:43:35:  Epoch[ 7 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16369424 * 1280; EvalErrorPrediction = 0.06718750 * 1280; time = 0.0534s; samplesPerSecond = 23964.2
08/18/2016 07:43:35:  Epoch[ 7 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16039195 * 1280; EvalErrorPrediction = 0.06484375 * 1280; time = 0.0554s; samplesPerSecond = 23102.2
08/18/2016 07:43:35:  Epoch[ 7 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.19018288 * 1280; EvalErrorPrediction = 0.08515625 * 1280; time = 0.0537s; samplesPerSecond = 23821.5
08/18/2016 07:43:35:  Epoch[ 7 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18001451 * 1280; EvalErrorPrediction = 0.08906250 * 1280; time = 0.0561s; samplesPerSecond = 22797.3
08/18/2016 07:43:35: Finished Epoch[ 7 of 50]: [Training] CrossEntropyWithSoftmax = 0.17465151 * 10000; EvalErrorPrediction = 0.07700000 * 10000; totalSamplesSeen = 70000; learningRatePerSample = 0.1; epochTime=0.430503s
08/18/2016 07:43:35: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/models/simple.dnn.7'

08/18/2016 07:43:35: Starting Epoch 8: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 8: samples [70000..80000] (first sequence at sample 70000), worker rank 0, total workers 1

08/18/2016 07:43:35: Starting minibatch loop.
08/18/2016 07:43:35:  Epoch[ 8 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17755967 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0559s; samplesPerSecond = 22879.2
08/18/2016 07:43:35:  Epoch[ 8 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16835443 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0554s; samplesPerSecond = 23089.7
08/18/2016 07:43:35:  Epoch[ 8 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17158954 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0549s; samplesPerSecond = 23295.2
08/18/2016 07:43:35:  Epoch[ 8 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16443648 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0546s; samplesPerSecond = 23440.6
08/18/2016 07:43:35:  Epoch[ 8 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17230582 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0550s; samplesPerSecond = 23266.4
08/18/2016 07:43:36:  Epoch[ 8 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.19415293 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0554s; samplesPerSecond = 23090.9
08/18/2016 07:43:36:  Epoch[ 8 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15374212 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0556s; samplesPerSecond = 23018.7
08/18/2016 07:43:36: Finished Epoch[ 8 of 50]: [Training] CrossEntropyWithSoftmax = 0.17304249 * 10000; EvalErrorPrediction = 0.07940000 * 10000; totalSamplesSeen = 80000; learningRatePerSample = 0.1; epochTime=0.434132s
08/18/2016 07:43:36: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/models/simple.dnn.8'

08/18/2016 07:43:36: Starting Epoch 9: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 9: samples [80000..90000] (first sequence at sample 80000), worker rank 0, total workers 1

08/18/2016 07:43:36: Starting minibatch loop.
08/18/2016 07:43:36:  Epoch[ 9 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.21020713 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0560s; samplesPerSecond = 22872.7
08/18/2016 07:43:36:  Epoch[ 9 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.20798750 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0549s; samplesPerSecond = 23311.7
08/18/2016 07:43:36:  Epoch[ 9 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.19791036 * 1280; EvalErrorPrediction = 0.09609375 * 1280; time = 0.0548s; samplesPerSecond = 23376.4
08/18/2016 07:43:36:  Epoch[ 9 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.19380016 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0549s; samplesPerSecond = 23335.1
08/18/2016 07:43:36:  Epoch[ 9 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18507528 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0551s; samplesPerSecond = 23247.4
08/18/2016 07:43:36:  Epoch[ 9 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17266235 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0563s; samplesPerSecond = 22755.2
08/18/2016 07:43:36:  Epoch[ 9 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17056141 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0540s; samplesPerSecond = 23698.0
08/18/2016 07:43:36: Finished Epoch[ 9 of 50]: [Training] CrossEntropyWithSoftmax = 0.19134744 * 10000; EvalErrorPrediction = 0.08200000 * 10000; totalSamplesSeen = 90000; learningRatePerSample = 0.1; epochTime=0.433941s
08/18/2016 07:43:36: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/models/simple.dnn.9'

08/18/2016 07:43:36: Starting Epoch 10: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 10: samples [90000..100000] (first sequence at sample 90000), worker rank 0, total workers 1

08/18/2016 07:43:36: Starting minibatch loop.
08/18/2016 07:43:36:  Epoch[10 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.19226292 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0573s; samplesPerSecond = 22341.7
08/18/2016 07:43:36:  Epoch[10 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15464629 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0548s; samplesPerSecond = 23355.5
08/18/2016 07:43:36:  Epoch[10 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17312844 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0546s; samplesPerSecond = 23456.1
08/18/2016 07:43:36:  Epoch[10 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15400076 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0576s; samplesPerSecond = 22213.7
08/18/2016 07:43:36:  Epoch[10 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.22229710 * 1280; EvalErrorPrediction = 0.09687500 * 1280; time = 0.0539s; samplesPerSecond = 23726.1
08/18/2016 07:43:36:  Epoch[10 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17282057 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0553s; samplesPerSecond = 23144.4
08/18/2016 07:43:36:  Epoch[10 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18742418 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0550s; samplesPerSecond = 23287.5
08/18/2016 07:43:37: Finished Epoch[10 of 50]: [Training] CrossEntropyWithSoftmax = 0.17764235 * 10000; EvalErrorPrediction = 0.07910000 * 10000; totalSamplesSeen = 100000; learningRatePerSample = 0.1; epochTime=0.435268s
08/18/2016 07:43:37: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/models/simple.dnn.10'

08/18/2016 07:43:37: Starting Epoch 11: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 11: samples [100000..110000] (first sequence at sample 100000), worker rank 0, total workers 1

08/18/2016 07:43:37: Starting minibatch loop.
08/18/2016 07:43:37:  Epoch[11 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.18568579 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0537s; samplesPerSecond = 23825.9
08/18/2016 07:43:37:  Epoch[11 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16320800 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0543s; samplesPerSecond = 23580.1
08/18/2016 07:43:37:  Epoch[11 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16654501 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0540s; samplesPerSecond = 23699.3
08/18/2016 07:43:37:  Epoch[11 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16168323 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0556s; samplesPerSecond = 23019.1
08/18/2016 07:43:37:  Epoch[11 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15500021 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0566s; samplesPerSecond = 22604.9
08/18/2016 07:43:37:  Epoch[11 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14945021 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0545s; samplesPerSecond = 23504.4
08/18/2016 07:43:37:  Epoch[11 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14351854 * 1280; EvalErrorPrediction = 0.06250000 * 1280; time = 0.0549s; samplesPerSecond = 23320.2
08/18/2016 07:43:37: Finished Epoch[11 of 50]: [Training] CrossEntropyWithSoftmax = 0.16356803 * 10000; EvalErrorPrediction = 0.07530000 * 10000; totalSamplesSeen = 110000; learningRatePerSample = 0.1; epochTime=0.430513s
08/18/2016 07:43:37: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/models/simple.dnn.11'

08/18/2016 07:43:37: Starting Epoch 12: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 12: samples [110000..120000] (first sequence at sample 110000), worker rank 0, total workers 1

08/18/2016 07:43:37: Starting minibatch loop.
08/18/2016 07:43:37:  Epoch[12 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.19238052 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0541s; samplesPerSecond = 23680.9
08/18/2016 07:43:37:  Epoch[12 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16844707 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0550s; samplesPerSecond = 23257.1
08/18/2016 07:43:37:  Epoch[12 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17573204 * 1280; EvalErrorPrediction = 0.08906250 * 1280; time = 0.0553s; samplesPerSecond = 23141.5
08/18/2016 07:43:37:  Epoch[12 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17776432 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0549s; samplesPerSecond = 23319.4
08/18/2016 07:43:37:  Epoch[12 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15835938 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0553s; samplesPerSecond = 23149.0
08/18/2016 07:43:37:  Epoch[12 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16589680 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0551s; samplesPerSecond = 23248.2
08/18/2016 07:43:37:  Epoch[12 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14364290 * 1280; EvalErrorPrediction = 0.06406250 * 1280; time = 0.0555s; samplesPerSecond = 23079.3
08/18/2016 07:43:37: Finished Epoch[12 of 50]: [Training] CrossEntropyWithSoftmax = 0.16862146 * 10000; EvalErrorPrediction = 0.08030000 * 10000; totalSamplesSeen = 120000; learningRatePerSample = 0.1; epochTime=0.432483s
08/18/2016 07:43:37: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/models/simple.dnn.12'

08/18/2016 07:43:37: Starting Epoch 13: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 13: samples [120000..130000] (first sequence at sample 120000), worker rank 0, total workers 1

08/18/2016 07:43:37: Starting minibatch loop.
08/18/2016 07:43:37:  Epoch[13 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15131066 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0577s; samplesPerSecond = 22194.9
08/18/2016 07:43:38:  Epoch[13 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.18000729 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0568s; samplesPerSecond = 22542.4
08/18/2016 07:43:38:  Epoch[13 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.18214641 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0540s; samplesPerSecond = 23689.2
08/18/2016 07:43:38:  Epoch[13 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14708543 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0546s; samplesPerSecond = 23454.8
08/18/2016 07:43:38:  Epoch[13 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16775689 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0563s; samplesPerSecond = 22737.8
08/18/2016 07:43:38:  Epoch[13 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17114563 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0555s; samplesPerSecond = 23046.9
08/18/2016 07:43:38:  Epoch[13 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15527258 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0562s; samplesPerSecond = 22788.4
08/18/2016 07:43:38: Finished Epoch[13 of 50]: [Training] CrossEntropyWithSoftmax = 0.16547717 * 10000; EvalErrorPrediction = 0.07730000 * 10000; totalSamplesSeen = 130000; learningRatePerSample = 0.1; epochTime=0.438919s
08/18/2016 07:43:38: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/models/simple.dnn.13'

08/18/2016 07:43:38: Starting Epoch 14: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 14: samples [130000..140000] (first sequence at sample 130000), worker rank 0, total workers 1

08/18/2016 07:43:38: Starting minibatch loop.
08/18/2016 07:43:38:  Epoch[14 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.21900370 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0542s; samplesPerSecond = 23595.3
08/18/2016 07:43:38:  Epoch[14 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.21172235 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0537s; samplesPerSecond = 23833.5
08/18/2016 07:43:38:  Epoch[14 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.22917652 * 1280; EvalErrorPrediction = 0.08906250 * 1280; time = 0.0549s; samplesPerSecond = 23302.0
08/18/2016 07:43:38:  Epoch[14 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.24510241 * 1280; EvalErrorPrediction = 0.09687500 * 1280; time = 0.0543s; samplesPerSecond = 23591.4
08/18/2016 07:43:38:  Epoch[14 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.20996208 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0554s; samplesPerSecond = 23096.8
08/18/2016 07:43:38:  Epoch[14 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15947275 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0539s; samplesPerSecond = 23745.5
08/18/2016 07:43:38:  Epoch[14 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16173429 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0553s; samplesPerSecond = 23136.9
08/18/2016 07:43:38: Finished Epoch[14 of 50]: [Training] CrossEntropyWithSoftmax = 0.20098314 * 10000; EvalErrorPrediction = 0.08100000 * 10000; totalSamplesSeen = 140000; learningRatePerSample = 0.1; epochTime=0.42871s
08/18/2016 07:43:38: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/models/simple.dnn.14'

08/18/2016 07:43:38: Starting Epoch 15: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 15: samples [140000..150000] (first sequence at sample 140000), worker rank 0, total workers 1

08/18/2016 07:43:38: Starting minibatch loop.
08/18/2016 07:43:38:  Epoch[15 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16884353 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0551s; samplesPerSecond = 23249.5
08/18/2016 07:43:38:  Epoch[15 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14229805 * 1280; EvalErrorPrediction = 0.06562500 * 1280; time = 0.0552s; samplesPerSecond = 23209.0
08/18/2016 07:43:38:  Epoch[15 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17884307 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0552s; samplesPerSecond = 23204.4
08/18/2016 07:43:39:  Epoch[15 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16690025 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0561s; samplesPerSecond = 22816.8
08/18/2016 07:43:39:  Epoch[15 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18277764 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0562s; samplesPerSecond = 22785.9
08/18/2016 07:43:39:  Epoch[15 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16112661 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0557s; samplesPerSecond = 22983.6
08/18/2016 07:43:39:  Epoch[15 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15518036 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0567s; samplesPerSecond = 22594.1
08/18/2016 07:43:39: Finished Epoch[15 of 50]: [Training] CrossEntropyWithSoftmax = 0.16386519 * 10000; EvalErrorPrediction = 0.07500000 * 10000; totalSamplesSeen = 150000; learningRatePerSample = 0.1; epochTime=0.437193s
08/18/2016 07:43:39: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/models/simple.dnn.15'

08/18/2016 07:43:39: Starting Epoch 16: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 16: samples [150000..160000] (first sequence at sample 150000), worker rank 0, total workers 1

08/18/2016 07:43:39: Starting minibatch loop.
08/18/2016 07:43:39:  Epoch[16 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16809491 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0540s; samplesPerSecond = 23704.6
08/18/2016 07:43:39:  Epoch[16 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15310568 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0548s; samplesPerSecond = 23357.7
08/18/2016 07:43:39:  Epoch[16 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.18207414 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0546s; samplesPerSecond = 23422.6
08/18/2016 07:43:39:  Epoch[16 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.19767089 * 1280; EvalErrorPrediction = 0.08828125 * 1280; time = 0.0549s; samplesPerSecond = 23327.0
08/18/2016 07:43:39:  Epoch[16 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.19895825 * 1280; EvalErrorPrediction = 0.09140625 * 1280; time = 0.0544s; samplesPerSecond = 23525.5
08/18/2016 07:43:39:  Epoch[16 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.19652357 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0558s; samplesPerSecond = 22954.7
08/18/2016 07:43:39:  Epoch[16 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.21215734 * 1280; EvalErrorPrediction = 0.09843750 * 1280; time = 0.0548s; samplesPerSecond = 23349.6
08/18/2016 07:43:39: Finished Epoch[16 of 50]: [Training] CrossEntropyWithSoftmax = 0.18783263 * 10000; EvalErrorPrediction = 0.08370000 * 10000; totalSamplesSeen = 160000; learningRatePerSample = 0.1; epochTime=0.430404s
08/18/2016 07:43:39: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/models/simple.dnn.16'

08/18/2016 07:43:39: Starting Epoch 17: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 17: samples [160000..170000] (first sequence at sample 160000), worker rank 0, total workers 1

08/18/2016 07:43:39: Starting minibatch loop.
08/18/2016 07:43:39:  Epoch[17 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.18662149 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0547s; samplesPerSecond = 23395.7
08/18/2016 07:43:39:  Epoch[17 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.19370583 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0543s; samplesPerSecond = 23560.2
08/18/2016 07:43:39:  Epoch[17 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.20847158 * 1280; EvalErrorPrediction = 0.09531250 * 1280; time = 0.0554s; samplesPerSecond = 23110.1
08/18/2016 07:43:39:  Epoch[17 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17158022 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0537s; samplesPerSecond = 23840.1
08/18/2016 07:43:39:  Epoch[17 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17116308 * 1280; EvalErrorPrediction = 0.08828125 * 1280; time = 0.0541s; samplesPerSecond = 23663.8
08/18/2016 07:43:40:  Epoch[17 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17138691 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0540s; samplesPerSecond = 23692.3
08/18/2016 07:43:40:  Epoch[17 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16964788 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0557s; samplesPerSecond = 22995.5
08/18/2016 07:43:40: Finished Epoch[17 of 50]: [Training] CrossEntropyWithSoftmax = 0.18152980 * 10000; EvalErrorPrediction = 0.08240000 * 10000; totalSamplesSeen = 170000; learningRatePerSample = 0.1; epochTime=0.429331s
08/18/2016 07:43:40: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/models/simple.dnn.17'

08/18/2016 07:43:40: Starting Epoch 18: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 18: samples [170000..180000] (first sequence at sample 170000), worker rank 0, total workers 1

08/18/2016 07:43:40: Starting minibatch loop.
08/18/2016 07:43:40:  Epoch[18 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15839990 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0553s; samplesPerSecond = 23165.7
08/18/2016 07:43:40:  Epoch[18 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16292278 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0556s; samplesPerSecond = 23024.1
08/18/2016 07:43:40:  Epoch[18 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16793890 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0557s; samplesPerSecond = 22979.8
08/18/2016 07:43:40:  Epoch[18 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15813804 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0545s; samplesPerSecond = 23479.8
08/18/2016 07:43:40:  Epoch[18 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15215302 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0549s; samplesPerSecond = 23330.4
08/18/2016 07:43:40:  Epoch[18 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15942945 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0552s; samplesPerSecond = 23173.7
08/18/2016 07:43:40:  Epoch[18 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15781574 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0559s; samplesPerSecond = 22891.9
08/18/2016 07:43:40: Finished Epoch[18 of 50]: [Training] CrossEntropyWithSoftmax = 0.15980331 * 10000; EvalErrorPrediction = 0.07450000 * 10000; totalSamplesSeen = 180000; learningRatePerSample = 0.1; epochTime=0.435056s
08/18/2016 07:43:40: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/models/simple.dnn.18'

08/18/2016 07:43:40: Starting Epoch 19: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 19: samples [180000..190000] (first sequence at sample 180000), worker rank 0, total workers 1

08/18/2016 07:43:40: Starting minibatch loop.
08/18/2016 07:43:40:  Epoch[19 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15393476 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0569s; samplesPerSecond = 22493.6
08/18/2016 07:43:40:  Epoch[19 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14663093 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0557s; samplesPerSecond = 22981.1
08/18/2016 07:43:40:  Epoch[19 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16556175 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0546s; samplesPerSecond = 23454.8
08/18/2016 07:43:40:  Epoch[19 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15092392 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0548s; samplesPerSecond = 23374.7
08/18/2016 07:43:40:  Epoch[19 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18200078 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0546s; samplesPerSecond = 23422.2
08/18/2016 07:43:40:  Epoch[19 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16241941 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0558s; samplesPerSecond = 22930.8
08/18/2016 07:43:40:  Epoch[19 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17173557 * 1280; EvalErrorPrediction = 0.08984375 * 1280; time = 0.0549s; samplesPerSecond = 23324.0
08/18/2016 07:43:41: Finished Epoch[19 of 50]: [Training] CrossEntropyWithSoftmax = 0.16261879 * 10000; EvalErrorPrediction = 0.07780000 * 10000; totalSamplesSeen = 190000; learningRatePerSample = 0.1; epochTime=0.435342s
08/18/2016 07:43:41: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/models/simple.dnn.19'

08/18/2016 07:43:41: Starting Epoch 20: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 20: samples [190000..200000] (first sequence at sample 190000), worker rank 0, total workers 1

08/18/2016 07:43:41: Starting minibatch loop.
08/18/2016 07:43:41:  Epoch[20 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16129819 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0554s; samplesPerSecond = 23103.0
08/18/2016 07:43:41:  Epoch[20 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16553568 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0549s; samplesPerSecond = 23304.5
08/18/2016 07:43:41:  Epoch[20 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16216450 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0552s; samplesPerSecond = 23182.1
08/18/2016 07:43:41:  Epoch[20 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17391176 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0552s; samplesPerSecond = 23197.7
08/18/2016 07:43:41:  Epoch[20 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16830420 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0541s; samplesPerSecond = 23681.3
08/18/2016 07:43:41:  Epoch[20 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15877714 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0544s; samplesPerSecond = 23530.7
08/18/2016 07:43:41:  Epoch[20 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16729193 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0549s; samplesPerSecond = 23321.9
08/18/2016 07:43:41: Finished Epoch[20 of 50]: [Training] CrossEntropyWithSoftmax = 0.16360972 * 10000; EvalErrorPrediction = 0.07680000 * 10000; totalSamplesSeen = 200000; learningRatePerSample = 0.1; epochTime=0.430403s
08/18/2016 07:43:41: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/models/simple.dnn.20'

08/18/2016 07:43:41: Starting Epoch 21: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 21: samples [200000..210000] (first sequence at sample 200000), worker rank 0, total workers 1

08/18/2016 07:43:41: Starting minibatch loop.
08/18/2016 07:43:41:  Epoch[21 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16338061 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0545s; samplesPerSecond = 23480.2
08/18/2016 07:43:41:  Epoch[21 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14520813 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0540s; samplesPerSecond = 23704.6
08/18/2016 07:43:41:  Epoch[21 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15791268 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0547s; samplesPerSecond = 23391.8
08/18/2016 07:43:41:  Epoch[21 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14244914 * 1280; EvalErrorPrediction = 0.06484375 * 1280; time = 0.0550s; samplesPerSecond = 23256.7
08/18/2016 07:43:41:  Epoch[21 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16053410 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0549s; samplesPerSecond = 23294.3
08/18/2016 07:43:41:  Epoch[21 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16650434 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0546s; samplesPerSecond = 23437.6
08/18/2016 07:43:41:  Epoch[21 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16314898 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0543s; samplesPerSecond = 23557.6
08/18/2016 07:43:41: Finished Epoch[21 of 50]: [Training] CrossEntropyWithSoftmax = 0.15772527 * 10000; EvalErrorPrediction = 0.07760000 * 10000; totalSamplesSeen = 210000; learningRatePerSample = 0.1; epochTime=0.428435s
08/18/2016 07:43:41: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/models/simple.dnn.21'

08/18/2016 07:43:41: Starting Epoch 22: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 22: samples [210000..220000] (first sequence at sample 210000), worker rank 0, total workers 1

08/18/2016 07:43:41: Starting minibatch loop.
08/18/2016 07:43:41:  Epoch[22 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15215702 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0592s; samplesPerSecond = 21635.9
08/18/2016 07:43:42:  Epoch[22 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13743281 * 1280; EvalErrorPrediction = 0.06171875 * 1280; time = 0.0655s; samplesPerSecond = 19535.4
08/18/2016 07:43:42:  Epoch[22 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16302943 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0556s; samplesPerSecond = 23016.6
08/18/2016 07:43:42:  Epoch[22 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16212945 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0559s; samplesPerSecond = 22897.2
08/18/2016 07:43:42:  Epoch[22 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15396323 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0558s; samplesPerSecond = 22920.6
08/18/2016 07:43:42:  Epoch[22 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14865255 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0555s; samplesPerSecond = 23071.4
08/18/2016 07:43:42:  Epoch[22 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18066330 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0556s; samplesPerSecond = 23026.6
08/18/2016 07:43:42: Finished Epoch[22 of 50]: [Training] CrossEntropyWithSoftmax = 0.15908649 * 10000; EvalErrorPrediction = 0.07470000 * 10000; totalSamplesSeen = 220000; learningRatePerSample = 0.1; epochTime=0.450545s
08/18/2016 07:43:42: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/models/simple.dnn.22'

08/18/2016 07:43:42: Starting Epoch 23: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 23: samples [220000..230000] (first sequence at sample 220000), worker rank 0, total workers 1

08/18/2016 07:43:42: Starting minibatch loop.
08/18/2016 07:43:42:  Epoch[23 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17810175 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0561s; samplesPerSecond = 22828.2
08/18/2016 07:43:42:  Epoch[23 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17201979 * 1280; EvalErrorPrediction = 0.09140625 * 1280; time = 0.0563s; samplesPerSecond = 22730.5
08/18/2016 07:43:42:  Epoch[23 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15118551 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0553s; samplesPerSecond = 23157.8
08/18/2016 07:43:42:  Epoch[23 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17852626 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0551s; samplesPerSecond = 23227.1
08/18/2016 07:43:42:  Epoch[23 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15494576 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0551s; samplesPerSecond = 23219.1
08/18/2016 07:43:42:  Epoch[23 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16574383 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0548s; samplesPerSecond = 23370.0
08/18/2016 07:43:42:  Epoch[23 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15394764 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0550s; samplesPerSecond = 23276.5
08/18/2016 07:43:42: Finished Epoch[23 of 50]: [Training] CrossEntropyWithSoftmax = 0.16411334 * 10000; EvalErrorPrediction = 0.07800000 * 10000; totalSamplesSeen = 230000; learningRatePerSample = 0.1; epochTime=0.433982s
08/18/2016 07:43:42: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/models/simple.dnn.23'

08/18/2016 07:43:42: Starting Epoch 24: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 24: samples [230000..240000] (first sequence at sample 230000), worker rank 0, total workers 1

08/18/2016 07:43:42: Starting minibatch loop.
08/18/2016 07:43:42:  Epoch[24 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16392395 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0543s; samplesPerSecond = 23584.9
08/18/2016 07:43:42:  Epoch[24 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17474854 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0541s; samplesPerSecond = 23670.0
08/18/2016 07:43:42:  Epoch[24 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14501925 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0547s; samplesPerSecond = 23399.9
08/18/2016 07:43:43:  Epoch[24 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.12699685 * 1280; EvalErrorPrediction = 0.05781250 * 1280; time = 0.0570s; samplesPerSecond = 22463.6
08/18/2016 07:43:43:  Epoch[24 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18087001 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0541s; samplesPerSecond = 23648.1
08/18/2016 07:43:43:  Epoch[24 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13314748 * 1280; EvalErrorPrediction = 0.05937500 * 1280; time = 0.0556s; samplesPerSecond = 23036.9
08/18/2016 07:43:43:  Epoch[24 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15527277 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0547s; samplesPerSecond = 23393.1
08/18/2016 07:43:43: Finished Epoch[24 of 50]: [Training] CrossEntropyWithSoftmax = 0.15477292 * 10000; EvalErrorPrediction = 0.07420000 * 10000; totalSamplesSeen = 240000; learningRatePerSample = 0.1; epochTime=0.431892s
08/18/2016 07:43:43: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/models/simple.dnn.24'

08/18/2016 07:43:43: Starting Epoch 25: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 25: samples [240000..250000] (first sequence at sample 240000), worker rank 0, total workers 1

08/18/2016 07:43:43: Starting minibatch loop.
08/18/2016 07:43:43:  Epoch[25 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.13738153 * 1280; EvalErrorPrediction = 0.06250000 * 1280; time = 0.0551s; samplesPerSecond = 23246.1
08/18/2016 07:43:43:  Epoch[25 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17392018 * 1280; EvalErrorPrediction = 0.09218750 * 1280; time = 0.0548s; samplesPerSecond = 23341.1
08/18/2016 07:43:43:  Epoch[25 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14000640 * 1280; EvalErrorPrediction = 0.06640625 * 1280; time = 0.0554s; samplesPerSecond = 23118.9
08/18/2016 07:43:43:  Epoch[25 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15249400 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0554s; samplesPerSecond = 23117.6
08/18/2016 07:43:43:  Epoch[25 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17014303 * 1280; EvalErrorPrediction = 0.08828125 * 1280; time = 0.0546s; samplesPerSecond = 23464.7
08/18/2016 07:43:43:  Epoch[25 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17271547 * 1280; EvalErrorPrediction = 0.08828125 * 1280; time = 0.0555s; samplesPerSecond = 23078.0
08/18/2016 07:43:43:  Epoch[25 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18483486 * 1280; EvalErrorPrediction = 0.10078125 * 1280; time = 0.0551s; samplesPerSecond = 23210.7
08/18/2016 07:43:43: Finished Epoch[25 of 50]: [Training] CrossEntropyWithSoftmax = 0.16432469 * 10000; EvalErrorPrediction = 0.08380000 * 10000; totalSamplesSeen = 250000; learningRatePerSample = 0.1; epochTime=0.43217s
08/18/2016 07:43:43: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/models/simple.dnn.25'

08/18/2016 07:43:43: Starting Epoch 26: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 26: samples [250000..260000] (first sequence at sample 250000), worker rank 0, total workers 1

08/18/2016 07:43:43: Starting minibatch loop.
08/18/2016 07:43:43:  Epoch[26 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17242832 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0543s; samplesPerSecond = 23574.9
08/18/2016 07:43:43:  Epoch[26 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.21459930 * 1280; EvalErrorPrediction = 0.09375000 * 1280; time = 0.0552s; samplesPerSecond = 23183.8
08/18/2016 07:43:43:  Epoch[26 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16780040 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0551s; samplesPerSecond = 23236.8
08/18/2016 07:43:43:  Epoch[26 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15442424 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0562s; samplesPerSecond = 22794.1
08/18/2016 07:43:43:  Epoch[26 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16801853 * 1280; EvalErrorPrediction = 0.09140625 * 1280; time = 0.0553s; samplesPerSecond = 23128.9
08/18/2016 07:43:44:  Epoch[26 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.12417669 * 1280; EvalErrorPrediction = 0.05312500 * 1280; time = 0.0545s; samplesPerSecond = 23495.3
08/18/2016 07:43:44:  Epoch[26 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16505795 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0554s; samplesPerSecond = 23106.4
08/18/2016 07:43:44: Finished Epoch[26 of 50]: [Training] CrossEntropyWithSoftmax = 0.16583668 * 10000; EvalErrorPrediction = 0.08000000 * 10000; totalSamplesSeen = 260000; learningRatePerSample = 0.1; epochTime=0.433124s
08/18/2016 07:43:44: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/models/simple.dnn.26'

08/18/2016 07:43:44: Starting Epoch 27: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 27: samples [260000..270000] (first sequence at sample 260000), worker rank 0, total workers 1

08/18/2016 07:43:44: Starting minibatch loop.
08/18/2016 07:43:44:  Epoch[27 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16580069 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0558s; samplesPerSecond = 22946.9
08/18/2016 07:43:44:  Epoch[27 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16926870 * 1280; EvalErrorPrediction = 0.09296875 * 1280; time = 0.0564s; samplesPerSecond = 22701.5
08/18/2016 07:43:44:  Epoch[27 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14731624 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0540s; samplesPerSecond = 23703.7
08/18/2016 07:43:44:  Epoch[27 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16391506 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0541s; samplesPerSecond = 23667.3
08/18/2016 07:43:44:  Epoch[27 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17033014 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0542s; samplesPerSecond = 23623.2
08/18/2016 07:43:44:  Epoch[27 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16041384 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0545s; samplesPerSecond = 23467.7
08/18/2016 07:43:44:  Epoch[27 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17107801 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0556s; samplesPerSecond = 23026.1
08/18/2016 07:43:44: Finished Epoch[27 of 50]: [Training] CrossEntropyWithSoftmax = 0.16273026 * 10000; EvalErrorPrediction = 0.07950000 * 10000; totalSamplesSeen = 270000; learningRatePerSample = 0.1; epochTime=0.430928s
08/18/2016 07:43:44: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/models/simple.dnn.27'

08/18/2016 07:43:44: Starting Epoch 28: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 28: samples [270000..280000] (first sequence at sample 270000), worker rank 0, total workers 1

08/18/2016 07:43:44: Starting minibatch loop.
08/18/2016 07:43:44:  Epoch[28 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15707815 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0543s; samplesPerSecond = 23588.8
08/18/2016 07:43:44:  Epoch[28 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16087980 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0557s; samplesPerSecond = 22993.9
08/18/2016 07:43:44:  Epoch[28 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16611364 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 0.0550s; samplesPerSecond = 23292.2
08/18/2016 07:43:44:  Epoch[28 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14507189 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0552s; samplesPerSecond = 23208.2
08/18/2016 07:43:44:  Epoch[28 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14170322 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0542s; samplesPerSecond = 23613.2
08/18/2016 07:43:44:  Epoch[28 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15535226 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0540s; samplesPerSecond = 23688.4
08/18/2016 07:43:44:  Epoch[28 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16404991 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0547s; samplesPerSecond = 23385.4
08/18/2016 07:43:45: Finished Epoch[28 of 50]: [Training] CrossEntropyWithSoftmax = 0.15698384 * 10000; EvalErrorPrediction = 0.07970000 * 10000; totalSamplesSeen = 280000; learningRatePerSample = 0.1; epochTime=0.430235s
08/18/2016 07:43:45: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/models/simple.dnn.28'

08/18/2016 07:43:45: Starting Epoch 29: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 29: samples [280000..290000] (first sequence at sample 280000), worker rank 0, total workers 1

08/18/2016 07:43:45: Starting minibatch loop.
08/18/2016 07:43:45:  Epoch[29 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15682557 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0554s; samplesPerSecond = 23108.4
08/18/2016 07:43:45:  Epoch[29 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13537197 * 1280; EvalErrorPrediction = 0.06484375 * 1280; time = 0.0553s; samplesPerSecond = 23156.9
08/18/2016 07:43:45:  Epoch[29 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17441618 * 1280; EvalErrorPrediction = 0.09453125 * 1280; time = 0.0557s; samplesPerSecond = 22997.2
08/18/2016 07:43:45:  Epoch[29 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14585423 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0542s; samplesPerSecond = 23629.8
08/18/2016 07:43:45:  Epoch[29 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16545286 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0536s; samplesPerSecond = 23902.4
08/18/2016 07:43:45:  Epoch[29 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14467678 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0545s; samplesPerSecond = 23473.7
08/18/2016 07:43:45:  Epoch[29 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16793623 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0561s; samplesPerSecond = 22826.6
08/18/2016 07:43:45: Finished Epoch[29 of 50]: [Training] CrossEntropyWithSoftmax = 0.16053500 * 10000; EvalErrorPrediction = 0.08080000 * 10000; totalSamplesSeen = 290000; learningRatePerSample = 0.1; epochTime=0.431397s
08/18/2016 07:43:45: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/models/simple.dnn.29'

08/18/2016 07:43:45: Starting Epoch 30: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 30: samples [290000..300000] (first sequence at sample 290000), worker rank 0, total workers 1

08/18/2016 07:43:45: Starting minibatch loop.
08/18/2016 07:43:45:  Epoch[30 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15942740 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0559s; samplesPerSecond = 22917.3
08/18/2016 07:43:45:  Epoch[30 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15095365 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0542s; samplesPerSecond = 23599.3
08/18/2016 07:43:45:  Epoch[30 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14841545 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0548s; samplesPerSecond = 23359.4
08/18/2016 07:43:45:  Epoch[30 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16833744 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 0.0553s; samplesPerSecond = 23134.3
08/18/2016 07:43:45:  Epoch[30 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15945673 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0564s; samplesPerSecond = 22691.4
08/18/2016 07:43:45:  Epoch[30 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16040192 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0550s; samplesPerSecond = 23263.4
08/18/2016 07:43:45:  Epoch[30 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16299820 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0549s; samplesPerSecond = 23311.3
08/18/2016 07:43:45: Finished Epoch[30 of 50]: [Training] CrossEntropyWithSoftmax = 0.15704203 * 10000; EvalErrorPrediction = 0.08010000 * 10000; totalSamplesSeen = 300000; learningRatePerSample = 0.1; epochTime=0.434369s
08/18/2016 07:43:45: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/models/simple.dnn.30'

08/18/2016 07:43:45: Starting Epoch 31: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 31: samples [300000..310000] (first sequence at sample 300000), worker rank 0, total workers 1

08/18/2016 07:43:45: Starting minibatch loop.
08/18/2016 07:43:45:  Epoch[31 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16174998 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0555s; samplesPerSecond = 23072.2
08/18/2016 07:43:46:  Epoch[31 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15350561 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0585s; samplesPerSecond = 21898.3
08/18/2016 07:43:46:  Epoch[31 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15347605 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0550s; samplesPerSecond = 23271.9
08/18/2016 07:43:46:  Epoch[31 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14528198 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0552s; samplesPerSecond = 23191.8
08/18/2016 07:43:46:  Epoch[31 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16926575 * 1280; EvalErrorPrediction = 0.08515625 * 1280; time = 0.0558s; samplesPerSecond = 22957.2
08/18/2016 07:43:46:  Epoch[31 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13906198 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0550s; samplesPerSecond = 23257.5
08/18/2016 07:43:46:  Epoch[31 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15153723 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0549s; samplesPerSecond = 23303.7
08/18/2016 07:43:46: Finished Epoch[31 of 50]: [Training] CrossEntropyWithSoftmax = 0.15330269 * 10000; EvalErrorPrediction = 0.07790000 * 10000; totalSamplesSeen = 310000; learningRatePerSample = 0.1; epochTime=0.438539s
08/18/2016 07:43:46: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/models/simple.dnn.31'

08/18/2016 07:43:46: Starting Epoch 32: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 32: samples [310000..320000] (first sequence at sample 310000), worker rank 0, total workers 1

08/18/2016 07:43:46: Starting minibatch loop.
08/18/2016 07:43:46:  Epoch[32 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15780182 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0550s; samplesPerSecond = 23275.3
08/18/2016 07:43:46:  Epoch[32 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14718969 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0559s; samplesPerSecond = 22880.0
08/18/2016 07:43:46:  Epoch[32 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14815490 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0552s; samplesPerSecond = 23201.0
08/18/2016 07:43:46:  Epoch[32 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15589647 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0548s; samplesPerSecond = 23350.0
08/18/2016 07:43:46:  Epoch[32 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15082045 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0559s; samplesPerSecond = 22913.2
08/18/2016 07:43:46:  Epoch[32 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15918269 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0543s; samplesPerSecond = 23590.1
08/18/2016 07:43:46:  Epoch[32 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15811920 * 1280; EvalErrorPrediction = 0.08515625 * 1280; time = 0.0552s; samplesPerSecond = 23170.8
08/18/2016 07:43:46: Finished Epoch[32 of 50]: [Training] CrossEntropyWithSoftmax = 0.15583013 * 10000; EvalErrorPrediction = 0.07920000 * 10000; totalSamplesSeen = 320000; learningRatePerSample = 0.1; epochTime=0.435317s
08/18/2016 07:43:46: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/models/simple.dnn.32'

08/18/2016 07:43:46: Starting Epoch 33: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 33: samples [320000..330000] (first sequence at sample 320000), worker rank 0, total workers 1

08/18/2016 07:43:46: Starting minibatch loop.
08/18/2016 07:43:46:  Epoch[33 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16428292 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0548s; samplesPerSecond = 23359.8
08/18/2016 07:43:46:  Epoch[33 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17547967 * 1280; EvalErrorPrediction = 0.09140625 * 1280; time = 0.0548s; samplesPerSecond = 23352.1
08/18/2016 07:43:46:  Epoch[33 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15117359 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0544s; samplesPerSecond = 23523.4
08/18/2016 07:43:47:  Epoch[33 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15776467 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0542s; samplesPerSecond = 23622.8
08/18/2016 07:43:47:  Epoch[33 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.13862848 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0553s; samplesPerSecond = 23126.8
08/18/2016 07:43:47:  Epoch[33 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14410787 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0553s; samplesPerSecond = 23127.2
08/18/2016 07:43:47:  Epoch[33 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16480093 * 1280; EvalErrorPrediction = 0.08984375 * 1280; time = 0.0569s; samplesPerSecond = 22479.0
08/18/2016 07:43:47: Finished Epoch[33 of 50]: [Training] CrossEntropyWithSoftmax = 0.15587941 * 10000; EvalErrorPrediction = 0.08000000 * 10000; totalSamplesSeen = 330000; learningRatePerSample = 0.1; epochTime=0.432648s
08/18/2016 07:43:47: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/models/simple.dnn.33'

08/18/2016 07:43:47: Starting Epoch 34: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 34: samples [330000..340000] (first sequence at sample 330000), worker rank 0, total workers 1

08/18/2016 07:43:47: Starting minibatch loop.
08/18/2016 07:43:47:  Epoch[34 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14667990 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0544s; samplesPerSecond = 23519.5
08/18/2016 07:43:47:  Epoch[34 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15634825 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0558s; samplesPerSecond = 22934.5
08/18/2016 07:43:47:  Epoch[34 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15693955 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0548s; samplesPerSecond = 23367.9
08/18/2016 07:43:47:  Epoch[34 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14793286 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0553s; samplesPerSecond = 23157.8
08/18/2016 07:43:47:  Epoch[34 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16621699 * 1280; EvalErrorPrediction = 0.09062500 * 1280; time = 0.0545s; samplesPerSecond = 23502.2
08/18/2016 07:43:47:  Epoch[34 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16044703 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0538s; samplesPerSecond = 23776.8
08/18/2016 07:43:47:  Epoch[34 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15663233 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0549s; samplesPerSecond = 23334.2
08/18/2016 07:43:47: Finished Epoch[34 of 50]: [Training] CrossEntropyWithSoftmax = 0.15420604 * 10000; EvalErrorPrediction = 0.07950000 * 10000; totalSamplesSeen = 340000; learningRatePerSample = 0.1; epochTime=0.429702s
08/18/2016 07:43:47: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/models/simple.dnn.34'

08/18/2016 07:43:47: Starting Epoch 35: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 35: samples [340000..350000] (first sequence at sample 340000), worker rank 0, total workers 1

08/18/2016 07:43:47: Starting minibatch loop.
08/18/2016 07:43:47:  Epoch[35 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16275167 * 1280; EvalErrorPrediction = 0.09218750 * 1280; time = 0.0551s; samplesPerSecond = 23214.9
08/18/2016 07:43:47:  Epoch[35 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14440117 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0556s; samplesPerSecond = 23028.6
08/18/2016 07:43:47:  Epoch[35 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14823112 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0554s; samplesPerSecond = 23114.3
08/18/2016 07:43:47:  Epoch[35 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14811258 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0564s; samplesPerSecond = 22687.0
08/18/2016 07:43:47:  Epoch[35 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14210854 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0568s; samplesPerSecond = 22542.0
08/18/2016 07:43:48:  Epoch[35 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14511356 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0548s; samplesPerSecond = 23355.5
08/18/2016 07:43:48:  Epoch[35 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15983601 * 1280; EvalErrorPrediction = 0.09218750 * 1280; time = 0.0548s; samplesPerSecond = 23351.7
08/18/2016 07:43:48: Finished Epoch[35 of 50]: [Training] CrossEntropyWithSoftmax = 0.15051633 * 10000; EvalErrorPrediction = 0.07740000 * 10000; totalSamplesSeen = 350000; learningRatePerSample = 0.1; epochTime=0.435145s
08/18/2016 07:43:48: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/models/simple.dnn.35'

08/18/2016 07:43:48: Starting Epoch 36: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 36: samples [350000..360000] (first sequence at sample 350000), worker rank 0, total workers 1

08/18/2016 07:43:48: Starting minibatch loop.
08/18/2016 07:43:48:  Epoch[36 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14917204 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0548s; samplesPerSecond = 23344.9
08/18/2016 07:43:48:  Epoch[36 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17716827 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 0.0546s; samplesPerSecond = 23434.2
08/18/2016 07:43:48:  Epoch[36 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15503080 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0557s; samplesPerSecond = 22991.0
08/18/2016 07:43:48:  Epoch[36 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15609474 * 1280; EvalErrorPrediction = 0.08515625 * 1280; time = 0.0542s; samplesPerSecond = 23603.6
08/18/2016 07:43:48:  Epoch[36 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15260749 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0543s; samplesPerSecond = 23579.7
08/18/2016 07:43:48:  Epoch[36 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13625846 * 1280; EvalErrorPrediction = 0.06562500 * 1280; time = 0.0549s; samplesPerSecond = 23305.4
08/18/2016 07:43:48:  Epoch[36 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14133377 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0550s; samplesPerSecond = 23255.0
08/18/2016 07:43:48: Finished Epoch[36 of 50]: [Training] CrossEntropyWithSoftmax = 0.15433484 * 10000; EvalErrorPrediction = 0.07960000 * 10000; totalSamplesSeen = 360000; learningRatePerSample = 0.1; epochTime=0.429548s
08/18/2016 07:43:48: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/models/simple.dnn.36'

08/18/2016 07:43:48: Starting Epoch 37: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 37: samples [360000..370000] (first sequence at sample 360000), worker rank 0, total workers 1

08/18/2016 07:43:48: Starting minibatch loop.
08/18/2016 07:43:48:  Epoch[37 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16840312 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 0.0550s; samplesPerSecond = 23270.2
08/18/2016 07:43:48:  Epoch[37 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14221466 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0548s; samplesPerSecond = 23375.6
08/18/2016 07:43:48:  Epoch[37 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15074725 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0554s; samplesPerSecond = 23116.4
08/18/2016 07:43:48:  Epoch[37 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.12537866 * 1280; EvalErrorPrediction = 0.05703125 * 1280; time = 0.0547s; samplesPerSecond = 23419.2
08/18/2016 07:43:48:  Epoch[37 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15708685 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0555s; samplesPerSecond = 23046.0
08/18/2016 07:43:48:  Epoch[37 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14255738 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0553s; samplesPerSecond = 23129.3
08/18/2016 07:43:48:  Epoch[37 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16219063 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0553s; samplesPerSecond = 23128.9
08/18/2016 07:43:49: Finished Epoch[37 of 50]: [Training] CrossEntropyWithSoftmax = 0.14977998 * 10000; EvalErrorPrediction = 0.07560000 * 10000; totalSamplesSeen = 370000; learningRatePerSample = 0.1; epochTime=0.433145s
08/18/2016 07:43:49: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/models/simple.dnn.37'

08/18/2016 07:43:49: Starting Epoch 38: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 38: samples [370000..380000] (first sequence at sample 370000), worker rank 0, total workers 1

08/18/2016 07:43:49: Starting minibatch loop.
08/18/2016 07:43:49:  Epoch[38 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16853067 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 0.0560s; samplesPerSecond = 22869.0
08/18/2016 07:43:49:  Epoch[38 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14644369 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0557s; samplesPerSecond = 22965.8
08/18/2016 07:43:49:  Epoch[38 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14097180 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0554s; samplesPerSecond = 23124.3
08/18/2016 07:43:49:  Epoch[38 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16173196 * 1280; EvalErrorPrediction = 0.08906250 * 1280; time = 0.0547s; samplesPerSecond = 23405.9
08/18/2016 07:43:49:  Epoch[38 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.13763905 * 1280; EvalErrorPrediction = 0.06640625 * 1280; time = 0.0537s; samplesPerSecond = 23855.2
08/18/2016 07:43:49:  Epoch[38 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15780435 * 1280; EvalErrorPrediction = 0.09062500 * 1280; time = 0.0546s; samplesPerSecond = 23431.6
08/18/2016 07:43:49:  Epoch[38 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.13848314 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0549s; samplesPerSecond = 23308.3
08/18/2016 07:43:49: Finished Epoch[38 of 50]: [Training] CrossEntropyWithSoftmax = 0.15009000 * 10000; EvalErrorPrediction = 0.07940000 * 10000; totalSamplesSeen = 380000; learningRatePerSample = 0.1; epochTime=0.432479s
08/18/2016 07:43:49: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/models/simple.dnn.38'

08/18/2016 07:43:49: Starting Epoch 39: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 39: samples [380000..390000] (first sequence at sample 380000), worker rank 0, total workers 1

08/18/2016 07:43:49: Starting minibatch loop.
08/18/2016 07:43:49:  Epoch[39 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14604163 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0555s; samplesPerSecond = 23064.3
08/18/2016 07:43:49:  Epoch[39 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14159646 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0538s; samplesPerSecond = 23780.8
08/18/2016 07:43:49:  Epoch[39 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15176196 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0556s; samplesPerSecond = 23020.8
08/18/2016 07:43:49:  Epoch[39 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15482063 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0544s; samplesPerSecond = 23509.5
08/18/2016 07:43:49:  Epoch[39 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16664176 * 1280; EvalErrorPrediction = 0.08906250 * 1280; time = 0.0540s; samplesPerSecond = 23718.2
08/18/2016 07:43:49:  Epoch[39 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.18571091 * 1280; EvalErrorPrediction = 0.09062500 * 1280; time = 0.0541s; samplesPerSecond = 23646.3
08/18/2016 07:43:49:  Epoch[39 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.19005480 * 1280; EvalErrorPrediction = 0.09687500 * 1280; time = 0.0551s; samplesPerSecond = 23251.6
08/18/2016 07:43:49: Finished Epoch[39 of 50]: [Training] CrossEntropyWithSoftmax = 0.16020200 * 10000; EvalErrorPrediction = 0.08150000 * 10000; totalSamplesSeen = 390000; learningRatePerSample = 0.1; epochTime=0.430257s
08/18/2016 07:43:49: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/models/simple.dnn.39'

08/18/2016 07:43:49: Starting Epoch 40: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 40: samples [390000..400000] (first sequence at sample 390000), worker rank 0, total workers 1

08/18/2016 07:43:49: Starting minibatch loop.
08/18/2016 07:43:49:  Epoch[40 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.18148261 * 1280; EvalErrorPrediction = 0.09531250 * 1280; time = 0.0611s; samplesPerSecond = 20954.1
08/18/2016 07:43:50:  Epoch[40 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15084592 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0624s; samplesPerSecond = 20511.8
08/18/2016 07:43:50:  Epoch[40 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15694163 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0545s; samplesPerSecond = 23491.4
08/18/2016 07:43:50:  Epoch[40 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15859671 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0566s; samplesPerSecond = 22617.6
08/18/2016 07:43:50:  Epoch[40 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16060653 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0554s; samplesPerSecond = 23098.4
08/18/2016 07:43:50:  Epoch[40 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16118555 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0556s; samplesPerSecond = 23013.7
08/18/2016 07:43:50:  Epoch[40 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14262094 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0547s; samplesPerSecond = 23385.0
08/18/2016 07:43:50: Finished Epoch[40 of 50]: [Training] CrossEntropyWithSoftmax = 0.15676152 * 10000; EvalErrorPrediction = 0.07940000 * 10000; totalSamplesSeen = 400000; learningRatePerSample = 0.1; epochTime=0.447049s
08/18/2016 07:43:50: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/models/simple.dnn.40'

08/18/2016 07:43:50: Starting Epoch 41: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 41: samples [400000..410000] (first sequence at sample 400000), worker rank 0, total workers 1

08/18/2016 07:43:50: Starting minibatch loop.
08/18/2016 07:43:50:  Epoch[41 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16488271 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0542s; samplesPerSecond = 23617.1
08/18/2016 07:43:50:  Epoch[41 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13255506 * 1280; EvalErrorPrediction = 0.06328125 * 1280; time = 0.0554s; samplesPerSecond = 23124.3
08/18/2016 07:43:50:  Epoch[41 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14599433 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0536s; samplesPerSecond = 23900.2
08/18/2016 07:43:50:  Epoch[41 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15061898 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0543s; samplesPerSecond = 23577.5
08/18/2016 07:43:50:  Epoch[41 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14728255 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0548s; samplesPerSecond = 23361.1
08/18/2016 07:43:50:  Epoch[41 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14453835 * 1280; EvalErrorPrediction = 0.06484375 * 1280; time = 0.0542s; samplesPerSecond = 23636.3
08/18/2016 07:43:50:  Epoch[41 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15256748 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0567s; samplesPerSecond = 22580.1
08/18/2016 07:43:50: Finished Epoch[41 of 50]: [Training] CrossEntropyWithSoftmax = 0.14739017 * 10000; EvalErrorPrediction = 0.07340000 * 10000; totalSamplesSeen = 410000; learningRatePerSample = 0.1; epochTime=0.430374s
08/18/2016 07:43:50: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/models/simple.dnn.41'

08/18/2016 07:43:50: Starting Epoch 42: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 42: samples [410000..420000] (first sequence at sample 410000), worker rank 0, total workers 1

08/18/2016 07:43:50: Starting minibatch loop.
08/18/2016 07:43:50:  Epoch[42 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14050791 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0543s; samplesPerSecond = 23578.4
08/18/2016 07:43:50:  Epoch[42 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14012403 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0546s; samplesPerSecond = 23423.5
08/18/2016 07:43:50:  Epoch[42 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15301588 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0555s; samplesPerSecond = 23062.2
08/18/2016 07:43:51:  Epoch[42 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14769430 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0560s; samplesPerSecond = 22840.4
08/18/2016 07:43:51:  Epoch[42 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15724902 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0563s; samplesPerSecond = 22742.6
08/18/2016 07:43:51:  Epoch[42 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15916276 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0543s; samplesPerSecond = 23584.0
08/18/2016 07:43:51:  Epoch[42 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18247223 * 1280; EvalErrorPrediction = 0.09687500 * 1280; time = 0.0545s; samplesPerSecond = 23489.3
08/18/2016 07:43:51: Finished Epoch[42 of 50]: [Training] CrossEntropyWithSoftmax = 0.15400946 * 10000; EvalErrorPrediction = 0.07950000 * 10000; totalSamplesSeen = 420000; learningRatePerSample = 0.1; epochTime=0.431671s
08/18/2016 07:43:51: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/models/simple.dnn.42'

08/18/2016 07:43:51: Starting Epoch 43: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 43: samples [420000..430000] (first sequence at sample 420000), worker rank 0, total workers 1

08/18/2016 07:43:51: Starting minibatch loop.
08/18/2016 07:43:51:  Epoch[43 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16290520 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 0.0559s; samplesPerSecond = 22903.8
08/18/2016 07:43:51:  Epoch[43 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.12217406 * 1280; EvalErrorPrediction = 0.06328125 * 1280; time = 0.0551s; samplesPerSecond = 23217.8
08/18/2016 07:43:51:  Epoch[43 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14747345 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0565s; samplesPerSecond = 22652.1
08/18/2016 07:43:51:  Epoch[43 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15295262 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0545s; samplesPerSecond = 23497.4
08/18/2016 07:43:51:  Epoch[43 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15701523 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0554s; samplesPerSecond = 23109.3
08/18/2016 07:43:51:  Epoch[43 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14177365 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0538s; samplesPerSecond = 23780.8
08/18/2016 07:43:51:  Epoch[43 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17111530 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0555s; samplesPerSecond = 23079.7
08/18/2016 07:43:51: Finished Epoch[43 of 50]: [Training] CrossEntropyWithSoftmax = 0.14959976 * 10000; EvalErrorPrediction = 0.07820000 * 10000; totalSamplesSeen = 430000; learningRatePerSample = 0.1; epochTime=0.43358s
08/18/2016 07:43:51: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/models/simple.dnn.43'

08/18/2016 07:43:51: Starting Epoch 44: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 44: samples [430000..440000] (first sequence at sample 430000), worker rank 0, total workers 1

08/18/2016 07:43:51: Starting minibatch loop.
08/18/2016 07:43:51:  Epoch[44 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16002653 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0547s; samplesPerSecond = 23402.5
08/18/2016 07:43:51:  Epoch[44 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15523703 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0561s; samplesPerSecond = 22836.8
08/18/2016 07:43:51:  Epoch[44 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.13000937 * 1280; EvalErrorPrediction = 0.06171875 * 1280; time = 0.0539s; samplesPerSecond = 23735.4
08/18/2016 07:43:51:  Epoch[44 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14639573 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0547s; samplesPerSecond = 23390.1
08/18/2016 07:43:51:  Epoch[44 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14898019 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0553s; samplesPerSecond = 23162.4
08/18/2016 07:43:52:  Epoch[44 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13171577 * 1280; EvalErrorPrediction = 0.06015625 * 1280; time = 0.0537s; samplesPerSecond = 23854.3
08/18/2016 07:43:52:  Epoch[44 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15750151 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0546s; samplesPerSecond = 23423.1
08/18/2016 07:43:52: Finished Epoch[44 of 50]: [Training] CrossEntropyWithSoftmax = 0.14805371 * 10000; EvalErrorPrediction = 0.07370000 * 10000; totalSamplesSeen = 440000; learningRatePerSample = 0.1; epochTime=0.430764s
08/18/2016 07:43:52: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/models/simple.dnn.44'

08/18/2016 07:43:52: Starting Epoch 45: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 45: samples [440000..450000] (first sequence at sample 440000), worker rank 0, total workers 1

08/18/2016 07:43:52: Starting minibatch loop.
08/18/2016 07:43:52:  Epoch[45 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17799401 * 1280; EvalErrorPrediction = 0.09453125 * 1280; time = 0.0549s; samplesPerSecond = 23328.3
08/18/2016 07:43:52:  Epoch[45 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14361689 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0549s; samplesPerSecond = 23324.9
08/18/2016 07:43:52:  Epoch[45 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15862920 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0556s; samplesPerSecond = 23036.1
08/18/2016 07:43:52:  Epoch[45 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15261703 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0537s; samplesPerSecond = 23828.1
08/18/2016 07:43:52:  Epoch[45 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14748673 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0554s; samplesPerSecond = 23085.9
08/18/2016 07:43:52:  Epoch[45 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13471236 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0546s; samplesPerSecond = 23429.1
08/18/2016 07:43:52:  Epoch[45 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15045977 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 0.0542s; samplesPerSecond = 23621.0
08/18/2016 07:43:52: Finished Epoch[45 of 50]: [Training] CrossEntropyWithSoftmax = 0.15047111 * 10000; EvalErrorPrediction = 0.07730000 * 10000; totalSamplesSeen = 450000; learningRatePerSample = 0.1; epochTime=0.430657s
08/18/2016 07:43:52: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/models/simple.dnn.45'

08/18/2016 07:43:52: Starting Epoch 46: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 46: samples [450000..460000] (first sequence at sample 450000), worker rank 0, total workers 1

08/18/2016 07:43:52: Starting minibatch loop.
08/18/2016 07:43:52:  Epoch[46 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.12665794 * 1280; EvalErrorPrediction = 0.05937500 * 1280; time = 0.0564s; samplesPerSecond = 22681.8
08/18/2016 07:43:52:  Epoch[46 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16435876 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0560s; samplesPerSecond = 22858.0
08/18/2016 07:43:52:  Epoch[46 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14386027 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0555s; samplesPerSecond = 23050.6
08/18/2016 07:43:52:  Epoch[46 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.13880796 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0554s; samplesPerSecond = 23118.5
08/18/2016 07:43:52:  Epoch[46 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14249053 * 1280; EvalErrorPrediction = 0.06562500 * 1280; time = 0.0551s; samplesPerSecond = 23239.3
08/18/2016 07:43:52:  Epoch[46 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14793310 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0538s; samplesPerSecond = 23801.6
08/18/2016 07:43:52:  Epoch[46 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15110197 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0552s; samplesPerSecond = 23209.0
08/18/2016 07:43:53: Finished Epoch[46 of 50]: [Training] CrossEntropyWithSoftmax = 0.14531976 * 10000; EvalErrorPrediction = 0.07110000 * 10000; totalSamplesSeen = 460000; learningRatePerSample = 0.1; epochTime=0.435222s
08/18/2016 07:43:53: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/models/simple.dnn.46'

08/18/2016 07:43:53: Starting Epoch 47: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 47: samples [460000..470000] (first sequence at sample 460000), worker rank 0, total workers 1

08/18/2016 07:43:53: Starting minibatch loop.
08/18/2016 07:43:53:  Epoch[47 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14704782 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0551s; samplesPerSecond = 23221.6
08/18/2016 07:43:53:  Epoch[47 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15385925 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0547s; samplesPerSecond = 23406.8
08/18/2016 07:43:53:  Epoch[47 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15467451 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 0.0558s; samplesPerSecond = 22950.2
08/18/2016 07:43:53:  Epoch[47 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.11875844 * 1280; EvalErrorPrediction = 0.06484375 * 1280; time = 0.0555s; samplesPerSecond = 23072.2
08/18/2016 07:43:53:  Epoch[47 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.13453021 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0543s; samplesPerSecond = 23567.1
08/18/2016 07:43:53:  Epoch[47 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15136251 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0560s; samplesPerSecond = 22862.5
08/18/2016 07:43:53:  Epoch[47 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.13608885 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0545s; samplesPerSecond = 23505.6
08/18/2016 07:43:53: Finished Epoch[47 of 50]: [Training] CrossEntropyWithSoftmax = 0.14234089 * 10000; EvalErrorPrediction = 0.07680000 * 10000; totalSamplesSeen = 470000; learningRatePerSample = 0.1; epochTime=0.433024s
08/18/2016 07:43:53: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/models/simple.dnn.47'

08/18/2016 07:43:53: Starting Epoch 48: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 48: samples [470000..480000] (first sequence at sample 470000), worker rank 0, total workers 1

08/18/2016 07:43:53: Starting minibatch loop.
08/18/2016 07:43:53:  Epoch[48 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14786462 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0556s; samplesPerSecond = 23031.1
08/18/2016 07:43:53:  Epoch[48 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14770790 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0555s; samplesPerSecond = 23056.4
08/18/2016 07:43:53:  Epoch[48 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14863453 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0546s; samplesPerSecond = 23457.4
08/18/2016 07:43:53:  Epoch[48 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14011574 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0554s; samplesPerSecond = 23120.1
08/18/2016 07:43:53:  Epoch[48 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14018188 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0550s; samplesPerSecond = 23259.6
08/18/2016 07:43:53:  Epoch[48 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14272261 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0562s; samplesPerSecond = 22773.0
08/18/2016 07:43:53:  Epoch[48 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.12746716 * 1280; EvalErrorPrediction = 0.06406250 * 1280; time = 0.0561s; samplesPerSecond = 22821.7
08/18/2016 07:43:53: Finished Epoch[48 of 50]: [Training] CrossEntropyWithSoftmax = 0.14266086 * 10000; EvalErrorPrediction = 0.07220000 * 10000; totalSamplesSeen = 480000; learningRatePerSample = 0.1; epochTime=0.436093s
08/18/2016 07:43:53: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/models/simple.dnn.48'

08/18/2016 07:43:53: Starting Epoch 49: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 49: samples [480000..490000] (first sequence at sample 480000), worker rank 0, total workers 1

08/18/2016 07:43:53: Starting minibatch loop.
08/18/2016 07:43:53:  Epoch[49 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15699010 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0568s; samplesPerSecond = 22517.0
08/18/2016 07:43:54:  Epoch[49 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.12933590 * 1280; EvalErrorPrediction = 0.06640625 * 1280; time = 0.0568s; samplesPerSecond = 22532.8
08/18/2016 07:43:54:  Epoch[49 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14571927 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0554s; samplesPerSecond = 23116.4
08/18/2016 07:43:54:  Epoch[49 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14288797 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0549s; samplesPerSecond = 23307.9
08/18/2016 07:43:54:  Epoch[49 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14050188 * 1280; EvalErrorPrediction = 0.06406250 * 1280; time = 0.0549s; samplesPerSecond = 23319.4
08/18/2016 07:43:54:  Epoch[49 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13541965 * 1280; EvalErrorPrediction = 0.06015625 * 1280; time = 0.0550s; samplesPerSecond = 23255.0
08/18/2016 07:43:54:  Epoch[49 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16449451 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0554s; samplesPerSecond = 23120.1
08/18/2016 07:43:54: Finished Epoch[49 of 50]: [Training] CrossEntropyWithSoftmax = 0.14475691 * 10000; EvalErrorPrediction = 0.07090000 * 10000; totalSamplesSeen = 490000; learningRatePerSample = 0.1; epochTime=0.435776s
08/18/2016 07:43:54: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/models/simple.dnn.49'

08/18/2016 07:43:54: Starting Epoch 50: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 50: samples [490000..500000] (first sequence at sample 490000), worker rank 0, total workers 1

08/18/2016 07:43:54: Starting minibatch loop.
08/18/2016 07:43:54:  Epoch[50 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14711518 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0561s; samplesPerSecond = 22806.6
08/18/2016 07:43:54:  Epoch[50 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13556859 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0556s; samplesPerSecond = 23008.3
08/18/2016 07:43:54:  Epoch[50 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.13794715 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0554s; samplesPerSecond = 23103.0
08/18/2016 07:43:54:  Epoch[50 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14867358 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0544s; samplesPerSecond = 23537.2
08/18/2016 07:43:54:  Epoch[50 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.13444343 * 1280; EvalErrorPrediction = 0.06640625 * 1280; time = 0.0533s; samplesPerSecond = 24028.5
08/18/2016 07:43:54:  Epoch[50 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14466057 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0541s; samplesPerSecond = 23656.8
08/18/2016 07:43:54:  Epoch[50 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14758101 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0547s; samplesPerSecond = 23403.8
08/18/2016 07:43:54: Finished Epoch[50 of 50]: [Training] CrossEntropyWithSoftmax = 0.14189413 * 10000; EvalErrorPrediction = 0.07380000 * 10000; totalSamplesSeen = 500000; learningRatePerSample = 0.1; epochTime=0.42982s
08/18/2016 07:43:54: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/models/simple.dnn'
08/18/2016 07:43:54: CNTKCommandTrainEnd: Simple_Demo

08/18/2016 07:43:54: Action "train" complete.


08/18/2016 07:43:54: ##############################################################################
08/18/2016 07:43:54: #                                                                            #
08/18/2016 07:43:54: # Action "write"                                                             #
08/18/2016 07:43:54: #                                                                            #
08/18/2016 07:43:54: ##############################################################################


Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalErrorPrediction = ErrorPrediction()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *1]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *1]
Validating --> MeanOfFeatures = Mean (features) : [2 x *1] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *1] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *1], [2], [2] -> [2 x *1]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *1] -> [50 x *1]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *1] -> [2 x 1 x *1]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *1], [2 x 1] -> [2 x 1 x *1]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *1] -> [2 x 1 x *1]
Validating --> Prior = Mean (labels) : [2 x *1] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *1], [2] -> [2 x 1 x *1]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.



Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 25 matrices, 3 are shared as 1, and 22 are not shared.

	{ CrossEntropyWithSoftmax : [1]
	  EvalErrorPrediction : [1]
	  PosteriorProb : [2 x 1 x *1] }

Minibatch[0]: ActualMBSize = 603
Written to C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/SimpleOutput*
Total Samples Evaluated = 603

08/18/2016 07:43:54: Action "write" complete.

08/18/2016 07:43:54: __COMPLETED__
=== Deleting last epoch data
==== Re-running from checkpoint
=== Running /cygdrive/c/jenkins/workspace/CNTK-Test-Windows-W1/x64/release/cntk.exe configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple/cntk.cntk currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu DeviceId=-1 timestamping=true makeMode=true
-------------------------------------------------------------------
Build info: 

		Built time: Aug 18 2016 06:54:41
		Last modified date: Thu Aug 18 03:27:57 2016
		Build type: Release
		Build target: GPU
		With 1bit-SGD: no
		Math lib: mkl
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
		CUB_PATH: C:\src\cub-1.4.1
		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
		Build Branch: HEAD
		Build SHA1: ac4da60ce4c7318dc6e020a8a97afa5c6952dfce
		Built by svcphil on dphaim-26-new
		Build Path: c:\jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
-------------------------------------------------------------------
Changed current directory to C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
08/18/2016 07:43:55: -------------------------------------------------------------------
08/18/2016 07:43:55: Build info: 

08/18/2016 07:43:55: 		Built time: Aug 18 2016 06:54:41
08/18/2016 07:43:55: 		Last modified date: Thu Aug 18 03:27:57 2016
08/18/2016 07:43:55: 		Build type: Release
08/18/2016 07:43:55: 		Build target: GPU
08/18/2016 07:43:55: 		With 1bit-SGD: no
08/18/2016 07:43:55: 		Math lib: mkl
08/18/2016 07:43:55: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
08/18/2016 07:43:55: 		CUB_PATH: C:\src\cub-1.4.1
08/18/2016 07:43:55: 		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
08/18/2016 07:43:55: 		Build Branch: HEAD
08/18/2016 07:43:55: 		Build SHA1: ac4da60ce4c7318dc6e020a8a97afa5c6952dfce
08/18/2016 07:43:55: 		Built by svcphil on dphaim-26-new
08/18/2016 07:43:55: 		Build Path: c:\jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
08/18/2016 07:43:55: -------------------------------------------------------------------
08/18/2016 07:43:59: -------------------------------------------------------------------
08/18/2016 07:43:59: GPU info:

08/18/2016 07:43:59: 		Device[0]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3072 MB
08/18/2016 07:43:59: 		Device[1]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3072 MB
08/18/2016 07:43:59: 		Device[2]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3072 MB
08/18/2016 07:43:59: 		Device[3]: cores = 2880; computeCapability = 3.5; type = "GeForce GTX 780 Ti"; memory = 3072 MB
08/18/2016 07:43:59: -------------------------------------------------------------------

08/18/2016 07:43:59: Running on DPHAIM-24 at 2016/08/18 07:43:59
08/18/2016 07:43:59: Command line: 
C:\jenkins\workspace\CNTK-Test-Windows-W1\x64\release\cntk.exe  configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple/cntk.cntk  currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data  RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu  DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data  ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple  OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu  DeviceId=-1  timestamping=true  makeMode=true



08/18/2016 07:43:59: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
08/18/2016 07:43:59: command=Simple_Demo:Simple_Demo_Output
DeviceNumber=-1
precision=float
modelPath=$RunDir$/models/simple.dnn
deviceId=$DeviceNumber$
outputNodeNames=ScaledLogLikelihood
traceLevel=1
Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=$DataDir$/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]
Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=$DataDir$/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=$RunDir$/SimpleOutput    
]
currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu
DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple
OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu
DeviceId=-1
timestamping=true
makeMode=true

08/18/2016 07:43:59: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<

08/18/2016 07:43:59: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
08/18/2016 07:43:59: command=Simple_Demo:Simple_Demo_Output
DeviceNumber=-1
precision=float
modelPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/models/simple.dnn
deviceId=-1
outputNodeNames=ScaledLogLikelihood
traceLevel=1
Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]
Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/SimpleOutput    
]
currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu
DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple
OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu
DeviceId=-1
timestamping=true
makeMode=true

08/18/2016 07:43:59: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<

08/18/2016 07:43:59: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
configparameters: cntk.cntk:command=Simple_Demo:Simple_Demo_Output
configparameters: cntk.cntk:ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple
configparameters: cntk.cntk:currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
configparameters: cntk.cntk:DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
configparameters: cntk.cntk:deviceId=-1
configparameters: cntk.cntk:DeviceNumber=-1
configparameters: cntk.cntk:makeMode=true
configparameters: cntk.cntk:modelPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/models/simple.dnn
configparameters: cntk.cntk:OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu
configparameters: cntk.cntk:outputNodeNames=ScaledLogLikelihood
configparameters: cntk.cntk:precision=float
configparameters: cntk.cntk:RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu
configparameters: cntk.cntk:Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]

configparameters: cntk.cntk:Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/SimpleOutput    
]

configparameters: cntk.cntk:timestamping=true
configparameters: cntk.cntk:traceLevel=1
08/18/2016 07:43:59: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
08/18/2016 07:43:59: Commands: Simple_Demo Simple_Demo_Output
08/18/2016 07:43:59: Precision = "float"
08/18/2016 07:43:59: CNTKModelPath: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/models/simple.dnn
08/18/2016 07:43:59: CNTKCommandTrainInfo: Simple_Demo : 50
08/18/2016 07:43:59: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 50

08/18/2016 07:43:59: ##############################################################################
08/18/2016 07:43:59: #                                                                            #
08/18/2016 07:43:59: # Action "train"                                                             #
08/18/2016 07:43:59: #                                                                            #
08/18/2016 07:43:59: ##############################################################################

08/18/2016 07:43:59: CNTKCommandTrainBegin: Simple_Demo
SimpleNetworkBuilder Using CPU

08/18/2016 07:43:59: Starting from checkpoint. Loading network from 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/models/simple.dnn.49'.

Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalErrorPrediction = ErrorPrediction()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *1]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *1]
Validating --> MeanOfFeatures = Mean (features) : [2 x *1] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *1] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *1], [2], [2] -> [2 x *1]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *1] -> [50 x *1]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *1] -> [2 x 1 x *1]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *1], [2 x 1] -> [2 x 1 x *1]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *1] -> [2 x 1 x *1]
Validating --> Prior = Mean (labels) : [2 x *1] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *1], [2] -> [2 x 1 x *1]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

08/18/2016 07:43:59: Loaded model with 25 nodes on CPU.

08/18/2016 07:43:59: Training criterion node(s):
08/18/2016 07:43:59: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax

08/18/2016 07:43:59: Evaluation criterion node(s):
08/18/2016 07:43:59: 	EvalErrorPrediction = ErrorPrediction


Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 40 matrices, 19 are shared as 8, and 21 are not shared.

	{ H2 : [50 x 1 x *1]
	  W1*H1 : [50 x 1 x *1] (gradient) }
	{ W0*features+B0 : [50 x 1 x *1] (gradient)
	  W1*H1 : [50 x 1 x *1] }
	{ B0 : [50 x 1] (gradient)
	  H1 : [50 x 1 x *1] (gradient)
	  W1*H1+B1 : [50 x 1 x *1] (gradient)
	  W2*H1 : [2 x 1 x *1] }
	{ HLast : [2 x 1 x *1]
	  W2 : [2 x 50] (gradient) }
	{ B1 : [50 x 1] (gradient)
	  H2 : [50 x 1 x *1] (gradient)
	  HLast : [2 x 1 x *1] (gradient) }
	{ W0 : [50 x 2] (gradient)
	  W0*features+B0 : [50 x 1 x *1] }
	{ H1 : [50 x 1 x *1]
	  W0*features : [50 x *1] (gradient) }
	{ W1 : [50 x 50] (gradient)
	  W1*H1+B1 : [50 x 1 x *1] }


08/18/2016 07:43:59: Training 2802 parameters in 6 out of 6 parameter tensors and 15 nodes with gradient:

08/18/2016 07:43:59: 	Node 'B0' (LearnableParameter operation) : [50 x 1]
08/18/2016 07:43:59: 	Node 'B1' (LearnableParameter operation) : [50 x 1]
08/18/2016 07:43:59: 	Node 'B2' (LearnableParameter operation) : [2 x 1]
08/18/2016 07:43:59: 	Node 'W0' (LearnableParameter operation) : [50 x 2]
08/18/2016 07:43:59: 	Node 'W1' (LearnableParameter operation) : [50 x 50]
08/18/2016 07:43:59: 	Node 'W2' (LearnableParameter operation) : [2 x 50]

08/18/2016 07:43:59: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

08/18/2016 07:43:59: Starting Epoch 50: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 50: samples [490000..500000] (first sequence at sample 490000), worker rank 0, total workers 1

08/18/2016 07:43:59: Starting minibatch loop.
08/18/2016 07:43:59:  Epoch[50 of 50]-Minibatch[   1-  10, 0.00000000000003%]: CrossEntropyWithSoftmax = 0.14711518 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0837s; samplesPerSecond = 15296.9
08/18/2016 07:43:59:  Epoch[50 of 50]-Minibatch[  11-  20, 0.00000000000006%]: CrossEntropyWithSoftmax = 0.13556859 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0618s; samplesPerSecond = 20696.2
08/18/2016 07:43:59:  Epoch[50 of 50]-Minibatch[  21-  30, 0.00000000000008%]: CrossEntropyWithSoftmax = 0.13794715 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0605s; samplesPerSecond = 21140.6
08/18/2016 07:43:59:  Epoch[50 of 50]-Minibatch[  31-  40, 0.00000000000011%]: CrossEntropyWithSoftmax = 0.14867358 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0600s; samplesPerSecond = 21325.5
08/18/2016 07:43:59:  Epoch[50 of 50]-Minibatch[  41-  50, 0.00000000000014%]: CrossEntropyWithSoftmax = 0.13444343 * 1280; EvalErrorPrediction = 0.06640625 * 1280; time = 0.0607s; samplesPerSecond = 21100.5
08/18/2016 07:43:59:  Epoch[50 of 50]-Minibatch[  51-  60, 0.00000000000017%]: CrossEntropyWithSoftmax = 0.14466057 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0597s; samplesPerSecond = 21454.9
08/18/2016 07:43:59:  Epoch[50 of 50]-Minibatch[  61-  70, 0.00000000000019%]: CrossEntropyWithSoftmax = 0.14758101 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0612s; samplesPerSecond = 20909.2
08/18/2016 07:43:59: Finished Epoch[50 of 50]: [Training] CrossEntropyWithSoftmax = 0.14189413 * 10000; EvalErrorPrediction = 0.07380000 * 10000; totalSamplesSeen = 500000; learningRatePerSample = 0.1; epochTime=0.500473s
08/18/2016 07:43:59: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/models/simple.dnn'
08/18/2016 07:43:59: CNTKCommandTrainEnd: Simple_Demo

08/18/2016 07:43:59: Action "train" complete.


08/18/2016 07:43:59: ##############################################################################
08/18/2016 07:43:59: #                                                                            #
08/18/2016 07:43:59: # Action "write"                                                             #
08/18/2016 07:43:59: #                                                                            #
08/18/2016 07:43:59: ##############################################################################


Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalErrorPrediction = ErrorPrediction()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *2]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *2]
Validating --> MeanOfFeatures = Mean (features) : [2 x *2] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *2] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *2], [2], [2] -> [2 x *2]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *2] -> [50 x *2]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *2], [50 x 1] -> [50 x 1 x *2]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *2], [50 x 1] -> [50 x 1 x *2]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *2] -> [2 x 1 x *2]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *2], [2 x 1] -> [2 x 1 x *2]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *2], [2 x 1 x *2] -> [1]
Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [2 x *2], [2 x 1 x *2] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *2] -> [2 x 1 x *2]
Validating --> Prior = Mean (labels) : [2 x *2] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *2], [2] -> [2 x 1 x *2]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.



Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 25 matrices, 3 are shared as 1, and 22 are not shared.

	{ CrossEntropyWithSoftmax : [1]
	  EvalErrorPrediction : [1]
	  PosteriorProb : [2 x 1 x *2] }

Minibatch[0]: ActualMBSize = 603
Written to C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818073609.312415\Speech_Simple@release_cpu/SimpleOutput*
Total Samples Evaluated = 603

08/18/2016 07:43:59: Action "write" complete.

08/18/2016 07:43:59: __COMPLETED__
