CPU info:
    CPU Model Name: Intel(R) Xeon(R) CPU W3530 @ 2.80GHz
    Hardware threads: 4
    Total Memory: 12580404 kB
-------------------------------------------------------------------
=== Running /cygdrive/c/jenkins/workspace/CNTK-Test-Windows-W1/x64/release/cntk.exe configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple/cntk.cntk currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu DeviceId=-1 timestamping=true
-------------------------------------------------------------------
Build info: 

		Built time: Aug 18 2016 08:32:42
		Last modified date: Thu Aug 18 07:29:22 2016
		Build type: Release
		Build target: GPU
		With 1bit-SGD: no
		Math lib: mkl
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
		CUB_PATH: C:\src\cub-1.4.1
		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
		Build Branch: HEAD
		Build SHA1: 1812482490dc842c0d654b96bb2ccd41afb62959
		Built by svcphil on LIANA-09-w
		Build Path: c:\jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
-------------------------------------------------------------------
Changed current directory to C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
08/18/2016 09:23:07: -------------------------------------------------------------------
08/18/2016 09:23:07: Build info: 

08/18/2016 09:23:07: 		Built time: Aug 18 2016 08:32:42
08/18/2016 09:23:07: 		Last modified date: Thu Aug 18 07:29:22 2016
08/18/2016 09:23:07: 		Build type: Release
08/18/2016 09:23:07: 		Build target: GPU
08/18/2016 09:23:07: 		With 1bit-SGD: no
08/18/2016 09:23:07: 		Math lib: mkl
08/18/2016 09:23:07: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
08/18/2016 09:23:07: 		CUB_PATH: C:\src\cub-1.4.1
08/18/2016 09:23:07: 		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
08/18/2016 09:23:07: 		Build Branch: HEAD
08/18/2016 09:23:07: 		Build SHA1: 1812482490dc842c0d654b96bb2ccd41afb62959
08/18/2016 09:23:07: 		Built by svcphil on LIANA-09-w
08/18/2016 09:23:07: 		Build Path: c:\jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
08/18/2016 09:23:07: -------------------------------------------------------------------
08/18/2016 09:23:08: -------------------------------------------------------------------
08/18/2016 09:23:08: GPU info:

08/18/2016 09:23:08: 		Device[0]: cores = 2496; computeCapability = 5.2; type = "Quadro M4000"; memory = 8090 MB
08/18/2016 09:23:08: -------------------------------------------------------------------

08/18/2016 09:23:08: Running on cntk-muc00 at 2016/08/18 09:23:08
08/18/2016 09:23:08: Command line: 
C:\jenkins\workspace\CNTK-Test-Windows-W1\x64\release\cntk.exe  configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple/cntk.cntk  currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data  RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu  DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data  ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple  OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu  DeviceId=-1  timestamping=true



08/18/2016 09:23:08: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
08/18/2016 09:23:08: command=Simple_Demo:Simple_Demo_Output
DeviceNumber=-1
precision=float
modelPath=$RunDir$/models/simple.dnn
deviceId=$DeviceNumber$
outputNodeNames=ScaledLogLikelihood
traceLevel=1
Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=$DataDir$/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]
Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=$DataDir$/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=$RunDir$/SimpleOutput    
]
currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu
DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple
OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu
DeviceId=-1
timestamping=true

08/18/2016 09:23:08: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<

08/18/2016 09:23:08: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
08/18/2016 09:23:08: command=Simple_Demo:Simple_Demo_Output
DeviceNumber=-1
precision=float
modelPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/models/simple.dnn
deviceId=-1
outputNodeNames=ScaledLogLikelihood
traceLevel=1
Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]
Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/SimpleOutput    
]
currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu
DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple
OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu
DeviceId=-1
timestamping=true

08/18/2016 09:23:08: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<

08/18/2016 09:23:08: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
configparameters: cntk.cntk:command=Simple_Demo:Simple_Demo_Output
configparameters: cntk.cntk:ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple
configparameters: cntk.cntk:currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
configparameters: cntk.cntk:DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
configparameters: cntk.cntk:deviceId=-1
configparameters: cntk.cntk:DeviceNumber=-1
configparameters: cntk.cntk:modelPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/models/simple.dnn
configparameters: cntk.cntk:OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu
configparameters: cntk.cntk:outputNodeNames=ScaledLogLikelihood
configparameters: cntk.cntk:precision=float
configparameters: cntk.cntk:RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu
configparameters: cntk.cntk:Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]

configparameters: cntk.cntk:Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/SimpleOutput    
]

configparameters: cntk.cntk:timestamping=true
configparameters: cntk.cntk:traceLevel=1
08/18/2016 09:23:08: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
08/18/2016 09:23:08: Commands: Simple_Demo Simple_Demo_Output
08/18/2016 09:23:08: Precision = "float"
08/18/2016 09:23:08: CNTKModelPath: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/models/simple.dnn
08/18/2016 09:23:08: CNTKCommandTrainInfo: Simple_Demo : 50
08/18/2016 09:23:08: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 50

08/18/2016 09:23:08: ##############################################################################
08/18/2016 09:23:08: #                                                                            #
08/18/2016 09:23:08: # Action "train"                                                             #
08/18/2016 09:23:08: #                                                                            #
08/18/2016 09:23:08: ##############################################################################

08/18/2016 09:23:08: CNTKCommandTrainBegin: Simple_Demo
SimpleNetworkBuilder Using CPU

08/18/2016 09:23:08: Creating virgin network.
Node 'W0' (LearnableParameter operation): Initializing Parameter[50 x 2] <- 0.000000.
Node 'W0' (LearnableParameter operation): Initializing Parameter[50 x 2] <- uniform(seed=1, range=0.050000*1.000000, onCPU=false).
Node 'B0' (LearnableParameter operation): Initializing Parameter[50 x 1] <- 0.000000.
Node 'B0' (LearnableParameter operation): Initializing Parameter[50 x 1] <- 0.000000.
Node 'W1' (LearnableParameter operation): Initializing Parameter[50 x 50] <- 0.000000.
Node 'W1' (LearnableParameter operation): Initializing Parameter[50 x 50] <- uniform(seed=2, range=0.050000*1.000000, onCPU=false).
Node 'B1' (LearnableParameter operation): Initializing Parameter[50 x 1] <- 0.000000.
Node 'B1' (LearnableParameter operation): Initializing Parameter[50 x 1] <- 0.000000.
Node 'W2' (LearnableParameter operation): Initializing Parameter[2 x 50] <- 0.000000.
Node 'W2' (LearnableParameter operation): Initializing Parameter[2 x 50] <- uniform(seed=3, range=0.050000*1.000000, onCPU=false).
Node 'B2' (LearnableParameter operation): Initializing Parameter[2 x 1] <- 0.000000.
Node 'B2' (LearnableParameter operation): Initializing Parameter[2 x 1] <- 0.000000.

Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalErrorPrediction = ErrorPrediction()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *]
Validating --> MeanOfFeatures = Mean (features) : [2 x *] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *], [2], [2] -> [2 x *]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *] -> [50 x *]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *], [50 x 1] -> [50 x 1 x *]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *] -> [50 x 1 x *]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *] -> [50 x 1 x *]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *], [50 x 1] -> [50 x 1 x *]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *] -> [50 x 1 x *]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *] -> [2 x 1 x *]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *], [2 x 1] -> [2 x 1 x *]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *], [2 x 1 x *] -> [1]
Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [2 x *], [2 x 1 x *] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *] -> [2 x 1 x *]
Validating --> Prior = Mean (labels) : [2 x *] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *], [2] -> [2 x 1 x *]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

08/18/2016 09:23:08: Created model with 25 nodes on CPU.

08/18/2016 09:23:08: Training criterion node(s):
08/18/2016 09:23:08: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax

08/18/2016 09:23:08: Evaluation criterion node(s):
08/18/2016 09:23:08: 	EvalErrorPrediction = ErrorPrediction


Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 40 matrices, 19 are shared as 8, and 21 are not shared.

	{ W0 : [50 x 2] (gradient)
	  W0*features+B0 : [50 x 1 x *] }
	{ H1 : [50 x 1 x *]
	  W0*features : [50 x *] (gradient) }
	{ W1 : [50 x 50] (gradient)
	  W1*H1+B1 : [50 x 1 x *] }
	{ H2 : [50 x 1 x *]
	  W1*H1 : [50 x 1 x *] (gradient) }
	{ B1 : [50 x 1] (gradient)
	  H2 : [50 x 1 x *] (gradient)
	  HLast : [2 x 1 x *] (gradient) }
	{ W0*features+B0 : [50 x 1 x *] (gradient)
	  W1*H1 : [50 x 1 x *] }
	{ HLast : [2 x 1 x *]
	  W2 : [2 x 50] (gradient) }
	{ B0 : [50 x 1] (gradient)
	  H1 : [50 x 1 x *] (gradient)
	  W1*H1+B1 : [50 x 1 x *] (gradient)
	  W2*H1 : [2 x 1 x *] }


08/18/2016 09:23:08: Training 2802 parameters in 6 out of 6 parameter tensors and 15 nodes with gradient:

08/18/2016 09:23:08: 	Node 'B0' (LearnableParameter operation) : [50 x 1]
08/18/2016 09:23:08: 	Node 'B1' (LearnableParameter operation) : [50 x 1]
08/18/2016 09:23:08: 	Node 'B2' (LearnableParameter operation) : [2 x 1]
08/18/2016 09:23:08: 	Node 'W0' (LearnableParameter operation) : [50 x 2]
08/18/2016 09:23:08: 	Node 'W1' (LearnableParameter operation) : [50 x 50]
08/18/2016 09:23:08: 	Node 'W2' (LearnableParameter operation) : [2 x 50]


08/18/2016 09:23:08: Precomputing --> 3 PreCompute nodes found.

08/18/2016 09:23:08: 	MeanOfFeatures = Mean()
08/18/2016 09:23:08: 	InvStdOfFeatures = InvStdDev()
08/18/2016 09:23:08: 	Prior = Mean()
BlockRandomizer::StartEpoch: epoch 1: samples [0..10000] (first sequence at sample 0), worker rank 0, total workers 1

08/18/2016 09:23:08: Precomputing --> Completed.


08/18/2016 09:23:08: Starting Epoch 1: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 1: samples [0..10000] (first sequence at sample 0), worker rank 0, total workers 1

08/18/2016 09:23:08: Starting minibatch loop.
08/18/2016 09:23:08:  Epoch[ 1 of 50]-Minibatch[   1-  10]: CrossEntropyWithSoftmax = 0.84135866 * 1280; EvalErrorPrediction = 0.49375000 * 1280; time = 0.0172s; samplesPerSecond = 74453.2
08/18/2016 09:23:08:  Epoch[ 1 of 50]-Minibatch[  11-  20]: CrossEntropyWithSoftmax = 0.80750933 * 1280; EvalErrorPrediction = 0.50937500 * 1280; time = 0.0163s; samplesPerSecond = 78316.2
08/18/2016 09:23:08:  Epoch[ 1 of 50]-Minibatch[  21-  30]: CrossEntropyWithSoftmax = 0.73671169 * 1280; EvalErrorPrediction = 0.48828125 * 1280; time = 0.0149s; samplesPerSecond = 85831.2
08/18/2016 09:23:08:  Epoch[ 1 of 50]-Minibatch[  31-  40]: CrossEntropyWithSoftmax = 0.71652222 * 1280; EvalErrorPrediction = 0.51484375 * 1280; time = 0.0149s; samplesPerSecond = 86004.2
08/18/2016 09:23:08:  Epoch[ 1 of 50]-Minibatch[  41-  50]: CrossEntropyWithSoftmax = 0.70134087 * 1280; EvalErrorPrediction = 0.50078125 * 1280; time = 0.0150s; samplesPerSecond = 85618.7
08/18/2016 09:23:08:  Epoch[ 1 of 50]-Minibatch[  51-  60]: CrossEntropyWithSoftmax = 0.71664810 * 1280; EvalErrorPrediction = 0.50781250 * 1280; time = 0.0159s; samplesPerSecond = 80447.5
08/18/2016 09:23:08:  Epoch[ 1 of 50]-Minibatch[  61-  70]: CrossEntropyWithSoftmax = 0.71382103 * 1280; EvalErrorPrediction = 0.50156250 * 1280; time = 0.0149s; samplesPerSecond = 85630.2
08/18/2016 09:23:08: Finished Epoch[ 1 of 50]: [Training] CrossEntropyWithSoftmax = 0.74341196 * 10000; EvalErrorPrediction = 0.50260000 * 10000; totalSamplesSeen = 10000; learningRatePerSample = 0.1; epochTime=0.124494s
08/18/2016 09:23:08: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/models/simple.dnn.1'

08/18/2016 09:23:08: Starting Epoch 2: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 2: samples [10000..20000] (first sequence at sample 10000), worker rank 0, total workers 1

08/18/2016 09:23:08: Starting minibatch loop.
08/18/2016 09:23:08:  Epoch[ 2 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.71325474 * 1280; EvalErrorPrediction = 0.49296875 * 1280; time = 0.0149s; samplesPerSecond = 85802.4
08/18/2016 09:23:08:  Epoch[ 2 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.75389853 * 1280; EvalErrorPrediction = 0.46406250 * 1280; time = 0.0166s; samplesPerSecond = 77154.9
08/18/2016 09:23:08:  Epoch[ 2 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.75757513 * 1280; EvalErrorPrediction = 0.51171875 * 1280; time = 0.0150s; samplesPerSecond = 85607.3
08/18/2016 09:23:08:  Epoch[ 2 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.75674992 * 1280; EvalErrorPrediction = 0.51171875 * 1280; time = 0.0149s; samplesPerSecond = 85981.1
08/18/2016 09:23:08:  Epoch[ 2 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.74725094 * 1280; EvalErrorPrediction = 0.50390625 * 1280; time = 0.0149s; samplesPerSecond = 85756.4
08/18/2016 09:23:08:  Epoch[ 2 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.73079414 * 1280; EvalErrorPrediction = 0.50546875 * 1280; time = 0.0150s; samplesPerSecond = 85590.1
08/18/2016 09:23:08:  Epoch[ 2 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.73625755 * 1280; EvalErrorPrediction = 0.50078125 * 1280; time = 0.0170s; samplesPerSecond = 75338.4
08/18/2016 09:23:08: Finished Epoch[ 2 of 50]: [Training] CrossEntropyWithSoftmax = 0.73900103 * 10000; EvalErrorPrediction = 0.49680000 * 10000; totalSamplesSeen = 20000; learningRatePerSample = 0.1; epochTime=0.122345s
08/18/2016 09:23:08: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/models/simple.dnn.2'

08/18/2016 09:23:08: Starting Epoch 3: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 3: samples [20000..30000] (first sequence at sample 20000), worker rank 0, total workers 1

08/18/2016 09:23:08: Starting minibatch loop.
08/18/2016 09:23:08:  Epoch[ 3 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.74044714 * 1280; EvalErrorPrediction = 0.50000000 * 1280; time = 0.0150s; samplesPerSecond = 85333.3
08/18/2016 09:23:08:  Epoch[ 3 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.73792162 * 1280; EvalErrorPrediction = 0.50625000 * 1280; time = 0.0167s; samplesPerSecond = 76619.2
08/18/2016 09:23:08:  Epoch[ 3 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.77087250 * 1280; EvalErrorPrediction = 0.52187500 * 1280; time = 0.0149s; samplesPerSecond = 85785.1
08/18/2016 09:23:08:  Epoch[ 3 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.75999603 * 1280; EvalErrorPrediction = 0.50234375 * 1280; time = 0.0150s; samplesPerSecond = 85078.1
08/18/2016 09:23:08:  Epoch[ 3 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.73512688 * 1280; EvalErrorPrediction = 0.50937500 * 1280; time = 0.0150s; samplesPerSecond = 85550.1
08/18/2016 09:23:08:  Epoch[ 3 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.71369209 * 1280; EvalErrorPrediction = 0.48984375 * 1280; time = 0.0149s; samplesPerSecond = 85929.1
08/18/2016 09:23:08:  Epoch[ 3 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.69696960 * 1280; EvalErrorPrediction = 0.50703125 * 1280; time = 0.0149s; samplesPerSecond = 85756.4
08/18/2016 09:23:08: Finished Epoch[ 3 of 50]: [Training] CrossEntropyWithSoftmax = 0.73257485 * 10000; EvalErrorPrediction = 0.50380000 * 10000; totalSamplesSeen = 30000; learningRatePerSample = 0.1; epochTime=0.120561s
08/18/2016 09:23:08: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/models/simple.dnn.3'

08/18/2016 09:23:08: Starting Epoch 4: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 4: samples [30000..40000] (first sequence at sample 30000), worker rank 0, total workers 1

08/18/2016 09:23:08: Starting minibatch loop.
08/18/2016 09:23:08:  Epoch[ 4 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.71515269 * 1280; EvalErrorPrediction = 0.49296875 * 1280; time = 0.0148s; samplesPerSecond = 86253.4
08/18/2016 09:23:09:  Epoch[ 4 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.74560342 * 1280; EvalErrorPrediction = 0.50234375 * 1280; time = 0.0166s; samplesPerSecond = 77029.5
08/18/2016 09:23:09:  Epoch[ 4 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.73897266 * 1280; EvalErrorPrediction = 0.47812500 * 1280; time = 0.0149s; samplesPerSecond = 85744.9
08/18/2016 09:23:09:  Epoch[ 4 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.71412621 * 1280; EvalErrorPrediction = 0.48671875 * 1280; time = 0.0149s; samplesPerSecond = 85687.5
08/18/2016 09:23:09:  Epoch[ 4 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.71213531 * 1280; EvalErrorPrediction = 0.50000000 * 1280; time = 0.0150s; samplesPerSecond = 85561.5
08/18/2016 09:23:09:  Epoch[ 4 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.70156898 * 1280; EvalErrorPrediction = 0.50390625 * 1280; time = 0.0149s; samplesPerSecond = 85767.9
08/18/2016 09:23:09:  Epoch[ 4 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.70737991 * 1280; EvalErrorPrediction = 0.49687500 * 1280; time = 0.0149s; samplesPerSecond = 86062.0
08/18/2016 09:23:09: Finished Epoch[ 4 of 50]: [Training] CrossEntropyWithSoftmax = 0.71707466 * 10000; EvalErrorPrediction = 0.49440000 * 10000; totalSamplesSeen = 40000; learningRatePerSample = 0.1; epochTime=0.120228s
08/18/2016 09:23:09: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/models/simple.dnn.4'

08/18/2016 09:23:09: Starting Epoch 5: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 5: samples [40000..50000] (first sequence at sample 40000), worker rank 0, total workers 1

08/18/2016 09:23:09: Starting minibatch loop.
08/18/2016 09:23:09:  Epoch[ 5 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.69854627 * 1280; EvalErrorPrediction = 0.50234375 * 1280; time = 0.0148s; samplesPerSecond = 86253.4
08/18/2016 09:23:09:  Epoch[ 5 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.70018868 * 1280; EvalErrorPrediction = 0.49140625 * 1280; time = 0.0166s; samplesPerSecond = 77215.4
08/18/2016 09:23:09:  Epoch[ 5 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.69679499 * 1280; EvalErrorPrediction = 0.51796875 * 1280; time = 0.0149s; samplesPerSecond = 85819.6
08/18/2016 09:23:09:  Epoch[ 5 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.69342022 * 1280; EvalErrorPrediction = 0.49531250 * 1280; time = 0.0150s; samplesPerSecond = 85293.5
08/18/2016 09:23:09:  Epoch[ 5 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.69504795 * 1280; EvalErrorPrediction = 0.48906250 * 1280; time = 0.0149s; samplesPerSecond = 85888.7
08/18/2016 09:23:09:  Epoch[ 5 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.70215073 * 1280; EvalErrorPrediction = 0.48593750 * 1280; time = 0.0149s; samplesPerSecond = 85958.0
08/18/2016 09:23:09:  Epoch[ 5 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.69844475 * 1280; EvalErrorPrediction = 0.47734375 * 1280; time = 0.0149s; samplesPerSecond = 85802.4
08/18/2016 09:23:09: Finished Epoch[ 5 of 50]: [Training] CrossEntropyWithSoftmax = 0.69761069 * 10000; EvalErrorPrediction = 0.49640000 * 10000; totalSamplesSeen = 50000; learningRatePerSample = 0.1; epochTime=0.120129s
08/18/2016 09:23:09: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/models/simple.dnn.5'

08/18/2016 09:23:09: Starting Epoch 6: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 6: samples [50000..60000] (first sequence at sample 50000), worker rank 0, total workers 1

08/18/2016 09:23:09: Starting minibatch loop.
08/18/2016 09:23:09:  Epoch[ 6 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.70235553 * 1280; EvalErrorPrediction = 0.49843750 * 1280; time = 0.0148s; samplesPerSecond = 86329.0
08/18/2016 09:23:09:  Epoch[ 6 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.69492078 * 1280; EvalErrorPrediction = 0.46875000 * 1280; time = 0.0167s; samplesPerSecond = 76564.2
08/18/2016 09:23:09:  Epoch[ 6 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.68310280 * 1280; EvalErrorPrediction = 0.49062500 * 1280; time = 0.0150s; samplesPerSecond = 85572.9
08/18/2016 09:23:09:  Epoch[ 6 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.68259964 * 1280; EvalErrorPrediction = 0.50625000 * 1280; time = 0.0154s; samplesPerSecond = 82885.4
08/18/2016 09:23:09:  Epoch[ 6 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.55136337 * 1280; EvalErrorPrediction = 0.29218750 * 1280; time = 0.0150s; samplesPerSecond = 85481.5
08/18/2016 09:23:09:  Epoch[ 6 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.26582794 * 1280; EvalErrorPrediction = 0.10390625 * 1280; time = 0.0148s; samplesPerSecond = 86556.7
08/18/2016 09:23:09:  Epoch[ 6 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17693977 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0149s; samplesPerSecond = 85762.1
08/18/2016 09:23:09: Finished Epoch[ 6 of 50]: [Training] CrossEntropyWithSoftmax = 0.49747188 * 10000; EvalErrorPrediction = 0.31920000 * 10000; totalSamplesSeen = 60000; learningRatePerSample = 0.1; epochTime=0.120718s
08/18/2016 09:23:09: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/models/simple.dnn.6'

08/18/2016 09:23:09: Starting Epoch 7: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 7: samples [60000..70000] (first sequence at sample 60000), worker rank 0, total workers 1

08/18/2016 09:23:09: Starting minibatch loop.
08/18/2016 09:23:09:  Epoch[ 7 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17653030 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0159s; samplesPerSecond = 80493.0
08/18/2016 09:23:09:  Epoch[ 7 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17294422 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0177s; samplesPerSecond = 72283.7
08/18/2016 09:23:09:  Epoch[ 7 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17368841 * 1280; EvalErrorPrediction = 0.07920625 * 1280; time = 0.0160s; samplesPerSecond = 79815.4
08/18/2016 09:23:09:  Epoch[ 7 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16366272 * 1280; EvalErrorPrediction = 0.06718750 * 1280; time = 0.0165s; samplesPerSecond = 77665.2
08/18/2016 09:23:09:  Epoch[ 7 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16037722 * 1280; EvalErrorPrediction = 0.06484375 * 1280; time = 0.0159s; samplesPerSecond = 80488.0
08/18/2016 09:23:09:  Epoch[ 7 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.19018154 * 1280; EvalErrorPrediction = 0.08477500 * 1280; time = 0.0159s; samplesPerSecond = 80422.2
08/18/2016 09:23:09:  Epoch[ 7 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17999439 * 1280; EvalErrorPrediction = 0.08906250 * 1280; time = 0.0159s; samplesPerSecond = 80361.6
08/18/2016 09:23:09: Finished Epoch[ 7 of 50]: [Training] CrossEntropyWithSoftmax = 0.17464830 * 10000; EvalErrorPrediction = 0.07680000 * 10000; totalSamplesSeen = 70000; learningRatePerSample = 0.1; epochTime=0.128699s
08/18/2016 09:23:09: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/models/simple.dnn.7'

08/18/2016 09:23:09: Starting Epoch 8: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 8: samples [70000..80000] (first sequence at sample 70000), worker rank 0, total workers 1

08/18/2016 09:23:09: Starting minibatch loop.
08/18/2016 09:23:09:  Epoch[ 8 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17757022 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0158s; samplesPerSecond = 80797.9
08/18/2016 09:23:09:  Epoch[ 8 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16836350 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0179s; samplesPerSecond = 71520.4
08/18/2016 09:23:09:  Epoch[ 8 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17159715 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0160s; samplesPerSecond = 80185.4
08/18/2016 09:23:09:  Epoch[ 8 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16443744 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0159s; samplesPerSecond = 80316.2
08/18/2016 09:23:09:  Epoch[ 8 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17230330 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0159s; samplesPerSecond = 80432.3
08/18/2016 09:23:10:  Epoch[ 8 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.19415026 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0159s; samplesPerSecond = 80518.3
08/18/2016 09:23:10:  Epoch[ 8 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15373411 * 1280; EvalErrorPrediction = 0.06875000 * 1280; time = 0.0159s; samplesPerSecond = 80386.9
08/18/2016 09:23:10: Finished Epoch[ 8 of 50]: [Training] CrossEntropyWithSoftmax = 0.17304440 * 10000; EvalErrorPrediction = 0.07940000 * 10000; totalSamplesSeen = 80000; learningRatePerSample = 0.1; epochTime=0.128191s
08/18/2016 09:23:10: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/models/simple.dnn.8'

08/18/2016 09:23:10: Starting Epoch 9: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 9: samples [80000..90000] (first sequence at sample 80000), worker rank 0, total workers 1

08/18/2016 09:23:10: Starting minibatch loop.
08/18/2016 09:23:10:  Epoch[ 9 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.21020851 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0159s; samplesPerSecond = 80508.2
08/18/2016 09:23:10:  Epoch[ 9 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.20796409 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0179s; samplesPerSecond = 71596.4
08/18/2016 09:23:10:  Epoch[ 9 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.19792776 * 1280; EvalErrorPrediction = 0.09609375 * 1280; time = 0.0159s; samplesPerSecond = 80296.1
08/18/2016 09:23:10:  Epoch[ 9 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.19371848 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0164s; samplesPerSecond = 77882.6
08/18/2016 09:23:10:  Epoch[ 9 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18505373 * 1280; EvalErrorPrediction = 0.08852500 * 1280; time = 0.0159s; samplesPerSecond = 80417.2
08/18/2016 09:23:10:  Epoch[ 9 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17269211 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0158s; samplesPerSecond = 80915.4
08/18/2016 09:23:10:  Epoch[ 9 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17060089 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0158s; samplesPerSecond = 80976.8
08/18/2016 09:23:10: Finished Epoch[ 9 of 50]: [Training] CrossEntropyWithSoftmax = 0.19135530 * 10000; EvalErrorPrediction = 0.08190000 * 10000; totalSamplesSeen = 90000; learningRatePerSample = 0.1; epochTime=0.128878s
08/18/2016 09:23:10: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/models/simple.dnn.9'

08/18/2016 09:23:10: Starting Epoch 10: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 10: samples [90000..100000] (first sequence at sample 90000), worker rank 0, total workers 1

08/18/2016 09:23:10: Starting minibatch loop.
08/18/2016 09:23:10:  Epoch[10 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.19234393 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0157s; samplesPerSecond = 81393.9
08/18/2016 09:23:10:  Epoch[10 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15464509 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0175s; samplesPerSecond = 73096.9
08/18/2016 09:23:10:  Epoch[10 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17311335 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0158s; samplesPerSecond = 81135.9
08/18/2016 09:23:10:  Epoch[10 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15399089 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0158s; samplesPerSecond = 81208.0
08/18/2016 09:23:10:  Epoch[10 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.22227230 * 1280; EvalErrorPrediction = 0.09687500 * 1280; time = 0.0157s; samplesPerSecond = 81585.8
08/18/2016 09:23:10:  Epoch[10 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17284317 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0157s; samplesPerSecond = 81476.8
08/18/2016 09:23:10:  Epoch[10 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18740721 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0162s; samplesPerSecond = 79110.0
08/18/2016 09:23:10: Finished Epoch[10 of 50]: [Training] CrossEntropyWithSoftmax = 0.17765001 * 10000; EvalErrorPrediction = 0.07910000 * 10000; totalSamplesSeen = 100000; learningRatePerSample = 0.1; epochTime=0.127042s
08/18/2016 09:23:10: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/models/simple.dnn.10'

08/18/2016 09:23:10: Starting Epoch 11: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 11: samples [100000..110000] (first sequence at sample 100000), worker rank 0, total workers 1

08/18/2016 09:23:10: Starting minibatch loop.
08/18/2016 09:23:10:  Epoch[11 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.18572437 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0148s; samplesPerSecond = 86439.8
08/18/2016 09:23:10:  Epoch[11 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16318010 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0164s; samplesPerSecond = 77934.7
08/18/2016 09:23:10:  Epoch[11 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16652555 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0148s; samplesPerSecond = 86767.9
08/18/2016 09:23:10:  Epoch[11 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16166201 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0148s; samplesPerSecond = 86474.8
08/18/2016 09:23:10:  Epoch[11 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15495000 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0171s; samplesPerSecond = 75024.9
08/18/2016 09:23:10:  Epoch[11 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14945574 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0148s; samplesPerSecond = 86562.5
08/18/2016 09:23:10:  Epoch[11 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14350967 * 1280; EvalErrorPrediction = 0.06250000 * 1280; time = 0.0149s; samplesPerSecond = 86119.9
08/18/2016 09:23:10: Finished Epoch[11 of 50]: [Training] CrossEntropyWithSoftmax = 0.16355641 * 10000; EvalErrorPrediction = 0.07530000 * 10000; totalSamplesSeen = 110000; learningRatePerSample = 0.1; epochTime=0.121905s
08/18/2016 09:23:10: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/models/simple.dnn.11'

08/18/2016 09:23:10: Starting Epoch 12: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 12: samples [110000..120000] (first sequence at sample 110000), worker rank 0, total workers 1

08/18/2016 09:23:10: Starting minibatch loop.
08/18/2016 09:23:10:  Epoch[12 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.19255348 * 1280; EvalErrorPrediction = 0.08555625 * 1280; time = 0.0158s; samplesPerSecond = 81259.5
08/18/2016 09:23:10:  Epoch[12 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16854106 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0176s; samplesPerSecond = 72822.4
08/18/2016 09:23:10:  Epoch[12 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17581871 * 1280; EvalErrorPrediction = 0.08906250 * 1280; time = 0.0159s; samplesPerSecond = 80752.0
08/18/2016 09:23:10:  Epoch[12 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17771955 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0158s; samplesPerSecond = 80843.8
08/18/2016 09:23:10:  Epoch[12 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15838194 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0158s; samplesPerSecond = 81197.7
08/18/2016 09:23:10:  Epoch[12 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16588488 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0157s; samplesPerSecond = 81528.7
08/18/2016 09:23:10:  Epoch[12 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14363699 * 1280; EvalErrorPrediction = 0.06406250 * 1280; time = 0.0157s; samplesPerSecond = 81280.2
08/18/2016 09:23:10: Finished Epoch[12 of 50]: [Training] CrossEntropyWithSoftmax = 0.16866189 * 10000; EvalErrorPrediction = 0.08020000 * 10000; totalSamplesSeen = 120000; learningRatePerSample = 0.1; epochTime=0.12696s
08/18/2016 09:23:11: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/models/simple.dnn.12'

08/18/2016 09:23:11: Starting Epoch 13: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 13: samples [120000..130000] (first sequence at sample 120000), worker rank 0, total workers 1

08/18/2016 09:23:11: Starting minibatch loop.
08/18/2016 09:23:11:  Epoch[13 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15133330 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0146s; samplesPerSecond = 87389.9
08/18/2016 09:23:11:  Epoch[13 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.18005999 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0166s; samplesPerSecond = 77048.1
08/18/2016 09:23:11:  Epoch[13 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.18221855 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0148s; samplesPerSecond = 86691.5
08/18/2016 09:23:11:  Epoch[13 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14709105 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0147s; samplesPerSecond = 86797.3
08/18/2016 09:23:11:  Epoch[13 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16784267 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0147s; samplesPerSecond = 86992.0
08/18/2016 09:23:11:  Epoch[13 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17118683 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0147s; samplesPerSecond = 86850.3
08/18/2016 09:23:11:  Epoch[13 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15527744 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0148s; samplesPerSecond = 86253.4
08/18/2016 09:23:11: Finished Epoch[13 of 50]: [Training] CrossEntropyWithSoftmax = 0.16551395 * 10000; EvalErrorPrediction = 0.07730000 * 10000; totalSamplesSeen = 130000; learningRatePerSample = 0.1; epochTime=0.119055s
08/18/2016 09:23:11: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/models/simple.dnn.13'

08/18/2016 09:23:11: Starting Epoch 14: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 14: samples [130000..140000] (first sequence at sample 130000), worker rank 0, total workers 1

08/18/2016 09:23:11: Starting minibatch loop.
08/18/2016 09:23:11:  Epoch[14 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.21903448 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0148s; samplesPerSecond = 86533.3
08/18/2016 09:23:11:  Epoch[14 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.21171846 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0165s; samplesPerSecond = 77773.7
08/18/2016 09:23:11:  Epoch[14 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.22919979 * 1280; EvalErrorPrediction = 0.08906250 * 1280; time = 0.0149s; samplesPerSecond = 85854.2
08/18/2016 09:23:11:  Epoch[14 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.24511843 * 1280; EvalErrorPrediction = 0.09687500 * 1280; time = 0.0148s; samplesPerSecond = 86779.7
08/18/2016 09:23:11:  Epoch[14 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.20996313 * 1280; EvalErrorPrediction = 0.07774375 * 1280; time = 0.0147s; samplesPerSecond = 86974.2
08/18/2016 09:23:11:  Epoch[14 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15947819 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0148s; samplesPerSecond = 86433.9
08/18/2016 09:23:11:  Epoch[14 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16172314 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0147s; samplesPerSecond = 86820.9
08/18/2016 09:23:11: Finished Epoch[14 of 50]: [Training] CrossEntropyWithSoftmax = 0.20098990 * 10000; EvalErrorPrediction = 0.08090000 * 10000; totalSamplesSeen = 140000; learningRatePerSample = 0.1; epochTime=0.119159s
08/18/2016 09:23:11: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/models/simple.dnn.14'

08/18/2016 09:23:11: Starting Epoch 15: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 15: samples [140000..150000] (first sequence at sample 140000), worker rank 0, total workers 1

08/18/2016 09:23:11: Starting minibatch loop.
08/18/2016 09:23:11:  Epoch[15 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16884749 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0158s; samplesPerSecond = 80920.5
08/18/2016 09:23:11:  Epoch[15 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14229040 * 1280; EvalErrorPrediction = 0.06562500 * 1280; time = 0.0175s; samplesPerSecond = 73188.9
08/18/2016 09:23:11:  Epoch[15 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17882740 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0179s; samplesPerSecond = 71440.5
08/18/2016 09:23:11:  Epoch[15 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16688123 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0162s; samplesPerSecond = 79139.4
08/18/2016 09:23:11:  Epoch[15 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18277683 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0158s; samplesPerSecond = 81099.9
08/18/2016 09:23:11:  Epoch[15 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16112986 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0158s; samplesPerSecond = 81171.9
08/18/2016 09:23:11:  Epoch[15 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15518370 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0157s; samplesPerSecond = 81290.5
08/18/2016 09:23:11: Finished Epoch[15 of 50]: [Training] CrossEntropyWithSoftmax = 0.16386208 * 10000; EvalErrorPrediction = 0.07500000 * 10000; totalSamplesSeen = 150000; learningRatePerSample = 0.1; epochTime=0.129401s
08/18/2016 09:23:11: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/models/simple.dnn.15'

08/18/2016 09:23:11: Starting Epoch 16: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 16: samples [150000..160000] (first sequence at sample 150000), worker rank 0, total workers 1

08/18/2016 09:23:11: Starting minibatch loop.
08/18/2016 09:23:11:  Epoch[16 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16816715 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0158s; samplesPerSecond = 81141.0
08/18/2016 09:23:11:  Epoch[16 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15312701 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0175s; samplesPerSecond = 73176.3
08/18/2016 09:23:11:  Epoch[16 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.18211365 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0158s; samplesPerSecond = 81182.2
08/18/2016 09:23:11:  Epoch[16 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.19771109 * 1280; EvalErrorPrediction = 0.08828125 * 1280; time = 0.0157s; samplesPerSecond = 81321.5
08/18/2016 09:23:11:  Epoch[16 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.19899631 * 1280; EvalErrorPrediction = 0.09140625 * 1280; time = 0.0157s; samplesPerSecond = 81554.6
08/18/2016 09:23:11:  Epoch[16 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.19653139 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0157s; samplesPerSecond = 81544.2
08/18/2016 09:23:11:  Epoch[16 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.21216993 * 1280; EvalErrorPrediction = 0.09843750 * 1280; time = 0.0157s; samplesPerSecond = 81497.5
08/18/2016 09:23:11: Finished Epoch[16 of 50]: [Training] CrossEntropyWithSoftmax = 0.18786394 * 10000; EvalErrorPrediction = 0.08350000 * 10000; totalSamplesSeen = 160000; learningRatePerSample = 0.1; epochTime=0.126514s
08/18/2016 09:23:12: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/models/simple.dnn.16'

08/18/2016 09:23:12: Starting Epoch 17: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 17: samples [160000..170000] (first sequence at sample 160000), worker rank 0, total workers 1

08/18/2016 09:23:12: Starting minibatch loop.
08/18/2016 09:23:12:  Epoch[17 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.18659199 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0147s; samplesPerSecond = 87104.5
08/18/2016 09:23:12:  Epoch[17 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.19368111 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0165s; samplesPerSecond = 77802.1
08/18/2016 09:23:12:  Epoch[17 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.20846658 * 1280; EvalErrorPrediction = 0.09531250 * 1280; time = 0.0148s; samplesPerSecond = 86509.9
08/18/2016 09:23:12:  Epoch[17 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17157269 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0155s; samplesPerSecond = 82735.4
08/18/2016 09:23:12:  Epoch[17 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17115402 * 1280; EvalErrorPrediction = 0.08828125 * 1280; time = 0.0148s; samplesPerSecond = 86750.3
08/18/2016 09:23:12:  Epoch[17 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17137775 * 1280; EvalErrorPrediction = 0.07149375 * 1280; time = 0.0147s; samplesPerSecond = 86897.5
08/18/2016 09:23:12:  Epoch[17 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16963568 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0148s; samplesPerSecond = 86527.4
08/18/2016 09:23:12: Finished Epoch[17 of 50]: [Training] CrossEntropyWithSoftmax = 0.18151743 * 10000; EvalErrorPrediction = 0.08230000 * 10000; totalSamplesSeen = 170000; learningRatePerSample = 0.1; epochTime=0.119618s
08/18/2016 09:23:12: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/models/simple.dnn.17'

08/18/2016 09:23:12: Starting Epoch 18: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 18: samples [170000..180000] (first sequence at sample 170000), worker rank 0, total workers 1

08/18/2016 09:23:12: Starting minibatch loop.
08/18/2016 09:23:12:  Epoch[18 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15840772 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0159s; samplesPerSecond = 80655.3
08/18/2016 09:23:12:  Epoch[18 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16292373 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0176s; samplesPerSecond = 72897.1
08/18/2016 09:23:12:  Epoch[18 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16793671 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0159s; samplesPerSecond = 80609.6
08/18/2016 09:23:12:  Epoch[18 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15812569 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0158s; samplesPerSecond = 80976.8
08/18/2016 09:23:12:  Epoch[18 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15216236 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0158s; samplesPerSecond = 81125.6
08/18/2016 09:23:12:  Epoch[18 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15943112 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0158s; samplesPerSecond = 81208.0
08/18/2016 09:23:12:  Epoch[18 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15781136 * 1280; EvalErrorPrediction = 0.06836875 * 1280; time = 0.0157s; samplesPerSecond = 81482.0
08/18/2016 09:23:12: Finished Epoch[18 of 50]: [Training] CrossEntropyWithSoftmax = 0.15980299 * 10000; EvalErrorPrediction = 0.07440000 * 10000; totalSamplesSeen = 180000; learningRatePerSample = 0.1; epochTime=0.127099s
08/18/2016 09:23:12: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/models/simple.dnn.18'

08/18/2016 09:23:12: Starting Epoch 19: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 19: samples [180000..190000] (first sequence at sample 180000), worker rank 0, total workers 1

08/18/2016 09:23:12: Starting minibatch loop.
08/18/2016 09:23:12:  Epoch[19 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15393217 * 1280; EvalErrorPrediction = 0.07772500 * 1280; time = 0.0147s; samplesPerSecond = 86838.5
08/18/2016 09:23:12:  Epoch[19 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14662540 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0165s; samplesPerSecond = 77754.8
08/18/2016 09:23:12:  Epoch[19 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16555657 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0147s; samplesPerSecond = 87063.0
08/18/2016 09:23:12:  Epoch[19 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15092411 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0148s; samplesPerSecond = 86773.8
08/18/2016 09:23:12:  Epoch[19 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18199005 * 1280; EvalErrorPrediction = 0.08631875 * 1280; time = 0.0148s; samplesPerSecond = 86445.6
08/18/2016 09:23:12:  Epoch[19 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16240711 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0147s; samplesPerSecond = 86815.0
08/18/2016 09:23:12:  Epoch[19 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17171764 * 1280; EvalErrorPrediction = 0.08984375 * 1280; time = 0.0168s; samplesPerSecond = 76077.3
08/18/2016 09:23:12: Finished Epoch[19 of 50]: [Training] CrossEntropyWithSoftmax = 0.16261082 * 10000; EvalErrorPrediction = 0.07790000 * 10000; totalSamplesSeen = 190000; learningRatePerSample = 0.1; epochTime=0.120971s
08/18/2016 09:23:12: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/models/simple.dnn.19'

08/18/2016 09:23:12: Starting Epoch 20: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 20: samples [190000..200000] (first sequence at sample 190000), worker rank 0, total workers 1

08/18/2016 09:23:12: Starting minibatch loop.
08/18/2016 09:23:12:  Epoch[20 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16127666 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0151s; samplesPerSecond = 84656.1
08/18/2016 09:23:12:  Epoch[20 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16555692 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0164s; samplesPerSecond = 77830.5
08/18/2016 09:23:12:  Epoch[20 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16218271 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0149s; samplesPerSecond = 85865.7
08/18/2016 09:23:12:  Epoch[20 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17390676 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0149s; samplesPerSecond = 86160.5
08/18/2016 09:23:12:  Epoch[20 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16834612 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0149s; samplesPerSecond = 85802.4
08/18/2016 09:23:12:  Epoch[20 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15878916 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0147s; samplesPerSecond = 86980.2
08/18/2016 09:23:12:  Epoch[20 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16729927 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0148s; samplesPerSecond = 86504.0
08/18/2016 09:23:12: Finished Epoch[20 of 50]: [Training] CrossEntropyWithSoftmax = 0.16362103 * 10000; EvalErrorPrediction = 0.07690000 * 10000; totalSamplesSeen = 200000; learningRatePerSample = 0.1; epochTime=0.119793s
08/18/2016 09:23:12: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/models/simple.dnn.20'

08/18/2016 09:23:12: Starting Epoch 21: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 21: samples [200000..210000] (first sequence at sample 200000), worker rank 0, total workers 1

08/18/2016 09:23:12: Starting minibatch loop.
08/18/2016 09:23:13:  Epoch[21 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16339048 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0411s; samplesPerSecond = 31131.4
08/18/2016 09:23:13:  Epoch[21 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14520251 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0166s; samplesPerSecond = 77024.9
08/18/2016 09:23:13:  Epoch[21 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15791464 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0149s; samplesPerSecond = 85693.2
08/18/2016 09:23:13:  Epoch[21 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14244738 * 1280; EvalErrorPrediction = 0.06484375 * 1280; time = 0.0149s; samplesPerSecond = 86125.7
08/18/2016 09:23:13:  Epoch[21 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16052628 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0148s; samplesPerSecond = 86241.7
08/18/2016 09:23:13:  Epoch[21 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16650000 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0150s; samplesPerSecond = 85555.8
08/18/2016 09:23:13:  Epoch[21 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16314554 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0149s; samplesPerSecond = 86143.1
08/18/2016 09:23:13: Finished Epoch[21 of 50]: [Training] CrossEntropyWithSoftmax = 0.15772334 * 10000; EvalErrorPrediction = 0.07760000 * 10000; totalSamplesSeen = 210000; learningRatePerSample = 0.1; epochTime=0.146267s
08/18/2016 09:23:13: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/models/simple.dnn.21'

08/18/2016 09:23:13: Starting Epoch 22: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 22: samples [210000..220000] (first sequence at sample 210000), worker rank 0, total workers 1

08/18/2016 09:23:13: Starting minibatch loop.
08/18/2016 09:23:13:  Epoch[22 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15215431 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0158s; samplesPerSecond = 81228.6
08/18/2016 09:23:13:  Epoch[22 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13743185 * 1280; EvalErrorPrediction = 0.06171875 * 1280; time = 0.0174s; samplesPerSecond = 73487.2
08/18/2016 09:23:13:  Epoch[22 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16302471 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0158s; samplesPerSecond = 81110.2
08/18/2016 09:23:13:  Epoch[22 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16212463 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0157s; samplesPerSecond = 81419.8
08/18/2016 09:23:13:  Epoch[22 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15395670 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0157s; samplesPerSecond = 81430.1
08/18/2016 09:23:13:  Epoch[22 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14864435 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0158s; samplesPerSecond = 81182.2
08/18/2016 09:23:13:  Epoch[22 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18065224 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0157s; samplesPerSecond = 81450.8
08/18/2016 09:23:13: Finished Epoch[22 of 50]: [Training] CrossEntropyWithSoftmax = 0.15908055 * 10000; EvalErrorPrediction = 0.07470000 * 10000; totalSamplesSeen = 220000; learningRatePerSample = 0.1; epochTime=0.126676s
08/18/2016 09:23:13: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/models/simple.dnn.22'

08/18/2016 09:23:13: Starting Epoch 23: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 23: samples [220000..230000] (first sequence at sample 220000), worker rank 0, total workers 1

08/18/2016 09:23:13: Starting minibatch loop.
08/18/2016 09:23:13:  Epoch[23 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17808341 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0147s; samplesPerSecond = 86862.1
08/18/2016 09:23:13:  Epoch[23 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17199432 * 1280; EvalErrorPrediction = 0.09140625 * 1280; time = 0.0165s; samplesPerSecond = 77575.8
08/18/2016 09:23:13:  Epoch[23 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15117135 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0153s; samplesPerSecond = 83813.5
08/18/2016 09:23:13:  Epoch[23 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.17853627 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0148s; samplesPerSecond = 86597.7
08/18/2016 09:23:13:  Epoch[23 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15493231 * 1280; EvalErrorPrediction = 0.07696250 * 1280; time = 0.0148s; samplesPerSecond = 86474.8
08/18/2016 09:23:13:  Epoch[23 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16575298 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0148s; samplesPerSecond = 86253.4
08/18/2016 09:23:13:  Epoch[23 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15395060 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0148s; samplesPerSecond = 86311.5
08/18/2016 09:23:13: Finished Epoch[23 of 50]: [Training] CrossEntropyWithSoftmax = 0.16410748 * 10000; EvalErrorPrediction = 0.07790000 * 10000; totalSamplesSeen = 230000; learningRatePerSample = 0.1; epochTime=0.119816s
08/18/2016 09:23:13: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/models/simple.dnn.23'

08/18/2016 09:23:13: Starting Epoch 24: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 24: samples [230000..240000] (first sequence at sample 230000), worker rank 0, total workers 1

08/18/2016 09:23:13: Starting minibatch loop.
08/18/2016 09:23:13:  Epoch[24 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16394640 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0157s; samplesPerSecond = 81497.5
08/18/2016 09:23:13:  Epoch[24 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17475795 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0175s; samplesPerSecond = 73009.4
08/18/2016 09:23:13:  Epoch[24 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14502659 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0162s; samplesPerSecond = 79173.6
08/18/2016 09:23:13:  Epoch[24 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.12699771 * 1280; EvalErrorPrediction = 0.05781250 * 1280; time = 0.0157s; samplesPerSecond = 81471.6
08/18/2016 09:23:13:  Epoch[24 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.18087049 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0158s; samplesPerSecond = 81166.8
08/18/2016 09:23:13:  Epoch[24 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13314967 * 1280; EvalErrorPrediction = 0.05937500 * 1280; time = 0.0157s; samplesPerSecond = 81404.2
08/18/2016 09:23:13:  Epoch[24 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15527067 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0157s; samplesPerSecond = 81663.9
08/18/2016 09:23:13: Finished Epoch[24 of 50]: [Training] CrossEntropyWithSoftmax = 0.15477764 * 10000; EvalErrorPrediction = 0.07420000 * 10000; totalSamplesSeen = 240000; learningRatePerSample = 0.1; epochTime=0.127056s
08/18/2016 09:23:13: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/models/simple.dnn.24'

08/18/2016 09:23:13: Starting Epoch 25: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 25: samples [240000..250000] (first sequence at sample 240000), worker rank 0, total workers 1

08/18/2016 09:23:13: Starting minibatch loop.
08/18/2016 09:23:13:  Epoch[25 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.13737992 * 1280; EvalErrorPrediction = 0.06250000 * 1280; time = 0.0148s; samplesPerSecond = 86539.1
08/18/2016 09:23:13:  Epoch[25 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17392012 * 1280; EvalErrorPrediction = 0.09218750 * 1280; time = 0.0166s; samplesPerSecond = 77318.0
08/18/2016 09:23:13:  Epoch[25 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14000478 * 1280; EvalErrorPrediction = 0.06640625 * 1280; time = 0.0148s; samplesPerSecond = 86469.0
08/18/2016 09:23:13:  Epoch[25 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15249076 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0148s; samplesPerSecond = 86299.9
08/18/2016 09:23:14:  Epoch[25 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17013674 * 1280; EvalErrorPrediction = 0.08828125 * 1280; time = 0.0148s; samplesPerSecond = 86457.3
08/18/2016 09:23:14:  Epoch[25 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.17271037 * 1280; EvalErrorPrediction = 0.08828125 * 1280; time = 0.0149s; samplesPerSecond = 85934.9
08/18/2016 09:23:14:  Epoch[25 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18482065 * 1280; EvalErrorPrediction = 0.10078125 * 1280; time = 0.0150s; samplesPerSecond = 85607.3
08/18/2016 09:23:14: Finished Epoch[25 of 50]: [Training] CrossEntropyWithSoftmax = 0.16432211 * 10000; EvalErrorPrediction = 0.08380000 * 10000; totalSamplesSeen = 250000; learningRatePerSample = 0.1; epochTime=0.119609s
08/18/2016 09:23:14: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/models/simple.dnn.25'

08/18/2016 09:23:14: Starting Epoch 26: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 26: samples [250000..260000] (first sequence at sample 250000), worker rank 0, total workers 1

08/18/2016 09:23:14: Starting minibatch loop.
08/18/2016 09:23:14:  Epoch[26 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17243935 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0148s; samplesPerSecond = 86305.7
08/18/2016 09:23:14:  Epoch[26 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.21459852 * 1280; EvalErrorPrediction = 0.09375000 * 1280; time = 0.0166s; samplesPerSecond = 77038.8
08/18/2016 09:23:14:  Epoch[26 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16779778 * 1280; EvalErrorPrediction = 0.08593750 * 1280; time = 0.0149s; samplesPerSecond = 85831.2
08/18/2016 09:23:14:  Epoch[26 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15444064 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0148s; samplesPerSecond = 86568.4
08/18/2016 09:23:14:  Epoch[26 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16801834 * 1280; EvalErrorPrediction = 0.09140625 * 1280; time = 0.0148s; samplesPerSecond = 86556.7
08/18/2016 09:23:14:  Epoch[26 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.12417469 * 1280; EvalErrorPrediction = 0.05312500 * 1280; time = 0.0147s; samplesPerSecond = 86927.0
08/18/2016 09:23:14:  Epoch[26 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16505775 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0149s; samplesPerSecond = 86062.0
08/18/2016 09:23:14: Finished Epoch[26 of 50]: [Training] CrossEntropyWithSoftmax = 0.16583987 * 10000; EvalErrorPrediction = 0.08000000 * 10000; totalSamplesSeen = 260000; learningRatePerSample = 0.1; epochTime=0.119471s
08/18/2016 09:23:14: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/models/simple.dnn.26'

08/18/2016 09:23:14: Starting Epoch 27: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 27: samples [260000..270000] (first sequence at sample 260000), worker rank 0, total workers 1

08/18/2016 09:23:14: Starting minibatch loop.
08/18/2016 09:23:14:  Epoch[27 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16579686 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0148s; samplesPerSecond = 86744.4
08/18/2016 09:23:14:  Epoch[27 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16927587 * 1280; EvalErrorPrediction = 0.09296875 * 1280; time = 0.0164s; samplesPerSecond = 77939.5
08/18/2016 09:23:14:  Epoch[27 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14731791 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0148s; samplesPerSecond = 86691.5
08/18/2016 09:23:14:  Epoch[27 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16392503 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0148s; samplesPerSecond = 86474.8
08/18/2016 09:23:14:  Epoch[27 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.17034235 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0148s; samplesPerSecond = 86451.4
08/18/2016 09:23:14:  Epoch[27 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16040993 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0148s; samplesPerSecond = 86201.1
08/18/2016 09:23:14:  Epoch[27 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17107973 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0152s; samplesPerSecond = 83956.4
08/18/2016 09:23:14: Finished Epoch[27 of 50]: [Training] CrossEntropyWithSoftmax = 0.16273350 * 10000; EvalErrorPrediction = 0.07950000 * 10000; totalSamplesSeen = 270000; learningRatePerSample = 0.1; epochTime=0.119691s
08/18/2016 09:23:14: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/models/simple.dnn.27'

08/18/2016 09:23:14: Starting Epoch 28: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 28: samples [270000..280000] (first sequence at sample 270000), worker rank 0, total workers 1

08/18/2016 09:23:14: Starting minibatch loop.
08/18/2016 09:23:14:  Epoch[28 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15706874 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0148s; samplesPerSecond = 86504.0
08/18/2016 09:23:14:  Epoch[28 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16088334 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0165s; samplesPerSecond = 77557.0
08/18/2016 09:23:14:  Epoch[28 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.16610873 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 0.0149s; samplesPerSecond = 86067.8
08/18/2016 09:23:14:  Epoch[28 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14506350 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0148s; samplesPerSecond = 86282.4
08/18/2016 09:23:14:  Epoch[28 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14170098 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0148s; samplesPerSecond = 86474.8
08/18/2016 09:23:14:  Epoch[28 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15534620 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0148s; samplesPerSecond = 86556.7
08/18/2016 09:23:14:  Epoch[28 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16403847 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0150s; samplesPerSecond = 85424.5
08/18/2016 09:23:14: Finished Epoch[28 of 50]: [Training] CrossEntropyWithSoftmax = 0.15697698 * 10000; EvalErrorPrediction = 0.07970000 * 10000; totalSamplesSeen = 280000; learningRatePerSample = 0.1; epochTime=0.119582s
08/18/2016 09:23:14: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/models/simple.dnn.28'

08/18/2016 09:23:14: Starting Epoch 29: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 29: samples [280000..290000] (first sequence at sample 280000), worker rank 0, total workers 1

08/18/2016 09:23:14: Starting minibatch loop.
08/18/2016 09:23:14:  Epoch[29 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15681946 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0147s; samplesPerSecond = 86891.6
08/18/2016 09:23:14:  Epoch[29 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13535986 * 1280; EvalErrorPrediction = 0.06484375 * 1280; time = 0.0164s; samplesPerSecond = 78196.6
08/18/2016 09:23:14:  Epoch[29 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.17443039 * 1280; EvalErrorPrediction = 0.09453125 * 1280; time = 0.0147s; samplesPerSecond = 86791.4
08/18/2016 09:23:14:  Epoch[29 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14585533 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0148s; samplesPerSecond = 86433.9
08/18/2016 09:23:14:  Epoch[29 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16543722 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0147s; samplesPerSecond = 86785.5
08/18/2016 09:23:14:  Epoch[29 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14467149 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0148s; samplesPerSecond = 86218.5
08/18/2016 09:23:14:  Epoch[29 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16792450 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0147s; samplesPerSecond = 86815.0
08/18/2016 09:23:14: Finished Epoch[29 of 50]: [Training] CrossEntropyWithSoftmax = 0.16052782 * 10000; EvalErrorPrediction = 0.08080000 * 10000; totalSamplesSeen = 290000; learningRatePerSample = 0.1; epochTime=0.118996s
08/18/2016 09:23:15: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/models/simple.dnn.29'

08/18/2016 09:23:15: Starting Epoch 30: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 30: samples [290000..300000] (first sequence at sample 290000), worker rank 0, total workers 1

08/18/2016 09:23:15: Starting minibatch loop.
08/18/2016 09:23:15:  Epoch[30 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15944378 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0147s; samplesPerSecond = 86968.3
08/18/2016 09:23:15:  Epoch[30 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15095129 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0165s; samplesPerSecond = 77735.9
08/18/2016 09:23:15:  Epoch[30 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14842370 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0148s; samplesPerSecond = 86568.4
08/18/2016 09:23:15:  Epoch[30 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16835256 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 0.0148s; samplesPerSecond = 86358.1
08/18/2016 09:23:15:  Epoch[30 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15946341 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0148s; samplesPerSecond = 86317.4
08/18/2016 09:23:15:  Epoch[30 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16039896 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0148s; samplesPerSecond = 86521.6
08/18/2016 09:23:15:  Epoch[30 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16299009 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0148s; samplesPerSecond = 86428.1
08/18/2016 09:23:15: Finished Epoch[30 of 50]: [Training] CrossEntropyWithSoftmax = 0.15704562 * 10000; EvalErrorPrediction = 0.08010000 * 10000; totalSamplesSeen = 300000; learningRatePerSample = 0.1; epochTime=0.119212s
08/18/2016 09:23:15: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/models/simple.dnn.30'

08/18/2016 09:23:15: Starting Epoch 31: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 31: samples [300000..310000] (first sequence at sample 300000), worker rank 0, total workers 1

08/18/2016 09:23:15: Starting minibatch loop.
08/18/2016 09:23:15:  Epoch[31 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16175009 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0158s; samplesPerSecond = 81264.7
08/18/2016 09:23:15:  Epoch[31 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15350379 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0174s; samplesPerSecond = 73601.3
08/18/2016 09:23:15:  Epoch[31 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15347362 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0157s; samplesPerSecond = 81306.0
08/18/2016 09:23:15:  Epoch[31 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14527326 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0158s; samplesPerSecond = 81084.5
08/18/2016 09:23:15:  Epoch[31 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16926255 * 1280; EvalErrorPrediction = 0.08515625 * 1280; time = 0.0157s; samplesPerSecond = 81280.2
08/18/2016 09:23:15:  Epoch[31 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13906174 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0157s; samplesPerSecond = 81601.4
08/18/2016 09:23:15:  Epoch[31 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15153933 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0157s; samplesPerSecond = 81601.4
08/18/2016 09:23:15: Finished Epoch[31 of 50]: [Training] CrossEntropyWithSoftmax = 0.15330140 * 10000; EvalErrorPrediction = 0.07790000 * 10000; totalSamplesSeen = 310000; learningRatePerSample = 0.1; epochTime=0.126412s
08/18/2016 09:23:15: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/models/simple.dnn.31'

08/18/2016 09:23:15: Starting Epoch 32: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 32: samples [310000..320000] (first sequence at sample 310000), worker rank 0, total workers 1

08/18/2016 09:23:15: Starting minibatch loop.
08/18/2016 09:23:15:  Epoch[32 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15780413 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0147s; samplesPerSecond = 86992.0
08/18/2016 09:23:15:  Epoch[32 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14718781 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0165s; samplesPerSecond = 77397.5
08/18/2016 09:23:15:  Epoch[32 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14815552 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0148s; samplesPerSecond = 86381.4
08/18/2016 09:23:15:  Epoch[32 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15589638 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0169s; samplesPerSecond = 75829.4
08/18/2016 09:23:15:  Epoch[32 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15081472 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0148s; samplesPerSecond = 86545.0
08/18/2016 09:23:15:  Epoch[32 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15917888 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0148s; samplesPerSecond = 86206.9
08/18/2016 09:23:15:  Epoch[32 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15811357 * 1280; EvalErrorPrediction = 0.08515625 * 1280; time = 0.0148s; samplesPerSecond = 86545.0
08/18/2016 09:23:15: Finished Epoch[32 of 50]: [Training] CrossEntropyWithSoftmax = 0.15582800 * 10000; EvalErrorPrediction = 0.07920000 * 10000; totalSamplesSeen = 320000; learningRatePerSample = 0.1; epochTime=0.121351s
08/18/2016 09:23:15: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/models/simple.dnn.32'

08/18/2016 09:23:15: Starting Epoch 33: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 33: samples [320000..330000] (first sequence at sample 320000), worker rank 0, total workers 1

08/18/2016 09:23:15: Starting minibatch loop.
08/18/2016 09:23:15:  Epoch[33 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16428132 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0147s; samplesPerSecond = 86815.0
08/18/2016 09:23:15:  Epoch[33 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17547922 * 1280; EvalErrorPrediction = 0.09140625 * 1280; time = 0.0166s; samplesPerSecond = 77154.9
08/18/2016 09:23:15:  Epoch[33 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15117135 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0148s; samplesPerSecond = 86235.9
08/18/2016 09:23:15:  Epoch[33 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15776210 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0149s; samplesPerSecond = 85981.1
08/18/2016 09:23:15:  Epoch[33 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.13863153 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0149s; samplesPerSecond = 85681.8
08/18/2016 09:23:15:  Epoch[33 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14410548 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0148s; samplesPerSecond = 86241.7
08/18/2016 09:23:15:  Epoch[33 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16479378 * 1280; EvalErrorPrediction = 0.08984375 * 1280; time = 0.0149s; samplesPerSecond = 86195.3
08/18/2016 09:23:15: Finished Epoch[33 of 50]: [Training] CrossEntropyWithSoftmax = 0.15587758 * 10000; EvalErrorPrediction = 0.08000000 * 10000; totalSamplesSeen = 330000; learningRatePerSample = 0.1; epochTime=0.119664s
08/18/2016 09:23:16: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/models/simple.dnn.33'

08/18/2016 09:23:16: Starting Epoch 34: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 34: samples [330000..340000] (first sequence at sample 330000), worker rank 0, total workers 1

08/18/2016 09:23:16: Starting minibatch loop.
08/18/2016 09:23:16:  Epoch[34 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14667526 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0158s; samplesPerSecond = 80940.9
08/18/2016 09:23:16:  Epoch[34 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15634509 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0175s; samplesPerSecond = 73030.2
08/18/2016 09:23:16:  Epoch[34 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15693443 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0159s; samplesPerSecond = 80604.5
08/18/2016 09:23:16:  Epoch[34 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14792595 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0158s; samplesPerSecond = 81187.4
08/18/2016 09:23:16:  Epoch[34 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16620936 * 1280; EvalErrorPrediction = 0.09062500 * 1280; time = 0.0160s; samplesPerSecond = 80245.8
08/18/2016 09:23:16:  Epoch[34 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16044407 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0158s; samplesPerSecond = 81269.8
08/18/2016 09:23:16:  Epoch[34 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15662746 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0158s; samplesPerSecond = 81171.9
08/18/2016 09:23:16: Finished Epoch[34 of 50]: [Training] CrossEntropyWithSoftmax = 0.15420134 * 10000; EvalErrorPrediction = 0.07950000 * 10000; totalSamplesSeen = 340000; learningRatePerSample = 0.1; epochTime=0.127149s
08/18/2016 09:23:16: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/models/simple.dnn.34'

08/18/2016 09:23:16: Starting Epoch 35: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 35: samples [340000..350000] (first sequence at sample 340000), worker rank 0, total workers 1

08/18/2016 09:23:16: Starting minibatch loop.
08/18/2016 09:23:16:  Epoch[35 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16275079 * 1280; EvalErrorPrediction = 0.09218750 * 1280; time = 0.0158s; samplesPerSecond = 80777.5
08/18/2016 09:23:16:  Epoch[35 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14440084 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0175s; samplesPerSecond = 73205.6
08/18/2016 09:23:16:  Epoch[35 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14822795 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0158s; samplesPerSecond = 80838.7
08/18/2016 09:23:16:  Epoch[35 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14810696 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0157s; samplesPerSecond = 81285.3
08/18/2016 09:23:16:  Epoch[35 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14210372 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0158s; samplesPerSecond = 81254.4
08/18/2016 09:23:16:  Epoch[35 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14510636 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0158s; samplesPerSecond = 81223.4
08/18/2016 09:23:16:  Epoch[35 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15983267 * 1280; EvalErrorPrediction = 0.09218750 * 1280; time = 0.0157s; samplesPerSecond = 81492.3
08/18/2016 09:23:16: Finished Epoch[35 of 50]: [Training] CrossEntropyWithSoftmax = 0.15051265 * 10000; EvalErrorPrediction = 0.07740000 * 10000; totalSamplesSeen = 350000; learningRatePerSample = 0.1; epochTime=0.126817s
08/18/2016 09:23:16: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/models/simple.dnn.35'

08/18/2016 09:23:16: Starting Epoch 36: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 36: samples [350000..360000] (first sequence at sample 350000), worker rank 0, total workers 1

08/18/2016 09:23:16: Starting minibatch loop.
08/18/2016 09:23:16:  Epoch[36 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14916126 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0158s; samplesPerSecond = 80838.7
08/18/2016 09:23:16:  Epoch[36 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.17715427 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 0.0175s; samplesPerSecond = 73205.6
08/18/2016 09:23:16:  Epoch[36 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15502880 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0165s; samplesPerSecond = 77575.8
08/18/2016 09:23:16:  Epoch[36 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15610175 * 1280; EvalErrorPrediction = 0.08515625 * 1280; time = 0.0178s; samplesPerSecond = 71982.9
08/18/2016 09:23:16:  Epoch[36 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15261445 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0158s; samplesPerSecond = 81012.7
08/18/2016 09:23:16:  Epoch[36 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13625555 * 1280; EvalErrorPrediction = 0.06562500 * 1280; time = 0.0158s; samplesPerSecond = 81125.6
08/18/2016 09:23:16:  Epoch[36 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14132891 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0158s; samplesPerSecond = 81017.8
08/18/2016 09:23:16: Finished Epoch[36 of 50]: [Training] CrossEntropyWithSoftmax = 0.15433134 * 10000; EvalErrorPrediction = 0.07960000 * 10000; totalSamplesSeen = 360000; learningRatePerSample = 0.1; epochTime=0.129677s
08/18/2016 09:23:16: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/models/simple.dnn.36'

08/18/2016 09:23:16: Starting Epoch 37: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 37: samples [360000..370000] (first sequence at sample 360000), worker rank 0, total workers 1

08/18/2016 09:23:16: Starting minibatch loop.
08/18/2016 09:23:16:  Epoch[37 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16839821 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 0.0159s; samplesPerSecond = 80523.4
08/18/2016 09:23:16:  Epoch[37 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14220848 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0176s; samplesPerSecond = 72710.7
08/18/2016 09:23:16:  Epoch[37 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15074270 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0158s; samplesPerSecond = 81058.8
08/18/2016 09:23:16:  Epoch[37 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.12536836 * 1280; EvalErrorPrediction = 0.05703125 * 1280; time = 0.0158s; samplesPerSecond = 81171.9
08/18/2016 09:23:16:  Epoch[37 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15707746 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0158s; samplesPerSecond = 81166.8
08/18/2016 09:23:16:  Epoch[37 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14255342 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0157s; samplesPerSecond = 81280.2
08/18/2016 09:23:16:  Epoch[37 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16218843 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0158s; samplesPerSecond = 81038.3
08/18/2016 09:23:16: Finished Epoch[37 of 50]: [Training] CrossEntropyWithSoftmax = 0.14977423 * 10000; EvalErrorPrediction = 0.07560000 * 10000; totalSamplesSeen = 370000; learningRatePerSample = 0.1; epochTime=0.127093s
08/18/2016 09:23:17: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/models/simple.dnn.37'

08/18/2016 09:23:17: Starting Epoch 38: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 38: samples [370000..380000] (first sequence at sample 370000), worker rank 0, total workers 1

08/18/2016 09:23:17: Starting minibatch loop.
08/18/2016 09:23:17:  Epoch[38 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16853386 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 0.0147s; samplesPerSecond = 87360.1
08/18/2016 09:23:17:  Epoch[38 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14644064 * 1280; EvalErrorPrediction = 0.07872500 * 1280; time = 0.0165s; samplesPerSecond = 77500.6
08/18/2016 09:23:17:  Epoch[38 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14097066 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0149s; samplesPerSecond = 85946.4
08/18/2016 09:23:17:  Epoch[38 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.16172438 * 1280; EvalErrorPrediction = 0.08906250 * 1280; time = 0.0148s; samplesPerSecond = 86346.5
08/18/2016 09:23:17:  Epoch[38 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.13763309 * 1280; EvalErrorPrediction = 0.06640625 * 1280; time = 0.0148s; samplesPerSecond = 86439.8
08/18/2016 09:23:17:  Epoch[38 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15780392 * 1280; EvalErrorPrediction = 0.09062500 * 1280; time = 0.0149s; samplesPerSecond = 86079.4
08/18/2016 09:23:17:  Epoch[38 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.13847876 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0148s; samplesPerSecond = 86358.1
08/18/2016 09:23:17: Finished Epoch[38 of 50]: [Training] CrossEntropyWithSoftmax = 0.15008671 * 10000; EvalErrorPrediction = 0.07950000 * 10000; totalSamplesSeen = 380000; learningRatePerSample = 0.1; epochTime=0.119813s
08/18/2016 09:23:17: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/models/simple.dnn.38'

08/18/2016 09:23:17: Starting Epoch 39: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 39: samples [380000..390000] (first sequence at sample 380000), worker rank 0, total workers 1

08/18/2016 09:23:17: Starting minibatch loop.
08/18/2016 09:23:17:  Epoch[39 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14603531 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0148s; samplesPerSecond = 86662.2
08/18/2016 09:23:17:  Epoch[39 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14158952 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0165s; samplesPerSecond = 77679.3
08/18/2016 09:23:17:  Epoch[39 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15175228 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0148s; samplesPerSecond = 86638.7
08/18/2016 09:23:17:  Epoch[39 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15481510 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0149s; samplesPerSecond = 85854.2
08/18/2016 09:23:17:  Epoch[39 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16663208 * 1280; EvalErrorPrediction = 0.08906250 * 1280; time = 0.0148s; samplesPerSecond = 86591.8
08/18/2016 09:23:17:  Epoch[39 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.18570747 * 1280; EvalErrorPrediction = 0.09062500 * 1280; time = 0.0149s; samplesPerSecond = 85952.2
08/18/2016 09:23:17:  Epoch[39 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.19004841 * 1280; EvalErrorPrediction = 0.09687500 * 1280; time = 0.0148s; samplesPerSecond = 86556.7
08/18/2016 09:23:17: Finished Epoch[39 of 50]: [Training] CrossEntropyWithSoftmax = 0.16019532 * 10000; EvalErrorPrediction = 0.08150000 * 10000; totalSamplesSeen = 390000; learningRatePerSample = 0.1; epochTime=0.119347s
08/18/2016 09:23:17: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/models/simple.dnn.39'

08/18/2016 09:23:17: Starting Epoch 40: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 40: samples [390000..400000] (first sequence at sample 390000), worker rank 0, total workers 1

08/18/2016 09:23:17: Starting minibatch loop.
08/18/2016 09:23:17:  Epoch[40 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.18147442 * 1280; EvalErrorPrediction = 0.09531250 * 1280; time = 0.0152s; samplesPerSecond = 84182.8
08/18/2016 09:23:17:  Epoch[40 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15084016 * 1280; EvalErrorPrediction = 0.07149375 * 1280; time = 0.0165s; samplesPerSecond = 77585.2
08/18/2016 09:23:17:  Epoch[40 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15693560 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0149s; samplesPerSecond = 86160.5
08/18/2016 09:23:17:  Epoch[40 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15859179 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0147s; samplesPerSecond = 86832.6
08/18/2016 09:23:17:  Epoch[40 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.16059690 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0148s; samplesPerSecond = 86562.5
08/18/2016 09:23:17:  Epoch[40 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.16117716 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0148s; samplesPerSecond = 86363.9
08/18/2016 09:23:17:  Epoch[40 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14261456 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0148s; samplesPerSecond = 86241.7
08/18/2016 09:23:17: Finished Epoch[40 of 50]: [Training] CrossEntropyWithSoftmax = 0.15675441 * 10000; EvalErrorPrediction = 0.07930000 * 10000; totalSamplesSeen = 400000; learningRatePerSample = 0.1; epochTime=0.119782s
08/18/2016 09:23:17: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/models/simple.dnn.40'

08/18/2016 09:23:17: Starting Epoch 41: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 41: samples [400000..410000] (first sequence at sample 400000), worker rank 0, total workers 1

08/18/2016 09:23:17: Starting minibatch loop.
08/18/2016 09:23:17:  Epoch[41 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16487644 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0150s; samplesPerSecond = 85242.4
08/18/2016 09:23:17:  Epoch[41 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13255112 * 1280; EvalErrorPrediction = 0.06328125 * 1280; time = 0.0166s; samplesPerSecond = 76936.9
08/18/2016 09:23:17:  Epoch[41 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14598637 * 1280; EvalErrorPrediction = 0.07578125 * 1280; time = 0.0148s; samplesPerSecond = 86218.5
08/18/2016 09:23:17:  Epoch[41 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15061154 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0148s; samplesPerSecond = 86509.9
08/18/2016 09:23:17:  Epoch[41 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14728184 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0148s; samplesPerSecond = 86329.0
08/18/2016 09:23:17:  Epoch[41 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14453273 * 1280; EvalErrorPrediction = 0.06484375 * 1280; time = 0.0149s; samplesPerSecond = 85647.4
08/18/2016 09:23:17:  Epoch[41 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15256281 * 1280; EvalErrorPrediction = 0.07890625 * 1280; time = 0.0148s; samplesPerSecond = 86521.6
08/18/2016 09:23:17: Finished Epoch[41 of 50]: [Training] CrossEntropyWithSoftmax = 0.14738488 * 10000; EvalErrorPrediction = 0.07340000 * 10000; totalSamplesSeen = 410000; learningRatePerSample = 0.1; epochTime=0.119913s
08/18/2016 09:23:17: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/models/simple.dnn.41'

08/18/2016 09:23:17: Starting Epoch 42: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 42: samples [410000..420000] (first sequence at sample 410000), worker rank 0, total workers 1

08/18/2016 09:23:17: Starting minibatch loop.
08/18/2016 09:23:17:  Epoch[42 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14050165 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0157s; samplesPerSecond = 81544.2
08/18/2016 09:23:17:  Epoch[42 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14012207 * 1280; EvalErrorPrediction = 0.07187500 * 1280; time = 0.0174s; samplesPerSecond = 73512.5
08/18/2016 09:23:18:  Epoch[42 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15301080 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0416s; samplesPerSecond = 30793.7
08/18/2016 09:23:18:  Epoch[42 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14769468 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0159s; samplesPerSecond = 80584.2
08/18/2016 09:23:18:  Epoch[42 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15724311 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0158s; samplesPerSecond = 81130.8
08/18/2016 09:23:18:  Epoch[42 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15916414 * 1280; EvalErrorPrediction = 0.08359375 * 1280; time = 0.0158s; samplesPerSecond = 81069.1
08/18/2016 09:23:18:  Epoch[42 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.18246956 * 1280; EvalErrorPrediction = 0.09687500 * 1280; time = 0.0158s; samplesPerSecond = 81017.8
08/18/2016 09:23:18: Finished Epoch[42 of 50]: [Training] CrossEntropyWithSoftmax = 0.15400653 * 10000; EvalErrorPrediction = 0.07950000 * 10000; totalSamplesSeen = 420000; learningRatePerSample = 0.1; epochTime=0.152577s
08/18/2016 09:23:18: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/models/simple.dnn.42'

08/18/2016 09:23:18: Starting Epoch 43: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 43: samples [420000..430000] (first sequence at sample 420000), worker rank 0, total workers 1

08/18/2016 09:23:18: Starting minibatch loop.
08/18/2016 09:23:18:  Epoch[43 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16290075 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 0.0158s; samplesPerSecond = 81064.0
08/18/2016 09:23:18:  Epoch[43 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.12216755 * 1280; EvalErrorPrediction = 0.06328125 * 1280; time = 0.0176s; samplesPerSecond = 72930.3
08/18/2016 09:23:18:  Epoch[43 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14746578 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0159s; samplesPerSecond = 80741.8
08/18/2016 09:23:18:  Epoch[43 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15294766 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0158s; samplesPerSecond = 80900.0
08/18/2016 09:23:18:  Epoch[43 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.15701170 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0157s; samplesPerSecond = 81331.8
08/18/2016 09:23:18:  Epoch[43 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14176731 * 1280; EvalErrorPrediction = 0.07968750 * 1280; time = 0.0166s; samplesPerSecond = 77071.3
08/18/2016 09:23:18:  Epoch[43 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.17110386 * 1280; EvalErrorPrediction = 0.08671875 * 1280; time = 0.0158s; samplesPerSecond = 81228.6
08/18/2016 09:23:18: Finished Epoch[43 of 50]: [Training] CrossEntropyWithSoftmax = 0.14959363 * 10000; EvalErrorPrediction = 0.07820000 * 10000; totalSamplesSeen = 430000; learningRatePerSample = 0.1; epochTime=0.127835s
08/18/2016 09:23:18: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/models/simple.dnn.43'

08/18/2016 09:23:18: Starting Epoch 44: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 44: samples [430000..440000] (first sequence at sample 430000), worker rank 0, total workers 1

08/18/2016 09:23:18: Starting minibatch loop.
08/18/2016 09:23:18:  Epoch[44 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.16002386 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0157s; samplesPerSecond = 81306.0
08/18/2016 09:23:18:  Epoch[44 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15523396 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0179s; samplesPerSecond = 71420.6
08/18/2016 09:23:18:  Epoch[44 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.13000481 * 1280; EvalErrorPrediction = 0.06171875 * 1280; time = 0.0167s; samplesPerSecond = 76623.8
08/18/2016 09:23:18:  Epoch[44 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14638886 * 1280; EvalErrorPrediction = 0.07656250 * 1280; time = 0.0159s; samplesPerSecond = 80619.8
08/18/2016 09:23:18:  Epoch[44 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14897165 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0158s; samplesPerSecond = 80946.1
08/18/2016 09:23:18:  Epoch[44 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13170981 * 1280; EvalErrorPrediction = 0.06015625 * 1280; time = 0.0158s; samplesPerSecond = 81084.5
08/18/2016 09:23:18:  Epoch[44 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15749292 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0158s; samplesPerSecond = 81259.5
08/18/2016 09:23:18: Finished Epoch[44 of 50]: [Training] CrossEntropyWithSoftmax = 0.14804790 * 10000; EvalErrorPrediction = 0.07370000 * 10000; totalSamplesSeen = 440000; learningRatePerSample = 0.1; epochTime=0.12833s
08/18/2016 09:23:18: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/models/simple.dnn.44'

08/18/2016 09:23:18: Starting Epoch 45: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 45: samples [440000..450000] (first sequence at sample 440000), worker rank 0, total workers 1

08/18/2016 09:23:18: Starting minibatch loop.
08/18/2016 09:23:18:  Epoch[45 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.17798588 * 1280; EvalErrorPrediction = 0.09453125 * 1280; time = 0.0159s; samplesPerSecond = 80716.4
08/18/2016 09:23:18:  Epoch[45 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14361205 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0180s; samplesPerSecond = 71194.2
08/18/2016 09:23:18:  Epoch[45 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15862515 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0158s; samplesPerSecond = 81146.2
08/18/2016 09:23:18:  Epoch[45 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.15260954 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0158s; samplesPerSecond = 80951.2
08/18/2016 09:23:18:  Epoch[45 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14747958 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0157s; samplesPerSecond = 81523.5
08/18/2016 09:23:18:  Epoch[45 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13470378 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0158s; samplesPerSecond = 81223.4
08/18/2016 09:23:18:  Epoch[45 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15045271 * 1280; EvalErrorPrediction = 0.08750000 * 1280; time = 0.0158s; samplesPerSecond = 80971.7
08/18/2016 09:23:18: Finished Epoch[45 of 50]: [Training] CrossEntropyWithSoftmax = 0.15046431 * 10000; EvalErrorPrediction = 0.07730000 * 10000; totalSamplesSeen = 450000; learningRatePerSample = 0.1; epochTime=0.127434s
08/18/2016 09:23:18: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/models/simple.dnn.45'

08/18/2016 09:23:18: Starting Epoch 46: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 46: samples [450000..460000] (first sequence at sample 450000), worker rank 0, total workers 1

08/18/2016 09:23:18: Starting minibatch loop.
08/18/2016 09:23:18:  Epoch[46 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.12665298 * 1280; EvalErrorPrediction = 0.05937500 * 1280; time = 0.0158s; samplesPerSecond = 81218.3
08/18/2016 09:23:18:  Epoch[46 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.16434898 * 1280; EvalErrorPrediction = 0.08046875 * 1280; time = 0.0175s; samplesPerSecond = 73222.4
08/18/2016 09:23:18:  Epoch[46 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14385383 * 1280; EvalErrorPrediction = 0.07548125 * 1280; time = 0.0157s; samplesPerSecond = 81352.5
08/18/2016 09:23:19:  Epoch[46 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.13879824 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0157s; samplesPerSecond = 81399.0
08/18/2016 09:23:19:  Epoch[46 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14248524 * 1280; EvalErrorPrediction = 0.06562500 * 1280; time = 0.0157s; samplesPerSecond = 81585.8
08/18/2016 09:23:19:  Epoch[46 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14791856 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0161s; samplesPerSecond = 79355.2
08/18/2016 09:23:19:  Epoch[46 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.15108385 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0158s; samplesPerSecond = 81022.9
08/18/2016 09:23:19: Finished Epoch[46 of 50]: [Training] CrossEntropyWithSoftmax = 0.14530992 * 10000; EvalErrorPrediction = 0.07120000 * 10000; totalSamplesSeen = 460000; learningRatePerSample = 0.1; epochTime=0.126956s
08/18/2016 09:23:19: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/models/simple.dnn.46'

08/18/2016 09:23:19: Starting Epoch 47: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 47: samples [460000..470000] (first sequence at sample 460000), worker rank 0, total workers 1

08/18/2016 09:23:19: Starting minibatch loop.
08/18/2016 09:23:19:  Epoch[47 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14703878 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0158s; samplesPerSecond = 81146.2
08/18/2016 09:23:19:  Epoch[47 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.15384475 * 1280; EvalErrorPrediction = 0.08437500 * 1280; time = 0.0178s; samplesPerSecond = 71833.4
08/18/2016 09:23:19:  Epoch[47 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.15466433 * 1280; EvalErrorPrediction = 0.08711875 * 1280; time = 0.0158s; samplesPerSecond = 81151.3
08/18/2016 09:23:19:  Epoch[47 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.11875772 * 1280; EvalErrorPrediction = 0.06484375 * 1280; time = 0.0157s; samplesPerSecond = 81311.1
08/18/2016 09:23:19:  Epoch[47 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.13452339 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0158s; samplesPerSecond = 81099.9
08/18/2016 09:23:19:  Epoch[47 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.15135207 * 1280; EvalErrorPrediction = 0.07812500 * 1280; time = 0.0157s; samplesPerSecond = 81306.0
08/18/2016 09:23:19:  Epoch[47 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.13608027 * 1280; EvalErrorPrediction = 0.07031250 * 1280; time = 0.0157s; samplesPerSecond = 81378.3
08/18/2016 09:23:19: Finished Epoch[47 of 50]: [Training] CrossEntropyWithSoftmax = 0.14233258 * 10000; EvalErrorPrediction = 0.07670000 * 10000; totalSamplesSeen = 470000; learningRatePerSample = 0.1; epochTime=0.127083s
08/18/2016 09:23:19: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/models/simple.dnn.47'

08/18/2016 09:23:19: Starting Epoch 48: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 48: samples [470000..480000] (first sequence at sample 470000), worker rank 0, total workers 1

08/18/2016 09:23:19: Starting minibatch loop.
08/18/2016 09:23:19:  Epoch[48 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14785752 * 1280; EvalErrorPrediction = 0.07734375 * 1280; time = 0.0147s; samplesPerSecond = 87163.8
08/18/2016 09:23:19:  Epoch[48 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.14769986 * 1280; EvalErrorPrediction = 0.08281250 * 1280; time = 0.0165s; samplesPerSecond = 77759.6
08/18/2016 09:23:19:  Epoch[48 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14862740 * 1280; EvalErrorPrediction = 0.07421875 * 1280; time = 0.0149s; samplesPerSecond = 86085.1
08/18/2016 09:23:19:  Epoch[48 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14010720 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0147s; samplesPerSecond = 86832.6
08/18/2016 09:23:19:  Epoch[48 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14017634 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 0.0148s; samplesPerSecond = 86253.4
08/18/2016 09:23:19:  Epoch[48 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14271622 * 1280; EvalErrorPrediction = 0.06796875 * 1280; time = 0.0154s; samplesPerSecond = 83003.7
08/18/2016 09:23:19:  Epoch[48 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.12745638 * 1280; EvalErrorPrediction = 0.06406250 * 1280; time = 0.0149s; samplesPerSecond = 85906.0
08/18/2016 09:23:19: Finished Epoch[48 of 50]: [Training] CrossEntropyWithSoftmax = 0.14265388 * 10000; EvalErrorPrediction = 0.07220000 * 10000; totalSamplesSeen = 480000; learningRatePerSample = 0.1; epochTime=0.119871s
08/18/2016 09:23:19: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/models/simple.dnn.48'

08/18/2016 09:23:19: Starting Epoch 49: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 49: samples [480000..490000] (first sequence at sample 480000), worker rank 0, total workers 1

08/18/2016 09:23:19: Starting minibatch loop.
08/18/2016 09:23:19:  Epoch[49 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.15698130 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0148s; samplesPerSecond = 86334.8
08/18/2016 09:23:19:  Epoch[49 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.12932813 * 1280; EvalErrorPrediction = 0.06640625 * 1280; time = 0.0165s; samplesPerSecond = 77604.0
08/18/2016 09:23:19:  Epoch[49 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.14570198 * 1280; EvalErrorPrediction = 0.07500000 * 1280; time = 0.0148s; samplesPerSecond = 86276.6
08/18/2016 09:23:19:  Epoch[49 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14288082 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0147s; samplesPerSecond = 86832.6
08/18/2016 09:23:19:  Epoch[49 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.14049444 * 1280; EvalErrorPrediction = 0.06406250 * 1280; time = 0.0150s; samplesPerSecond = 85550.1
08/18/2016 09:23:19:  Epoch[49 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.13541660 * 1280; EvalErrorPrediction = 0.06015625 * 1280; time = 0.0149s; samplesPerSecond = 86177.9
08/18/2016 09:23:19:  Epoch[49 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.16448231 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0150s; samplesPerSecond = 85350.4
08/18/2016 09:23:19: Finished Epoch[49 of 50]: [Training] CrossEntropyWithSoftmax = 0.14474827 * 10000; EvalErrorPrediction = 0.07090000 * 10000; totalSamplesSeen = 490000; learningRatePerSample = 0.1; epochTime=0.119672s
08/18/2016 09:23:19: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/models/simple.dnn.49'

08/18/2016 09:23:19: Starting Epoch 50: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 50: samples [490000..500000] (first sequence at sample 490000), worker rank 0, total workers 1

08/18/2016 09:23:19: Starting minibatch loop.
08/18/2016 09:23:19:  Epoch[50 of 50]-Minibatch[   1-  10, 14.29%]: CrossEntropyWithSoftmax = 0.14711052 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0151s; samplesPerSecond = 84841.3
08/18/2016 09:23:19:  Epoch[50 of 50]-Minibatch[  11-  20, 28.57%]: CrossEntropyWithSoftmax = 0.13556508 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0166s; samplesPerSecond = 77122.4
08/18/2016 09:23:19:  Epoch[50 of 50]-Minibatch[  21-  30, 42.86%]: CrossEntropyWithSoftmax = 0.13794255 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0148s; samplesPerSecond = 86323.2
08/18/2016 09:23:19:  Epoch[50 of 50]-Minibatch[  31-  40, 57.14%]: CrossEntropyWithSoftmax = 0.14866614 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0148s; samplesPerSecond = 86265.0
08/18/2016 09:23:19:  Epoch[50 of 50]-Minibatch[  41-  50, 71.43%]: CrossEntropyWithSoftmax = 0.13444252 * 1280; EvalErrorPrediction = 0.06640625 * 1280; time = 0.0148s; samplesPerSecond = 86201.1
08/18/2016 09:23:19:  Epoch[50 of 50]-Minibatch[  51-  60, 85.71%]: CrossEntropyWithSoftmax = 0.14465528 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0149s; samplesPerSecond = 86108.3
08/18/2016 09:23:20:  Epoch[50 of 50]-Minibatch[  61-  70, 100.00%]: CrossEntropyWithSoftmax = 0.14756641 * 1280; EvalErrorPrediction = 0.06913125 * 1280; time = 0.0148s; samplesPerSecond = 86381.4
08/18/2016 09:23:20: Finished Epoch[50 of 50]: [Training] CrossEntropyWithSoftmax = 0.14188734 * 10000; EvalErrorPrediction = 0.07390000 * 10000; totalSamplesSeen = 500000; learningRatePerSample = 0.1; epochTime=0.11994s
08/18/2016 09:23:20: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/models/simple.dnn'
08/18/2016 09:23:20: CNTKCommandTrainEnd: Simple_Demo

08/18/2016 09:23:20: Action "train" complete.


08/18/2016 09:23:20: ##############################################################################
08/18/2016 09:23:20: #                                                                            #
08/18/2016 09:23:20: # Action "write"                                                             #
08/18/2016 09:23:20: #                                                                            #
08/18/2016 09:23:20: ##############################################################################


Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalErrorPrediction = ErrorPrediction()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *1]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *1]
Validating --> MeanOfFeatures = Mean (features) : [2 x *1] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *1] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *1], [2], [2] -> [2 x *1]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *1] -> [50 x *1]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *1] -> [2 x 1 x *1]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *1], [2 x 1] -> [2 x 1 x *1]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *1] -> [2 x 1 x *1]
Validating --> Prior = Mean (labels) : [2 x *1] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *1], [2] -> [2 x 1 x *1]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.



Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 25 matrices, 3 are shared as 1, and 22 are not shared.

	{ CrossEntropyWithSoftmax : [1]
	  EvalErrorPrediction : [1]
	  PosteriorProb : [2 x 1 x *1] }

Minibatch[0]: ActualMBSize = 603
Written to C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/SimpleOutput*
Total Samples Evaluated = 603

08/18/2016 09:23:20: Action "write" complete.

08/18/2016 09:23:20: __COMPLETED__
=== Deleting last epoch data
==== Re-running from checkpoint
=== Running /cygdrive/c/jenkins/workspace/CNTK-Test-Windows-W1/x64/release/cntk.exe configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple/cntk.cntk currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu DeviceId=-1 timestamping=true makeMode=true
-------------------------------------------------------------------
Build info: 

		Built time: Aug 18 2016 08:32:42
		Last modified date: Thu Aug 18 07:29:22 2016
		Build type: Release
		Build target: GPU
		With 1bit-SGD: no
		Math lib: mkl
		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
		CUB_PATH: C:\src\cub-1.4.1
		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
		Build Branch: HEAD
		Build SHA1: 1812482490dc842c0d654b96bb2ccd41afb62959
		Built by svcphil on LIANA-09-w
		Build Path: c:\jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
-------------------------------------------------------------------
Changed current directory to C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
08/18/2016 09:23:21: -------------------------------------------------------------------
08/18/2016 09:23:21: Build info: 

08/18/2016 09:23:21: 		Built time: Aug 18 2016 08:32:42
08/18/2016 09:23:21: 		Last modified date: Thu Aug 18 07:29:22 2016
08/18/2016 09:23:21: 		Build type: Release
08/18/2016 09:23:21: 		Build target: GPU
08/18/2016 09:23:21: 		With 1bit-SGD: no
08/18/2016 09:23:21: 		Math lib: mkl
08/18/2016 09:23:21: 		CUDA_PATH: C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v7.5
08/18/2016 09:23:21: 		CUB_PATH: C:\src\cub-1.4.1
08/18/2016 09:23:21: 		CUDNN_PATH: c:\NVIDIA\cudnn-4.0\cuda
08/18/2016 09:23:21: 		Build Branch: HEAD
08/18/2016 09:23:21: 		Build SHA1: 1812482490dc842c0d654b96bb2ccd41afb62959
08/18/2016 09:23:21: 		Built by svcphil on LIANA-09-w
08/18/2016 09:23:21: 		Build Path: c:\jenkins\workspace\CNTK-Build-Windows\Source\CNTK\
08/18/2016 09:23:21: -------------------------------------------------------------------
08/18/2016 09:23:22: -------------------------------------------------------------------
08/18/2016 09:23:22: GPU info:

08/18/2016 09:23:22: 		Device[0]: cores = 2496; computeCapability = 5.2; type = "Quadro M4000"; memory = 8090 MB
08/18/2016 09:23:22: -------------------------------------------------------------------

08/18/2016 09:23:22: Running on cntk-muc00 at 2016/08/18 09:23:22
08/18/2016 09:23:22: Command line: 
C:\jenkins\workspace\CNTK-Test-Windows-W1\x64\release\cntk.exe  configFile=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple/cntk.cntk  currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data  RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu  DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data  ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple  OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu  DeviceId=-1  timestamping=true  makeMode=true



08/18/2016 09:23:22: >>>>>>>>>>>>>>>>>>>> RAW CONFIG (VARIABLES NOT RESOLVED) >>>>>>>>>>>>>>>>>>>>
08/18/2016 09:23:22: command=Simple_Demo:Simple_Demo_Output
DeviceNumber=-1
precision=float
modelPath=$RunDir$/models/simple.dnn
deviceId=$DeviceNumber$
outputNodeNames=ScaledLogLikelihood
traceLevel=1
Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=$DataDir$/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]
Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=$DataDir$/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=$RunDir$/SimpleOutput    
]
currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu
DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple
OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu
DeviceId=-1
timestamping=true
makeMode=true

08/18/2016 09:23:22: <<<<<<<<<<<<<<<<<<<< RAW CONFIG (VARIABLES NOT RESOLVED)  <<<<<<<<<<<<<<<<<<<<

08/18/2016 09:23:22: >>>>>>>>>>>>>>>>>>>> RAW CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
08/18/2016 09:23:22: command=Simple_Demo:Simple_Demo_Output
DeviceNumber=-1
precision=float
modelPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/models/simple.dnn
deviceId=-1
outputNodeNames=ScaledLogLikelihood
traceLevel=1
Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]
Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/SimpleOutput    
]
currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu
DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple
OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu
DeviceId=-1
timestamping=true
makeMode=true

08/18/2016 09:23:22: <<<<<<<<<<<<<<<<<<<< RAW CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<

08/18/2016 09:23:22: >>>>>>>>>>>>>>>>>>>> PROCESSED CONFIG WITH ALL VARIABLES RESOLVED >>>>>>>>>>>>>>>>>>>>
configparameters: cntk.cntk:command=Simple_Demo:Simple_Demo_Output
configparameters: cntk.cntk:ConfigDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Simple
configparameters: cntk.cntk:currentDirectory=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
configparameters: cntk.cntk:DataDir=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data
configparameters: cntk.cntk:deviceId=-1
configparameters: cntk.cntk:DeviceNumber=-1
configparameters: cntk.cntk:makeMode=true
configparameters: cntk.cntk:modelPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/models/simple.dnn
configparameters: cntk.cntk:OutputDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu
configparameters: cntk.cntk:outputNodeNames=ScaledLogLikelihood
configparameters: cntk.cntk:precision=float
configparameters: cntk.cntk:RunDir=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu
configparameters: cntk.cntk:Simple_Demo=[
    action=train
    SimpleNetworkBuilder=[
        layerSizes=2:50*2:2
        trainingCriterion=CrossEntropyWithSoftmax
        evalCriterion=ErrorPrediction
        layerTypes=Sigmoid
        initValueScale=1.0
        applyMeanVarNorm=true
        uniformInit=true
        needPrior=true
    ]
    SGD=[
        epochSize=0 
        minibatchSize=128
        learningRatesPerSample=0.1
        momentumAsTimeConstant=2500
        dropoutRate=0.0
        maxEpochs=50
        keepCheckPointFiles = true
    ]
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTrain_cntk_text.txt
        input = [
            features=[
dim = 2      
                format = "dense"
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
]

configparameters: cntk.cntk:Simple_Demo_Output=[
    action=write
    reader=[
        readerType=CNTKTextFormatReader
        file=C:\jenkins\workspace\CNTK-Test-Windows-W1\Tests\EndToEndTests\Speech\Data/SimpleDataTest_cntk_text.txt
        input = [
            features=[
dim = 2 
                format = "dense" 
            ]
            labels=[
dim = 2 
                format = "dense"
            ]
        ]
    ]
outputPath=C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/SimpleOutput    
]

configparameters: cntk.cntk:timestamping=true
configparameters: cntk.cntk:traceLevel=1
08/18/2016 09:23:22: <<<<<<<<<<<<<<<<<<<< PROCESSED CONFIG WITH ALL VARIABLES RESOLVED <<<<<<<<<<<<<<<<<<<<
08/18/2016 09:23:22: Commands: Simple_Demo Simple_Demo_Output
08/18/2016 09:23:22: Precision = "float"
08/18/2016 09:23:22: CNTKModelPath: C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/models/simple.dnn
08/18/2016 09:23:22: CNTKCommandTrainInfo: Simple_Demo : 50
08/18/2016 09:23:22: CNTKCommandTrainInfo: CNTKNoMoreCommands_Total : 50

08/18/2016 09:23:22: ##############################################################################
08/18/2016 09:23:22: #                                                                            #
08/18/2016 09:23:22: # Action "train"                                                             #
08/18/2016 09:23:22: #                                                                            #
08/18/2016 09:23:22: ##############################################################################

08/18/2016 09:23:22: CNTKCommandTrainBegin: Simple_Demo
SimpleNetworkBuilder Using CPU

08/18/2016 09:23:22: Starting from checkpoint. Loading network from 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/models/simple.dnn.49'.

Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalErrorPrediction = ErrorPrediction()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *1]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *1]
Validating --> MeanOfFeatures = Mean (features) : [2 x *1] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *1] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *1], [2], [2] -> [2 x *1]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *1] -> [50 x *1]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *1], [50 x 1] -> [50 x 1 x *1]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *1] -> [50 x 1 x *1]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *1] -> [2 x 1 x *1]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *1], [2 x 1] -> [2 x 1 x *1]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [2 x *1], [2 x 1 x *1] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *1] -> [2 x 1 x *1]
Validating --> Prior = Mean (labels) : [2 x *1] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *1], [2] -> [2 x 1 x *1]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.

08/18/2016 09:23:22: Loaded model with 25 nodes on CPU.

08/18/2016 09:23:22: Training criterion node(s):
08/18/2016 09:23:22: 	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax

08/18/2016 09:23:22: Evaluation criterion node(s):
08/18/2016 09:23:22: 	EvalErrorPrediction = ErrorPrediction


Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 40 matrices, 19 are shared as 8, and 21 are not shared.

	{ H1 : [50 x 1 x *1]
	  W0*features : [50 x *1] (gradient) }
	{ W0*features+B0 : [50 x 1 x *1] (gradient)
	  W1*H1 : [50 x 1 x *1] }
	{ B0 : [50 x 1] (gradient)
	  H1 : [50 x 1 x *1] (gradient)
	  W1*H1+B1 : [50 x 1 x *1] (gradient)
	  W2*H1 : [2 x 1 x *1] }
	{ H2 : [50 x 1 x *1]
	  W1*H1 : [50 x 1 x *1] (gradient) }
	{ W0 : [50 x 2] (gradient)
	  W0*features+B0 : [50 x 1 x *1] }
	{ W1 : [50 x 50] (gradient)
	  W1*H1+B1 : [50 x 1 x *1] }
	{ HLast : [2 x 1 x *1]
	  W2 : [2 x 50] (gradient) }
	{ B1 : [50 x 1] (gradient)
	  H2 : [50 x 1 x *1] (gradient)
	  HLast : [2 x 1 x *1] (gradient) }


08/18/2016 09:23:22: Training 2802 parameters in 6 out of 6 parameter tensors and 15 nodes with gradient:

08/18/2016 09:23:22: 	Node 'B0' (LearnableParameter operation) : [50 x 1]
08/18/2016 09:23:22: 	Node 'B1' (LearnableParameter operation) : [50 x 1]
08/18/2016 09:23:22: 	Node 'B2' (LearnableParameter operation) : [2 x 1]
08/18/2016 09:23:22: 	Node 'W0' (LearnableParameter operation) : [50 x 2]
08/18/2016 09:23:22: 	Node 'W1' (LearnableParameter operation) : [50 x 50]
08/18/2016 09:23:22: 	Node 'W2' (LearnableParameter operation) : [2 x 50]

08/18/2016 09:23:22: No PreCompute nodes found, or all already computed. Skipping pre-computation step.

08/18/2016 09:23:22: Starting Epoch 50: learning rate per sample = 0.100000  effective momentum = 0.950085  momentum as time constant = 2499.8 samples
BlockRandomizer::StartEpoch: epoch 50: samples [490000..500000] (first sequence at sample 490000), worker rank 0, total workers 1

08/18/2016 09:23:22: Starting minibatch loop.
08/18/2016 09:23:22:  Epoch[50 of 50]-Minibatch[   1-  10, 0.00000000000003%]: CrossEntropyWithSoftmax = 0.14711052 * 1280; EvalErrorPrediction = 0.08203125 * 1280; time = 0.0312s; samplesPerSecond = 41041.4
08/18/2016 09:23:22:  Epoch[50 of 50]-Minibatch[  11-  20, 0.00000000000006%]: CrossEntropyWithSoftmax = 0.13556508 * 1280; EvalErrorPrediction = 0.07109375 * 1280; time = 0.0266s; samplesPerSecond = 48171.0
08/18/2016 09:23:22:  Epoch[50 of 50]-Minibatch[  21-  30, 0.00000000000008%]: CrossEntropyWithSoftmax = 0.13794255 * 1280; EvalErrorPrediction = 0.07343750 * 1280; time = 0.0168s; samplesPerSecond = 76104.4
08/18/2016 09:23:22:  Epoch[50 of 50]-Minibatch[  31-  40, 0.00000000000011%]: CrossEntropyWithSoftmax = 0.14866614 * 1280; EvalErrorPrediction = 0.08125000 * 1280; time = 0.0168s; samplesPerSecond = 76181.4
08/18/2016 09:23:22:  Epoch[50 of 50]-Minibatch[  41-  50, 0.00000000000014%]: CrossEntropyWithSoftmax = 0.13444252 * 1280; EvalErrorPrediction = 0.06640625 * 1280; time = 0.0168s; samplesPerSecond = 76005.0
08/18/2016 09:23:22:  Epoch[50 of 50]-Minibatch[  51-  60, 0.00000000000017%]: CrossEntropyWithSoftmax = 0.14465528 * 1280; EvalErrorPrediction = 0.07265625 * 1280; time = 0.0169s; samplesPerSecond = 75793.5
08/18/2016 09:23:25:  Epoch[50 of 50]-Minibatch[  61-  70, 0.00000000000019%]: CrossEntropyWithSoftmax = 0.14756641 * 1280; EvalErrorPrediction = 0.06953125 * 1280; time = 3.3833s; samplesPerSecond = 378.3
08/18/2016 09:23:25: Finished Epoch[50 of 50]: [Training] CrossEntropyWithSoftmax = 0.14188734 * 10000; EvalErrorPrediction = 0.07390000 * 10000; totalSamplesSeen = 500000; learningRatePerSample = 0.1; epochTime=3.52582s
08/18/2016 09:23:25: SGD: Saving checkpoint model 'C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/models/simple.dnn'
08/18/2016 09:23:25: CNTKCommandTrainEnd: Simple_Demo

08/18/2016 09:23:25: Action "train" complete.


08/18/2016 09:23:25: ##############################################################################
08/18/2016 09:23:25: #                                                                            #
08/18/2016 09:23:25: # Action "write"                                                             #
08/18/2016 09:23:25: #                                                                            #
08/18/2016 09:23:25: ##############################################################################


Post-processing network...

7 roots:
	CrossEntropyWithSoftmax = CrossEntropyWithSoftmax()
	EvalErrorPrediction = ErrorPrediction()
	InvStdOfFeatures = InvStdDev()
	MeanOfFeatures = Mean()
	PosteriorProb = Softmax()
	Prior = Mean()
	ScaledLogLikelihood = Minus()

Validating network. 25 nodes to process in pass 1.

Validating --> labels = InputValue() :  -> [2 x *2]
Validating --> W2 = LearnableParameter() :  -> [2 x 50]
Validating --> W1 = LearnableParameter() :  -> [50 x 50]
Validating --> W0 = LearnableParameter() :  -> [50 x 2]
Validating --> features = InputValue() :  -> [2 x *2]
Validating --> MeanOfFeatures = Mean (features) : [2 x *2] -> [2]
Validating --> InvStdOfFeatures = InvStdDev (features) : [2 x *2] -> [2]
Validating --> MVNormalizedFeatures = PerDimMeanVarNormalization (features, MeanOfFeatures, InvStdOfFeatures) : [2 x *2], [2], [2] -> [2 x *2]
Validating --> W0*features = Times (W0, MVNormalizedFeatures) : [50 x 2], [2 x *2] -> [50 x *2]
Validating --> B0 = LearnableParameter() :  -> [50 x 1]
Validating --> W0*features+B0 = Plus (W0*features, B0) : [50 x *2], [50 x 1] -> [50 x 1 x *2]
Validating --> H1 = Sigmoid (W0*features+B0) : [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> W1*H1 = Times (W1, H1) : [50 x 50], [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> B1 = LearnableParameter() :  -> [50 x 1]
Validating --> W1*H1+B1 = Plus (W1*H1, B1) : [50 x 1 x *2], [50 x 1] -> [50 x 1 x *2]
Validating --> H2 = Sigmoid (W1*H1+B1) : [50 x 1 x *2] -> [50 x 1 x *2]
Validating --> W2*H1 = Times (W2, H2) : [2 x 50], [50 x 1 x *2] -> [2 x 1 x *2]
Validating --> B2 = LearnableParameter() :  -> [2 x 1]
Validating --> HLast = Plus (W2*H1, B2) : [2 x 1 x *2], [2 x 1] -> [2 x 1 x *2]
Validating --> CrossEntropyWithSoftmax = CrossEntropyWithSoftmax (labels, HLast) : [2 x *2], [2 x 1 x *2] -> [1]
Validating --> EvalErrorPrediction = ErrorPrediction (labels, HLast) : [2 x *2], [2 x 1 x *2] -> [1]
Validating --> PosteriorProb = Softmax (HLast) : [2 x 1 x *2] -> [2 x 1 x *2]
Validating --> Prior = Mean (labels) : [2 x *2] -> [2]
Validating --> LogOfPrior = Log (Prior) : [2] -> [2]
Validating --> ScaledLogLikelihood = Minus (HLast, LogOfPrior) : [2 x 1 x *2], [2] -> [2 x 1 x *2]

Validating network. 17 nodes to process in pass 2.


Validating network, final pass.



12 out of 25 nodes do not share the minibatch layout with the input data.

Post-processing network complete.



Allocating matrices for forward and/or backward propagation.

Memory Sharing: Out of 25 matrices, 3 are shared as 1, and 22 are not shared.

	{ CrossEntropyWithSoftmax : [1]
	  EvalErrorPrediction : [1]
	  PosteriorProb : [2 x 1 x *2] }

Minibatch[0]: ActualMBSize = 603
Written to C:\Users\svcphil\AppData\Local\Temp\cntk-test-20160818091536.638579\Speech_Simple@release_cpu/SimpleOutput*
Total Samples Evaluated = 603

08/18/2016 09:23:25: Action "write" complete.

08/18/2016 09:23:25: __COMPLETED__
